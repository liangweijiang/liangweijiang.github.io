{"meta":{"title":"Hexo","subtitle":"","description":"","author":"liangweijiang","url":"https://liangweijiang.github.io","root":"/"},"pages":[{"title":"categories","date":"2020-02-19T09:53:30.000Z","updated":"2020-02-19T09:54:44.015Z","comments":true,"path":"categories/index.html","permalink":"https://liangweijiang.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-02-19T10:00:45.000Z","updated":"2020-02-19T10:01:19.886Z","comments":true,"path":"tags/index.html","permalink":"https://liangweijiang.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"《趣谈网络协议》学习笔记之--最重要的传输层(下)","slug":"NetworkProtocol-05","date":"2020-03-23T07:36:59.725Z","updated":"2020-03-23T07:46:15.694Z","comments":true,"path":"2020/03/23/NetworkProtocol-05/","link":"","permalink":"https://liangweijiang.github.io/2020/03/23/NetworkProtocol-05/","excerpt":"","text":"学习自极客时间《趣谈网络协议》 作者：刘超 最重要的传输层(下)socket套接字一. 什么是socket?在计算机通信领域，socket 被翻译为“套接字”，它是计算机之间进行通信的一种约定或一种方式。通过 socket 这种约定，一台计算机可以接收其他计算机的数据，也可以向其他计算机发送数据。套接字（socket）是一个抽象层，应用程序可以通过它发送或接收数据，可对其进行像对文件一样的打开、读写和关闭等操作。套接字允许应用程序将I/O插入到网络中，并与网络中的其他应用程序进行通信。网络套接字是IP地址与端口的组合。 二. socket的通讯方式在网络层，Socket 函数需要指定到底是 IPv4 还是 IPv6，分别对应设置为 AF_INET 和 AF_INET6。另外，还要指定到底是 TCP 还是 UDP。TCP 协议是基于数据流的，所以设置为 SOCK_STREAM，而 UDP 是基于数据报的，因而设置为 SOCK_DGRAM。 三. 基于 TCP 协议的 Socket 程序函数调用过程 TCP 的服务端要先监听一个端口，一般是先调用 bind 函数，给这个 Socket 赋予一个 IP 地址和端口。内核要通过 TCP 头里面的这个端口，来找到你这个应用程序，把包给你。有时候，一台机器会有多个网卡，也就会有多个 IP 地址，你可以选择监听所有的网卡，也可以选择监听一个网卡，这样，只有发给这个网卡的包，才会给你。 当服务端有了 IP 和端口号，就可以调用 listen 函数进行监听。在 TCP 的状态图里面，有一个 listen 状态，当调用这个函数之后，服务端就进入了这个状态，这个时候客户端就可以发起连接了。 在内核中，为每个 Socket 维护两个队列。一个是已经建立了连接的队列，这时候连接三次握手已经完毕，处于 established 状态；一个是还没有完全建立连接的队列，这个时候三次握手还没完成，处于 syn_rcvd 的状态。 接下来，服务端调用 accept 函数，拿出一个已经完成的连接进行处理。如果还没有完成，就要等着。 在服务端等待的时候，客户端可以通过 connect 函数发起连接。先在参数中指明要连接的 IP 地址和端口号，然后开始发起三次握手。内核会给客户端分配一个临时的端口。一旦握手成功，服务端的 accept 就会返回另一个 Socket（监听的 Socket 和真正用来传数据的 Socket 是两个，一个叫作监听 Socket，一个叫作已连接 Socket。） 连接建立成功之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。 Socket 在 Linux 中就是以文件的形式存在的。除此之外，还存在文件描述符。写入和读出，也是通过文件描述符。 在内核中，Socket 是一个文件，那对应就有文件描述符。每一个进程都有一个数据结构 task_struct，里面指向一个文件描述符数组，来列出这个进程打开的所有文件的文件描述符。文件描述符是一个整数，是这个数组的下标。 这个数组中的内容是一个指针，指向内核中所有打开的文件的列表。既然是一个文件，就会有一个 inode，只不过 Socket 对应的 inode 不像真正的文件系统一样，保存在硬盘上的，而是在内存中的。在这个 inode 中，指向了 Socket 在内核中的 Socket 结构。 在这个结构里面，主要的是两个队列，一个是发送队列，一个是接收队列。在这两个队列里面保存的是一个缓存 sk_buff。这个缓存里面能够看到完整的包的结构。 四. 基于 UDP 协议的 Socket 程序函数调用过程UDP 是没有连接的，所以不需要三次握手，也就不需要调用 listen 和 connect，但是，UDP 的的交互仍然需要 IP 和端口号，因而也需要 bind。UDP 是没有维护连接状态的，因而不需要每对连接建立一组 Socket，而是只要有一个 Socket，就能够和多个客户端通信。也正是因为没有连接状态，每次通信的时候，都调用 sendto 和 recvfrom，都可以传入 IP 地址和端口。 五. 服务器如何连接更多的请求方式一：多进程方式 因为复制了文件描述符列表，而文件描述符都是指向整个内核统一的打开文件列表的，因而父进程刚才因为 accept 创建的已连接 Socket 也是一个文件描述符，同样也会被子进程获得。接下来，子进程就可以通过这个已连接 Socket 和客户端进行互通了，当通信完毕之后，就可以退出进程，那父进程如何知道子进程干完了项目，要退出呢？这个整数就是子进程的 ID，父进程可以通过这个 ID 查看子进程是否完成项目，是否需要退出。 方式二:多线程方式 方式三:IO多路复用(重点) select监听由于 Socket 是文件描述符，因而某个线程盯的所有的 Socket，都放在一个文件描述符集合 fd_set 中，这就是项目进度墙，然后调用 select 函数来监听文件描述符集合是否有变化。一旦有变化，就会依次查看每个文件描述符。那些发生变化的文件描述符在 fd_set 对应的位都设为 1，表示 Socket 可读或者可写，从而可以进行读写操作，然后再调用 select，接着盯着下一轮的变化。 epoll函数上面 select 函数还是有问题的，因为每次 Socket 所在的文件描述符集合中有 Socket 发生变化的时候，都需要通过轮询的方式。而epoll函数，它在内核中的实现不是通过轮询的方式，而是通过注册 callback 函数的方式，当某个文件描述符发送变化的时候，就会主动通知。 问题思考 epoll 是 Linux 上的函数，那你知道 Windows 上对应的机制是什么吗？如果想实现一个跨平台的程序，你知道应该怎么办吗？Windows 上对应的机制是IOCP。通常的办法是，线程池中的工作线程的数量与CPU内核数量相同，以此来最小化线程切换代价。一个IOCP对象，在操作系统中可关联着多个Socket和（或）文件控制端。 IOCP对象内部有一个先进先出（FIFO）队列，用于存放IOCP所关联的输入输出端的服务请求完成消息。请求输入输出服务的进程不接收IO服务完成通知，而是检查IOCP的消息队列以确定IO请求的状态。 （线程池中的）多个线程负责从IOCP消息队列中取走完成通知并执行数据处理；如果队列中没有消息，那么线程阻塞挂起在该队列。这些线程从而实现了负载均衡。 select, poll 和 epoll 的区别 select的第一个参数nfds为fdset集合中最大描述符值加1，fdset是一个位数组，其大小限制为__FD_SETSIZE（1024），位数组的每一位代表其对应的描述符是否需要被检查。第二三四参数表示需要关注读、写、错误事件的文件描述符位数组，这些参数既是输入参数也是输出参数，可能会被内核修改用于标示哪些描述符上发生了关注的事件，所以每次调用select前都需要重新初始化fdset。timeout参数为超时时间，该结构会被内核修改，其值为超时剩余的时间。 poll与select不同，通过一个pollfd数组向内核传递需要关注的事件，故没有描述符个数的限制，pollfd中的events字段和revents分别用于标示关注的事件和发生的事件，故pollfd数组只需要被初始化一次。poll的实现机制与select类似，其对应内核中的sys_poll，只不过poll向内核传递pollfd数组，然后对pollfd中的每个描述符进行poll，相比处理fdset来说，poll效率更高。poll返回后，需要对pollfd中的每个元素检查其revents值，来得指事件是否发生。 select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用 epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在 epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的 时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间，这就是回调机制带来的性能提升。 select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要 一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内 部定义的等待队列），这也能节省不少的开销。 参考来自:https://www.cnblogs.com/xiaoyuanqujing/protected/articles/11715744.html","categories":[{"name":"随笔","slug":"随笔","permalink":"https://liangweijiang.github.io/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://liangweijiang.github.io/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"}]},{"title":"《趣谈网络协议》学习笔记之--最重要的传输层(上)","slug":"NetworkProtocol-04","date":"2020-03-22T15:43:31.110Z","updated":"2020-03-23T06:50:24.141Z","comments":true,"path":"2020/03/22/NetworkProtocol-04/","link":"","permalink":"https://liangweijiang.github.io/2020/03/22/NetworkProtocol-04/","excerpt":"","text":"学习自极客时间《趣谈网络协议》 作者：刘超 最重要的传输层(上)1. UDP协议一. TCP 和 UDP的区别 TCP 是面向连接的，UDP 是面向无连接的。 所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性。 TCP提供可靠交付,通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。UDP 继承了 IP 包的特性，不保证不丢失，不保证按顺序到达。 TCP是面向字节流的,而 UDP 继承了 IP 的特性，基于数据报的，一个一个地发，一个一个地收。 TCP 是可以有拥塞控制的。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点。UDP 就不会，应用让我发，我就发，管它洪水滔天。 TCP 其实是一个有状态服务,精确地记着哪个包发送了没有，接收到没有，发送到哪个了，应该接收哪个了，错一点儿都不行。而 UDP 则是无状态服务。通俗地说是没脑子的，天真无邪的，发出去就发出去了。 二. UDP 包头是什么样的？ 无论应用程序写的使用 TCP 传数据，还是 UDP 传数据，都要监听一个端口,根据端口号，将数据交给相应的应用程序。 三. UDP 的三大使用场景 需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用。DHCP 就是基于 UDP 协议的。一般的获取 IP 地址都是内网请求，而且一次获取不到 IP 又没事，过一会儿还有机会。PXE 可以在启动的时候自动安装操作系统，操作系统镜像的下载使用的 TFTP，这个也是基于 UDP 协议的。在还没有操作系统的时候，客户端拥有的资源很少，不适合维护一个复杂的状态机，而且因为是内网，一般也没啥问题。 不需要一对一沟通，建立连接，而是可以广播的应用。UDP 的不面向连接的功能，可以使得可以承载广播或者多播的协议。DHCP 就是一种广播的形式，就是基于 UDP 协议的。 需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前的时候。 四. 基于 UDP 的例子 网页或者 APP 的访问原来访问网页和手机 APP 都是基于 HTTP 协议的。HTTP 协议是基于 TCP 的，建立连接都需要多次交互，对于时延比较大的目前主流的移动互联网来讲，建立一次连接需要的时间会比较长，然而既然是移动中，TCP 可能还会断了重连，也是很耗时的。而且目前的 HTTP 协议，往往采取多个数据通道共享一个连接的情况，这样本来为了加快传输速度，但是 TCP 的严格顺序策略使得哪怕共享通道，前一个不来，后一个和前一个即便没关系，也要等着，时延也会加大。 流媒体的协议直播协议多使用 RTMP,而这个 RTMP 协议也是基于 TCP 的。TCP 的严格顺序传输要保证前一个收到了，下一个才能确认，如果前一个收不到，下一个就算包已经收到了，在缓存里面，也需要等着。对于直播来讲，这显然是不合适的，因为老的视频帧丢了其实也就丢了，就算再传过来用户也不在意了，他们要看新的了，如果老是没来就等着，卡顿了，新的也看不了，那就会丢失客户，所以直播，实时性比较比较重要，宁可丢包，也不要卡顿的。还有就是当网络不好的时候，TCP 协议会主动降低发送速度，这对本来当时就卡的看视频来讲是要命的，应该应用层马上重传，而不是主动让步。因而，很多直播应用，都基于 UDP 实现了自己的视频传输协议。 实时游戏游戏对实时要求较为严格的情况下，采用自定义的可靠 UDP 协议，自定义重传策略，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成的影响。 IoT 物联网一方面，物联网领域终端资源少，很可能只是个内存非常小的嵌入式系统，而维护 TCP 协议代价太大；另一方面，物联网对实时性要求也很高，而 TCP 还是因为上面的那些原因导致时延大。Google 旗下的 Nest 建立 Thread Group，推出了物联网通信协议 Thread，就是基于 UDP 协议的。 移动通信领域在 4G 网络里，移动流量上网的数据面对的协议 GTP-U 是基于 UDP 的。因为移动网络协议比较复杂，而 GTP 协议本身就包含复杂的手机上线下线的通信协议。如果基于 TCP，TCP 的机制就显得非常多余。 问题思考都说 TCP 是面向连接的，在计算机看来，怎么样才算一个连接呢？ TCP/UDP建立连接的本质就是在客户端和服务端各自维护一定的数据结构（一种状态机），来记录和维护这个“连接”的状态 。并不是真的会在这两个端之间有一条类似“网络专线”这么一个东西。 在IP层，网络情况该不稳定还是不稳定，数据传输走的是什么路径上层是控制不了的，TCP能做的只能是做更多判断，更多重试，更多拥塞控制之类的东西。 2. TCP协议（上）一. TCP 包头格式 源端口和目的端口: 两个应用程序通讯少不了端口 *序号和确认序号: *编号是为了解决乱序问题。发出去的包应该有确认，如果没有收到就应该重新发送，直到送达。确认序号可以解决不丢包的问题。 *状态位: *SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。 *窗口大小: *TCP 要做流量控制，通信双方各声明一个窗口，标识自己当前能够的处理能力，别发送的太快,也别发的太慢。除了做流量控制以外，TCP 还会做拥塞控制。 二. TCP三次握手 一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。 服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。 客户端收到服务端发送的 SYN 和 ACK 之后，发送 ACK 的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。 为了维护这个连接，双方都要维护一个状态机，在连接建立的过程中，双方的状态变化时序图就像这样。 三次握手除了双方建立连接外，主要还是为了沟通一件事情，就是 TCP 包的序号的问题。每个连接都要有不同的序号。这个序号的起始序号是随着时间变化的，可以看成一个 32 位的计数器，每 4ms 加一，如果计算一下，如果到重复，需要 4 个多小时，那个绕路的包早就死翘翘了，因为我们都知道 IP 包头里面有个 TTL，也即生存时间。 为什么要三次，而不是两次？按说两个人打招呼，一来一回就可以了啊？为了可靠，为什么不是四次？ 假设A要与B通讯,当A发起第一个请求是,可能请求到达不了B,或者B没有响应,这时候A就会选择继续重发,终于B收到了A的消息,知道A想要连接,但是A还不知道,可能还会继续重发。 B 收到了请求包，就知道了 A 的存在，并且知道 A 要和它建立连接。如果 B 不乐意建立连接，则 A 会重试一阵后放弃，连接建立失败，没有问题；如果 B 是乐意建立连接的，则会发送应答包给 A。当然对于 B 来说，这个应答包也是一入网络深似海，不知道能不能到达 A。这个时候 B 自然不能认为连接是建立好了，因为应答包仍然会丢，会绕弯路，或者 A 已经挂了都有可能。 而且这个时候 B 还能碰到一个诡异的现象就是，A 和 B 原来建立了连接，做了简单通信后，结束了连接。还记得吗？A 建立连接的时候，请求包重复发了几次，有的请求包绕了一大圈又回来了，B 会认为这也是一个正常的的请求的话，因此建立了连接，可以想象，这个连接不会进行下去，也没有个终结的时候，纯属单相思了。因而两次握手肯定不行。 当然 A 发给 B 的应答之应答也会丢，也会绕路，甚至 B 挂了。按理来说，还应该有个应答之应答之应答，这样下去就没底了。所以四次握手是可以的，四十次都可以，关键四百次也不能保证就真的可靠了。只要双方的消息都有去有回，就基本可以了。 三. TCP四次挥手 断开的时候,客户端首先发起FIN请求,接着进入FIN_WAIT_1 的状态。服务器接收到客户端的FIN的请求后，就ACK客户端的请求，然后进入CLOSE_WAIT 的状态。 客户端收到服务器的ACK后，便进入FIN_WAIT_2 的状态，如果这个时候 服务器 直接跑路，则客户端将永远在这个状态。TCP 协议里面并没有对这个状态的处理，但是 Linux 有，可以调整 tcp_fin_timeout 这个参数，设置一个超时时间。 服务器也想断开连接,便向客户端发送FIN,表示要结束连接。 客户端收到服务器发来的FIN,也向服务器发送一个ACK，确认收到了服务器的请求，便从 FIN_WAIT_2 状态结束。为了确保服务器能够收到这个ACK，TCP 协议要求客户端最后等待一段时间 TIME_WAIT，这个时间要足够长，长到如果服务器没收到 ACK 的话，服务器会重发FIN，客户端收到后也会重新发一个 ACK 并且足够时间到达服务器。而且如果客户端没有等待足够的时间，端口就直接空出来了，但是服务器不知道，服务器原来发过的很多包很可能还在路上，如果客户端的端口被一个新的应用占用了，这个新的应用会收到上个连接中服务器发过来的包。等待的时间设为 2MSL，MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。 四. TCP 状态机 问题思考 TCP 的连接有这么多的状态，如何在系统中查看某个连接的状态? netstat可以在系统中查看某个连接的状态。 2.如何避免TCP的TIME_WAIT状态（高并发）?首先服务器可以设置SO_REUSEADDR套接字选项来通知内核，如果端口忙，但TCP连接位于TIME_WAIT状态时可以重用端口。在一个非常有用的场景就是，如果你的服务器程序停止后想立即重启，而新的套接字依旧希望使用同一端口，此时SO_REUSEADDR选项就可以避免TIME_WAIT状态。如何避免TCP的TIME_WAIT状态（高并发) 服务器遭到SYN攻击怎么办？如何防御SYN攻击？ TCP SYN flood洪水攻击原理和防御破解 针对SYN洪水攻击的防御措施 TCP 协议（下）一. 如何实现一个靠谱的协议？为了保证顺序性，每一个包都有一个 ID。在建立连接的时候，会商定起始的 ID 是什么，然后按照 ID 一个个发送。为了保证不丢包，对于发送的包都要进行应答，但是这个应答也不是一个一个来的，而是会应答某个之前的 ID，表示都收到了，这种模式称为累计确认或者累计应答（cumulative acknowledgment）。 为了记录所有发送的包和接收的包，TCP 也需要发送端和接收端分别都有缓存来保存这些记录。发送端的缓存里是按照包的 ID 一个个排列，根据处理的情况分成四个部分。 第一部分, 发送并确认的。 第二部分, 发送了尚未确认的。 第三部分, 没有发送，但是已经等待发送的。 第四部分， 没有发送，并且暂时还不会发送的。 区分第三和第四部分是因为要流量控制，把握分寸，根据窗口的工作量先评估一下，多了就加，少了就减。 在 TCP 里，接收端会给发送端报一个窗口的大小，叫 Advertised window。这个窗口的大小应该等于上面的第二部分加上第三部分。超过这个窗口的，接收端做不过来，就不能发送了。 发送端需要保持下面的数据结构： 接收方的数据结构如下： AdvertisedWindow=MaxRcvBuffer-((NextByteExpected-1)-LastByteRead)。 其中第二部分里面，由于受到的包可能不是顺序的，会出现空挡，只有和第一部分连续的，可以马上进行回复，中间空着的部分需要等待，哪怕后面的已经来了。 二. 顺序问题与丢包问题发送方和接收方可能会出现以下情况: 接收方接受到了包并发送了相应的ACK,但是可能在路上丢失了. 接收方接受了包但是这个包的前一个包没有接收到,出现了乱序,所以只能缓存着不能ACK 顺序问题和丢包问题都有可能发生，所以我们先来看确认与重发的机制。 一种方法就是超时重试，也即对每一个发送了，但是没有 ACK 的包，都有设一个定时器，超过了一定的时间，就重新尝试。估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断的变化。除了采样 RTT，还要采样 RTT 的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为自适应重传算法。 每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。有一个可以快速重传的机制，当接收方收到一个序号大于下一个所期望的报文段时，就会检测到数据流中的一个间隔，于是它就会发送冗余的 ACK，仍然 ACK 的是期望接收的报文段。而当客户端收到三个冗余的 ACK 后，就会在定时器过期之前，重传丢失的报文段 还有一种方式称为 Selective Acknowledgment （SACK）。这种方式需要在 TCP 头里加一个 SACK 的东西，可以将缓存的地图发送给发送方。例如可以发送 ACK6、SACK8、SACK9，有了地图，发送方一下子就能看出来是 7 丢了。 三. 流量控制问题 当发送方发送包的数量过大,例如将第三部分没有发送但等待发送的包一次性发完,这时候只有当发送方收到接收方发来的ACK,才能继续发送包。 如果接收方实在处理的太慢，导致缓存中没有空间了，可以通过确认信息修改窗口的大小，甚至可以设置为 0，则发送方将暂时停止发送。如果接收端还是一直不处理数据，则随着确认的包越来越多，窗口越来越小，直到为 0。 发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。 四. 拥塞控制问题拥塞控制的问题，也是通过窗口的大小来控制的，前面的滑动窗口 rwnd 是怕发送方把接收方缓存塞满，而拥塞窗口 cwnd，是怕把网络塞满。 原来发送一个包，从一端到达另一端，假设一共经过四个设备，每个设备处理一个包时间耗费 1s，所以到达另一端需要耗费 4s，如果发送的更加快速，则单位时间内，会有更多的包到达这些中间设备，这些设备还是只能每秒处理一个包的话，多出来的包就会被丢弃，这是我们不想看到的。 这个时候，我们可以想其他的办法，例如这个四个设备本来每秒处理一个包，但是我们在这些设备上加缓存，处理不过来的在队列里面排着，这样包就不会丢失，但是缺点是会增加时延，这个缓存的包，4s 肯定到达不了接收端了，如果时延达到一定程度，就会超时重传，也是我们不想看到的。 TCP 的拥塞控制主要来避免两种现象，包丢失和超时重传。一旦出现了这些现象就说明，发送速度太快了，要慢一点。 窗口调整的办法: 慢启动 一条 TCP 连接开始，cwnd 设置为一个报文段，一次只能发送一个；当收到这一个确认的时候，cwnd 加一，于是一次能够发送两个；当这两个的确认到来的时候，每个确认 cwnd 加一，两个确认 cwnd 加二，于是一次能够发送四个；当这四个的确认到来的时候，每个确认 cwnd 加一，四个确认 cwnd 加四，于是一次能够发送八个。可以看出这是指数性的增长。 有一个值 ssthresh 为 65535 个字节，当超过这个值的时候，就要小心一点了，不能倒这么快了，要慢下来。每收到一个确认后，cwnd 增加 1/cwnd，我们接着上面的过程来，一次发送八个，当八个确认到来的时候，每个确认增加 1/8，八个确认一共 cwnd 增加 1，于是一次能够发送九个，变成了线性增长。但是始终都会溢出。 快速重传算法。当接收端发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速的重传，不必等待超时再重传。TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，这时候就将cwnd 减半为 cwnd/2，然后 sshthresh = cwnd，当三个包返回的时候，cwnd = sshthresh + 3，也就是没有一夜回到解放前，而是还在比较高的值，呈线性增长。 但是还是会出现问题; 第一个问题是丢包并不代表着通道满了，也可能是管子本来就漏水。例如公网上带宽不满也会丢包，这个时候就认为拥塞了，退缩了，其实是不对的。 第二个问题是 TCP 的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经晚了。其实 TCP 只要填满管道就可以了，不应该接着填，直到连缓存也填满。 为了优化这两个问题，后来有了 TCP BBR 拥塞算法。它企图找到一个平衡点，就是通过不断的加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以很好的达到高带宽和低时延的平衡。 问题思考TCP 的 BBR 听起来很牛，你知道他是如何达到这个最优点的嘛？ 1 设备缓存会导致延时？假如经过设备的包都不需要进入缓存，那么得到的速度是最快的。进入缓存且等待，等待的时间就是额外的延时。BBR就是为了避免这些问题：充分利用带宽；降低buffer占用率。 2 降低发送packet的速度，为何反而提速了？标准TCP拥塞算法是遇到丢包的数据时快速下降发送速度，因为算法假设丢包都是因为过程设备缓存满了。快速下降后重新慢启动，整个过程对于带宽来说是浪费的。通过packet速度-时间的图来看，从积分上看，BBR充分利用带宽时发送效率才是最高的。可以说BBR比标准TCP拥塞算法更正确地处理了数据丢包。对于网络上有一定丢包率的公网，BBR会更加智慧一点。回顾网络发展过程，带宽的是极大地改进的，而最小延迟会受限与介质传播速度，不会明显减少。BBR可以说是应运而生。 3 BBR如何解决延时？S1：慢启动开始时，以前期的延迟时间为延迟最小值Tmin。然后监控延迟值是否达到Tmin的n倍，达到这个阀值后，判断带宽已经消耗尽且使用了一定的缓存，进入排空阶段。S2：指数降低发送速率，直至延迟不再降低。这个过程的原理同S1S3：协议进入稳定运行状态。交替探测带宽和延迟，且大多数时间下都处于带宽探测阶段。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://liangweijiang.github.io/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://liangweijiang.github.io/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"}]},{"title":"每日一道算法之--合并K个排序链表","slug":"algorithm-23","date":"2020-03-20T07:59:05.513Z","updated":"2020-03-20T08:00:24.956Z","comments":true,"path":"2020/03/20/algorithm-23/","link":"","permalink":"https://liangweijiang.github.io/2020/03/20/algorithm-23/","excerpt":"","text":"合并K个排序链表力扣第23题:https://leetcode-cn.com/problems/merge-k-sorted-lists/ 合并 k 个排序链表，返回合并后的排序链表。请分析和描述算法的复杂度。 示例: 输入:[ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6]输出: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6 暴力算法把N个数放到一个数组里，再一起排序，O(NlogN)。 12345678910111213141516class Solution(object): def mergeKLists(self, lists): \"\"\" :type lists: List[ListNode] :rtype: ListNode \"\"\" self.nodes = [] head = point = ListNode(0) for l in lists: while l: self.nodes.append(l.val) l = l.next for x in sorted(self.nodes): point.next = ListNode(x) point = point.next return head.next 分治算法这道题其实和归并排序基本是完全一样的,利用分治思想,将k个链表分成多个两组链表再合并,和归并排序基本一致. 123456789101112131415161718192021222324252627282930# Definition for singly-linked list.# class ListNode:# def __init__(self, x):# self.val = x# self.next = Noneclass Solution: def mergeKLists(self, lists: List[ListNode]) -&gt; ListNode: if not lists: return n = len(lists) if n &lt; 2: return lists[n - 1] mid = n // 2 left = lists[0:mid] right= lists[mid:] return self.merge(self.mergeKLists(left), self.mergeKLists(right)) def merge(self, l, r): new_node = ListNode(0) n = new_node while l and r: if l.val &lt;= r.val: n.next, l = l, l.next else: n.next, r = r, r.next n = n.next if l: n.next = l if r: n.next = r return new_node.next 复杂度分析时间复杂度:我们可以在 O(n)的时间内合并两个有序链表，其中 n 是两个链表中的总节点数。将所有的合并进程加起来，我们可以得到时间复杂度为 O(Nlogk),其中 k 是链表的数目。 空间复杂度:没有用到额外的数据结构,可以用O(1)的空间复杂度合并两个链表,所以空间复杂度为O(1) 利用堆(优先队列)实现由于k个链表是有序的，我们实际上只需要维护k个指针从k个链表的头向尾滑动，每次选取k个链表的表头里的最小加入新的有序链表里。这就可以维护一个最小堆(优先队列)。 123456789101112131415161718class Solution: def mergeKLists(self, lists: List[ListNode]) -&gt; ListNode: import heapq que = [] # curs存K个链表滑动的头指针 for index, node in enumerate(lists): if node!=None: heapq.heappush(que ,(node.val, index)) dummy_node = ListNode(-1) cur = dummy_node while que: val, index = heapq.heappop(que) cur.next = lists[index] cur = cur.next lists[index] = lists[index].next if lists[index] is not None: heapq.heappush(que, (lists[index].val, index)) return dummy_node.next 复杂度分析时间复杂度: 因为是维护的堆,当我们弹出一个元素是,重新堆化的时间复杂度为 O(logk),其中k为链表的数目,同时找到最小元素的时间复杂度为O(1), 链表总共有N个节点,所以时间复杂度为 O(Nlogk)。 空间复杂度： O(n) 。创造一个新的链表需要 O(n) 的开销。 O(k) 。以上代码采用了重复利用原有节点，所以只要 O(1) 的空间。同时优先队列（通常用堆实现）需要 O(k) 的空间（远比大多数情况的 N 要小）。","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"分治","slug":"分治","permalink":"https://liangweijiang.github.io/tags/%E5%88%86%E6%B2%BB/"},{"name":"优先队列","slug":"优先队列","permalink":"https://liangweijiang.github.io/tags/%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/"},{"name":"堆","slug":"堆","permalink":"https://liangweijiang.github.io/tags/%E5%A0%86/"}]},{"title":"每日一道算法之--最长上升子序列","slug":"algorithm-300","date":"2020-03-17T16:54:50.537Z","updated":"2020-03-17T16:55:51.686Z","comments":true,"path":"2020/03/18/algorithm-300/","link":"","permalink":"https://liangweijiang.github.io/2020/03/18/algorithm-300/","excerpt":"","text":"最长上升子序列力扣第300题:https://leetcode-cn.com/problems/longest-increasing-subsequence/ 给定一个无序的整数数组，找到其中最长上升子序列的长度。 示例: 输入: [10,9,2,5,3,7,101,18]输出: 4解释: 最长的上升子序列是 [2,3,7,101]，它的长度是 4。说明: 可能会有多种最长上升子序列的组合，你只需要输出对应的长度即可。你算法的时间复杂度应该为 O(n2) 。进阶: 你能将算法的时间复杂度降低到 O(n log n) 吗? 1. 动态规划一看到最字,首先想到的是动态规划和贪心算法。这道题动态规划还是挺好想的，循环两次遍历，这样子就能找到所有的情况，状态转移方程为： if num[j] &gt; num[i]: dp[i] = max(dp[i], dp[j] + 1) 代码如下: 123456789class Solution: def lengthOfLIS(self, nums: List[int]) -&gt; int: if not nums: return 0 dp = [1 for _ in range(len(nums))] for i in range(len(nums)): for j in range(i): if nums[i] &gt; nums[j]: dp[i] = max(dp[i], dp[j] + 1) return max(dp) 1.1 复杂度分析时间复杂度:O(n^2)，其中 n 为数组nums 的长度。动态规划的状态数为 n，计算状态 dp[i] 时，需要 O(n) 的时间遍历 dp[0…i−1] 的所有状态，所以总时间复杂度为 O(n^2)。 空间复杂度:需要额外使用长度为 n 的 dp 数组,所以空间复杂度为O(n)。 2. 贪心 + 二分查找我一开始想到了用分治去处理这道题,但是因为分治太难去统计长度了,所以觉得不太行,就去看了一下官方题解。 代码如下： 12345678910111213141516171819class Solution: def lengthOfLIS(self, nums: List[int]) -&gt; int: if not nums: return 0 res = [] for num in nums: if not res or num &gt; res[-1]: res.append(num) else: l, r = 0, len(res) - 1 index = r while l &lt;= r: mid = l + int((r -l) &gt;&gt; 1) if res[mid] &gt;= num: index = mid r = mid - 1 else: l = mid + 1 res[index] = num return len(res) 2.1 复杂度分析时间复杂度：数组nums 的长度为 n，我们依次用数组中的元素去更新 d 数组，而更新 d 数组时需要进行 O(logn) 的二分搜索，所以总时间复杂度为 O(nlogn)。 空间复杂度:需要额外使用长度为 n 的 dp 数组,所以空间复杂度为O(n)。 参考文章官方题解:https://leetcode-cn.com/problems/longest-increasing-subsequence/solution/zui-chang-shang-sheng-zi-xu-lie-by-leetcode-soluti/ 精选题解:https://leetcode-cn.com/problems/longest-increasing-subsequence/solution/zui-chang-shang-sheng-zi-xu-lie-dong-tai-gui-hua-2/ 相似题目673. 最长递增子序列的个数 646. 最长数对链 334. 递增的三元子序列","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"https://liangweijiang.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"二分查找","slug":"二分查找","permalink":"https://liangweijiang.github.io/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"name":"贪心","slug":"贪心","permalink":"https://liangweijiang.github.io/tags/%E8%B4%AA%E5%BF%83/"}]},{"title":"写给自己的一些话","slug":"dream","date":"2020-03-15T18:36:58.976Z","updated":"2020-03-15T18:41:53.689Z","comments":true,"path":"2020/03/16/dream/","link":"","permalink":"https://liangweijiang.github.io/2020/03/16/dream/","excerpt":"","text":"写给自己的一些话昨晚收到了人生的第一份面试邀请，头条的邀请，心情真的很激动，但是更多的也是紧张。倒也不是说自己的技术不行吧，而是，在几个月前，对于腾讯头条阿里这种像是珠穆朗玛峰那种我想都不敢想的大厂，我竟然能收到面试。 高中， 那个自傲的自己高中生活三年，当时在学校成绩一直还算可以，起初是蹦着中科大和复旦去的，最差也得有个华工吧哈哈，当时成绩确实还可以，但是有点飘了哈。当我高考成绩出来后，我懵了，真的当时就整个人飘忽忽的，看着这个成绩单，我知道自己再也不是那个当初自傲的自己了。大伯劝我复读，说什么算过我的命今天考试不行，明年清华都能上（当时高考前大伯就叮嘱我要我复读了），但是我不信命，我这辈子都没想过我要复读。我不后悔，换句话说，后悔也没用。 大一，那个懵懂的自己于是来到了广工，大一这一年，真的是对专业一窍不通，开始的时候连C的课设都难办，下学期的时候，有几位同学进了工作室，而我真的一点基础都没有，笔试一面混一混，到了二面，人就傻了，操作系统是啥？正则匹配是什么？完全不懂啊。哎，大一真的是跟个无头苍蝇一样，根本不知道自己的目标是什么，甚至连自己的专业都不知道是什么，更不用说去看什么书去充实自己。 大二，那个颓废的自己大二，逐渐变成了老司机，开始疯狂逃课了，一周五天睡四天，那个时候的心情我现在都还记得，哎，工作室进不去了，还有啥用，看着在工作室的同学天天有着自己的事做，心里其实很难受，但是又不知道从何下手，只能通过打游戏来麻痹自己，成绩一落千丈，从全级第六掉到了全班倒数，那时候就处在每天的颓废和罪恶感中，很是难受。知道下学期，因为性格很开朗，认识了很多朋友，也包括工作室的伙伴，我开始向他们询问学习方法和学习书籍，同时接触到了Python这一门语言，渐渐地爱上了这一门语言，虽然对比于c++和java来说，它有许多不足，但是它有着自己的魅力去吸引我。大二下学期快放假的时候，我逐渐开始学习起来，虽然效率不高，因为看的是视频，学的时间不多，但是那时候我开始，真的想学习了。 大三，开始去改变自己大三我知道自己不能再这样下去了，于是我决定彻彻底底的改变自己。起步的时候很辛苦，这种辛苦是要入门计算机，看视频效率真的太慢了，但是看书看不下去，我就讲视频1.5倍速，看了15天，当时记得看到了socket编程，刚好碰到了计网的课设，我就自己写了一人ftp文件传输系统，参加了答辩，那是我人生中第一次答辩，我第一个感受到了作为一个技术人员给我带来的成就感，逐渐地，我爱上了编程。后来碰上了老师叫上一届的师兄回来分享经验，谈到了春招，当时距离春招就三个多月了，我又开始了恐慌，真的每天都在愁。然后我得到了我一个朋友的帮助，这里我真的非常感谢我这个朋友，是他给了我很大的信心和建议，让我去复习底层的知识。当时刚好碰上了考试，我又浪费了半个月的时间。考完试后，我开始了痛苦但是又快乐的基础知识学习，真的太爽了学习基础。计算机网络，操所系统，数据结构与算法，我开始尝试着去看书，去看极客专栏，一步一步脚踏实地地去学习，这段时间的收获真的太多了，不仅仅是知识，更多的是心态上的成熟。 梦想是我学习的动力从小到大我的梦想都没有改变过，虽然我颓废过，堕落过，但是他真的是我生活上一个很大的支撑点。最近我在一个视频上看到这样一段话： 我当时真的眼泪直接绷不住了，这真的是我一直以来藏在心里的话。对于一个的大学生来说，除了梦想，他还能有什么呢，但这就是我一直没有放弃的原因，因为我知道，这是驱动我努力前行的动力。 感谢我身边的所有人在我大学期间，真的受到了无数人的帮助，真的感谢每一位爱我的人和我爱的人，人生真的就是需要这样一群人，才能构建你一生的轨迹。 感谢我这个编程很牛逼的好朋友，在自己也要复习，完全没有必要帮助我的情况下，给我推荐技术线，学习资料，一直鼓励我叫我不要放弃，一直帮我修改简历，真的这段时间一直陪着我。 感谢我大学的好哥们，一直安慰我，鼓励我，给我信心，帮我找岗位，一直默默地支持我 感谢我的叔叔，给我分享自己的人生经验，无时无刻都在支持我 感谢这位阿里的师兄，本来互不相识，却给我很多宝贵的学习经验和方法，同时也一直鼓励我 感谢我的女朋友，在我这段时间里，学习没怎么陪她，但是她很体谅我，还天天过来安慰鼓励我 我要感谢的人真的太多太多了，父母亲人就更不用多说了，他们总是默默地为我付出着，我一定会带着他们的祝福，坚定地走下去 学习目标最后附上自己的学习目标：坚持学习算法，知道完全掌握；对网络协议达到精通的程度；熟悉自己领域的技术栈，做到踏踏实实的学习。希望4年之后，自己能达到自己理想的水准。最后附上自己的日学习计划，一定要长期坚持下来 面试来了，尽全力对待，不留遗憾，给爷冲！！！！","categories":[{"name":"随笔","slug":"随笔","permalink":"https://liangweijiang.github.io/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[]},{"title":"《趣谈网络协议》学习笔记之--从二层到三层（下）","slug":"NetworkProtocol-03","date":"2020-03-15T16:50:10.771Z","updated":"2020-03-15T16:51:21.097Z","comments":true,"path":"2020/03/16/NetworkProtocol-03/","link":"","permalink":"https://liangweijiang.github.io/2020/03/16/NetworkProtocol-03/","excerpt":"","text":"学习自极客时间《趣谈网络协议》 作者：刘超 从二层到三层（下）4. 网关的实现一. 怎么样在宿舍上网有两种方式: 有一台电脑需要两张网卡,一张网卡的线插到交换机上，另一张网卡的线插到校园网的网口。而且，这张新的网卡的 IP 地址要按照学校网管部门分配的配置，不然上不了网。这种情况下，如果你们宿舍的人要上网，就需要一直开着那台电脑。 买个家庭路由器,家庭路由器会有内网网口和外网网口。把外网网口的线插到校园网的网口上，将这个外网网口配置成和网管部的一样。内网网口连上所有的电脑。这种情况下，如果你有人要上网，就需要一直开着路由器。 其实家庭路由器和电脑的功能一样,只不过是嵌入式系统而已。 其他电脑要上网还需要配置网卡。当然 DHCP 是可以默认配置的。在进行网卡配置的时候，除了 IP 地址，还需要配置一个Gateway 的东西，这个就是网关。 二. MAC 头和 IP 头的细节 在 MAC 头里面，先是目标 MAC 地址，然后是源 MAC 地址，然后有一个协议类型，用来说明里面是 IP 协议。 IP 头里面的版本号，目前主流的还是 IPv4，数据包是按照服务类型（Type of Service，TOS）被分配到三个波段（band）里面的。TOS 是 IP 头里面的一个字段，代表了当前的包是高优先级的，还是低优先级的。TTL 指生存时间,与ICMP有关。 另外，还有 8 位标识协议。这里到了下一层的协议，也就是，是 TCP 还是 UDP。最重要的就是源 IP 和目标 IP。先是源 IP 地址，然后是目标 IP 地址。在任何一台机器上，当要访问另一个 IP 地址的时候，都会先判断，这个目标 IP 地址，和当前机器的 IP 地址，是否在同一个网段。怎么判断同一个网段呢？需要 CIDR 和子网掩码。 如果是同一个网段，则直接通过ARP获取Mac地址，如果不同网段，就需要经过网关了。获取网关的Mac地址也是在局域网中吼，流程是一样的。 网关往往是一个路由器，是一个三层转发的设备。啥叫三层设备？就是把 MAC 头和 IP 头都取下来，然后根据里面的内容，看看接下来把包往哪里转发的设备。路由器是一台设备，它有多个网口或者网卡，分别连着多个局域网。每个网卡的 IP 地址都和局域网的 IP 地址相同的网段，就是那个局域网的网关。 三. 静态路由路由器可以分为静态路由和动态路由。静态路由，其实就是在路由器上，配置一条一条规则。这些规则包括：想访问 BBS 站（它肯定有个网段），从 2 号口出去，下一跳是 IP2；想访问教学视频站（它也有个自己的网段），从 3 号口出去，下一跳是 IP3，然后保存在路由器里。每当要选择从哪只手抛出去的时候，就一条一条的匹配规则，找到符合的规则，就按规则中设置的那样，从某个口抛出去，找下一跳 IPX。 四。 IP 头和 MAC 头哪些变、哪些不变？MAC 地址是一个局域网内才有效的地址。因而，MAC 地址只要过网关，就必定会改变，因为已经换了局域网。两者主要的区别在于 IP 地址是否改变。不改变 IP 地址的网关，我们称为转发网关；改变 IP 地址的网关，我们称为NAT 网关。 当各个局域网间网段有商量，即IP段没有冲突的时候，不同网段间用户的通讯，经过网关的时候，IP地址不会改变，改变的是Mac地址。 当局域网之间没有商量过，各定各的网段，因而 IP 段冲突了。不同网段间用户的通讯，经过网关的时候，需要将当前局域网内的IP地址转换成国际通用的IP地址，当到了最后一跳时，NAT网关再将国际IP地址转换成私网的IP地址，最终达到接收方。这里Mac地址也在不断变化的。从这个过程可以看出，IP 地址也会变。这个过程用英文说就是 Network Address Translation，简称 NAT。 总结 如果离开本局域网，就需要经过网关，网关是路由器的一个网口； 路由器是一个三层设备，里面有如何寻找下一跳的规则； 当在你家里要访问 163 网站的时候，你的包需要 NAT 成为公网 IP，返回的包又要 NAT 成你的私有 IP，返回包怎么知道这是你的请求呢？它怎么就这么智能的 NAT 成了你的 IP 而非别人的 IP 呢？ NAT在进行地址替换时不仅仅包含IP地址，还有端口号。具体说来就是，我们在进行连接外网服务器请求的数据包中，除了源、目的IP地址外，还有源、目的端口号。其中目的端口号是固定的，比如21或80等等。但源端口号是随机生成的。当数据包到达进行NAT的设备时，除了私有IP地址会被替换成公网IP地址外，端口号也会被替换成NAT随机生成的端口号。NAT的端口号和局域网中的主机一一对应，同时NAT设备维护一张端口号和主机对应的表。当外网服务器返回数据到NAT设备时，NAT设备通过返回数据包中的端口号找到局域网中的主机并将数据转发。 5. 路由协议一张路由表中会有多条路由规则。每一条规则至少包含这三项信息。 目的网络：这个包想去哪儿？ 出口设备：将包从哪个口扔出去？ 下一跳网关：下一个路由器的地址。 一. 动态路由算法复杂的网络拓扑结构中,路由的路径就转化成为如何在途中找到最短路径的问题。求最短路径常用的有两种方法，一种是 Bellman-Ford 算法，一种是 Dijkstra 算法。在计算机网络中基本也是用这两种方法计算的。 距离矢量路由算法 第一大类的算法称为距离矢量路由（distance vector routing）。它是基于 Bellman-Ford 算法的。 这种算法的基本思路是，每个路由器都保存一个路由表，包含多行，每行对应网络中的一个路由器，每一行 包含两部分信息，一个是要到目标路由器，从那条线出去，另一个是到目标路由器的距离。由此可以看出，每个路由器都是知道全局信息的。那这个信息如何更新呢？每个路由器都知道自己和邻居之间的距离，每过几秒，每个路由器都将自己所知的到达所有的路由器的距离告知邻居，每个路由器也能从邻居那里得到相似的信息。每个路由器根据新收集的信息，计算和其他路由器的距离，比如自己的一个邻居距离目标路由器的距离是 M，而自己距离邻居是 x，则自己距离目标路由器是 x+M。 距离矢量路由算法存在的问题: 第一个问题就是好消息传得快，坏消息传得慢。 如果有个路由器加入了这个网络，它的邻居就能很快发现它，然后将消息广播出去。要不了多久，整个网络就都知道了。但是一旦一个路由器挂了，挂的消息是没有广播的。当每个路由器发现原来的道路到不了这个路由器的时候，感觉不到它已经挂了，而是试图通过其他的路径访问，直到试过了所有的路径，才发现这个路由器是真的挂了。 这种算法的第二个问题是，每次发送的时候，要发送整个全局路由表。 链路状态路由算法 第二大类算法是链路状态路由（link state routing），基于 Dijkstra 算法。 这种算法的基本思路是：当一个路由器启动的时候，首先是发现邻居，向邻居 say hello，邻居都回复。然后计算和邻居的距离，发送一个 echo，要求马上返回，除以二就是距离。然后将自己和邻居之间的链路状态包广播出去，发送到整个网络的每个路由器。这样每个路由器都能够收到它和邻居之间的关系的信息。因而，每个路由器都能在自己本地构建一个完整的图，然后针对这个图使用 Dijkstra 算法，找到两点之间的最短路径。 不像距离距离矢量路由协议那样，更新时发送整个路由表。链路状态路由协议只广播更新的或改变的网络拓扑，这使得更新信息更小，节省了带宽和 CPU 利用率。而且一旦一个路由器挂了，它的邻居都会广播这个消息，可以使得坏消息迅速收敛。 二. 动态路由协议 基于链路状态路由算法的 OSPF OSPF（Open Shortest Path First，开放式最短路径优先）就是这样一个基于链路状态路由协议，广泛应用在数据中心中的协议。由于主要用在数据中心内部，用于路由决策，因而称为内部网关协议（Interior Gateway Protocol，简称 IGP）。 内部网关协议的重点就是找到最短的路径。在一个组织内部，路径最短往往最优。当然有时候 OSPF 可以发现多个最短的路径，可以在这多个路径中进行负载均衡，这常常被称为等价路由。这一点非常重要。有了等价路由，到一个地方去可以有相同的两个路线，可以分摊流量，还可以当一条路不通的时候，走另外一条路。 基于距离矢量路由算法的 BGP 但是外网的路由协议，也即国家之间的，又有所不同。我们称为外网路由协议（Border Gateway Protocol，简称 BGP）。 对于网络包同样，每个数据中心都设置自己的 Policy。例如，哪些外部的 IP 可以让内部知晓，哪些内部的 IP 可以让外部知晓，哪些可以通过，哪些不能通过。 在网络世界，这一个个国家成为自治系统 AS（Autonomous System）。自治系统分几种类型。 Stub AS：对外只有一个连接。这类 AS 不会传输其他 AS 的包。例如，个人或者小公司的网络。 Multihomed AS：可能有多个连接连到其他的 AS，但是大多拒绝帮其他的 AS 传输包。例如一些大公司的网络。 Transit AS：有多个连接连到其他的 AS，并且可以帮助其他的 AS 传输包。例如主干网。 BGP 又分为两类，eBGP 和 iBGP。自治系统间，边界路由器之间使用 eBGP 广播路由。内部网络也需要访问其他的自治系统。边界路由器如何将 BGP 学习到的路由导入到内部网络呢？就是通过运行 iBGP，使得内部的路由器能够找到到达外网目的地的最好的边界路由器。 BGP 协议使用的算法是路径矢量路由协议（path-vector protocol）。它是距离矢量路由协议的升级版。前面说了距离矢量路由协议的缺点。其中一个是收敛慢。在 BGP 里面，除了下一跳 hop 之外，还包括了自治系统 AS 的路径，从而可以避免坏消息传的慢的问题，也即上面所描述的，B 知道 C 原来能够到达 A，是因为通过自己，一旦自己都到达不了 A 了，就不用假设 C 还能到达 A 了。 路由信息协议(RIP) 路由信息协议是在一个AS系统中使用地内部路由选择协议，是个非常简单的基于距离向量路由选择的协议。 它路由器生产商之间使用的第一个开放标准，是最广泛的路由协议，在所有IP路由平台上都可以得到。当使用RIP时，一台Cisco路由器可以与其他厂商的路由器连接。 路由信息协议是内部网关协议IGP中最先得到使用的协议。RIP是一种分布式的基于距离矢量的路由选择协议，是因特网的标准协议，其最大优点就是实现简单，开销较小。 问题拓展路由器之间信息的交换使用什么协议呢？ OSPF基于IP协议，端口号为89原因：ospf自身提供主从协商机制，可以保证可靠的传输，另外全网路由器保持着同样的一个lsdb，当拓扑发生变化时，需要携带的变更信息较少，通过IP协议即可完成 RIP协议采用UDP是因为，rip每周期需全网组播路由信息，路由信息数目较大，故使用UDP协议可提高效率 BGP为边界网关协议，因携带的路由信息较多，且可能跨不同网络传送路由信息，为保证可靠性，需使用TCP协议，可兼顾容量和可靠性","categories":[{"name":"随笔","slug":"随笔","permalink":"https://liangweijiang.github.io/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://liangweijiang.github.io/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"}]},{"title":"每日一道算法之--最长公共子序列","slug":"algorithm-1143","date":"2020-03-15T12:19:20.111Z","updated":"2020-03-15T12:20:02.798Z","comments":true,"path":"2020/03/15/algorithm-1143/","link":"","permalink":"https://liangweijiang.github.io/2020/03/15/algorithm-1143/","excerpt":"","text":"最长公共子序列力扣第1143题:https://leetcode-cn.com/problems/longest-common-subsequence/ 给定两个字符串 text1 和 text2，返回这两个字符串的最长公共子序列。 一个字符串的 子序列 是指这样一个新的字符串：它是由原字符串在不改变字符的相对顺序的情况下删除某些字符（也可以不删除任何字符）后组成的新字符串。例如，”ace” 是 “abcde” 的子序列，但 “aec” 不是 “abcde” 的子序列。两个字符串的「公共子序列」是这两个字符串所共同拥有的子序列。 若这两个字符串没有公共子序列，则返回 0。 示例 1: 输入：text1 = “abcde”, text2 = “ace”输出：3解释：最长公共子序列是 “ace”，它的长度为 3。 示例 2: 输入：text1 = “abc”, text2 = “abc”输出：3解释：最长公共子序列是 “abc”，它的长度为 3。 示例 3: 输入：text1 = “abc”, text2 = “def”输出：0解释：两个字符串没有公共子序列，返回 0。 动态规划哈哈,又看到了最字,这次要多分析题目了,看看动态规划是不是合适.看看是否符合动态规划的三大特征最优子结构、无后效性和重复子问题。 首先看这道题,每当遍历到一个位置时,当前的最长公共字符串和子字符串的最长公共子序列有关,所以符合最优子结构。 我们只关心前面子串最长公共子序列的长度，不关心这个状态是怎么一步一步推导出来的。所以符合无后性所以动态规划来做这道题应该还是可以的 下面来分析一下这道题目： 这道题有两个字符串，很明显我们可以构造一个二维数组，来存储每种情况对应的状态值 我们循环遍历这两个字符串，当两个字符串的字符是一样的，就证明找到了一个公共子序列的元素，在子问题的基础上加一；如果不相等，则看两个字符串当前谁的公共子序列最长。 123456789101112class Solution: def longestCommonSubsequence(self, text1: str, text2: str) -&gt; int: if not text1 or not text2: return 0 len1, len2 = len(text1), len(text2) dp = [[0] * (len2 + 1) for _ in range(len1 + 1)] for i in range(1, len1 + 1): for j in range(1, len2 + 1): if text1[i-1] == text2[j-1]: dp[i][j] = dp[i - 1][j - 1] + 1 else: dp[i][j] = max(dp[i - 1][j], dp[i][j - 1]) return dp[-1][-1] 优化动态规划可以看到上面的这一段代码,运用了二维数组这种比较复杂的数据结构,把所有的状态都记录了下来,但是可以发现,其实只有最后一行的数据才是有效的,因为其他数据会失效,所以我们可以用一维数组,只存储最后一行的数据。 1234567891011121314151617class Solution: def longestCommonSubsequence(self, text1: str, text2: str) -&gt; int: if not text1 or not text2: return 0 len1, len2 = len(text1), len(text2) dp = [0 for _ in range(len2 + 1)] for i in range(1, len1 + 1): tmp = 0 for j in range(1, len2 + 1): # 拿到上一次的最大子序列 prev = tmp # 获取上一个循环的在这个字符位置的最大子序列 tmp = dp[j] if text1[i-1] == text2[j-1]: dp[j] = prev + 1 else: dp[j] = max(dp[j -1], dp[j]) return dp[-1]","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"https://liangweijiang.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"}]},{"title":"每日一道算法之--岛屿的最大面积","slug":"algorithm-695","date":"2020-03-15T10:29:09.174Z","updated":"2020-03-15T10:31:36.670Z","comments":true,"path":"2020/03/15/algorithm-695/","link":"","permalink":"https://liangweijiang.github.io/2020/03/15/algorithm-695/","excerpt":"","text":"岛屿的最大面积力扣第695题:https://leetcode-cn.com/problems/max-area-of-island/ 给定一个包含了一些 0 和 1的非空二维数组 grid , 一个 岛屿 是由四个方向 (水平或垂直) 的 1 (代表土地) 构成的组合。你可以假设二维矩阵的四个边缘都被水包围着。 找到给定的二维数组中最大的岛屿面积。(如果没有岛屿，则返回面积为0。) 示例 1: [[0,0,1,0,0,0,0,1,0,0,0,0,0], [0,0,0,0,0,0,0,1,1,1,0,0,0], [0,1,1,0,1,0,0,0,0,0,0,0,0], [0,1,0,0,1,1,0,0,1,0,1,0,0], [0,1,0,0,1,1,0,0,1,1,1,0,0], [0,0,0,0,0,0,0,0,0,0,1,0,0], [0,0,0,0,0,0,0,1,1,1,0,0,0], [0,0,0,0,0,0,0,1,1,0,0,0,0]]对于上面这个给定矩阵应返回 6。注意答案不应该是11，因为岛屿只能包含水平或垂直的四个方向的‘1’。 示例 2: [[0,0,0,0,0,0,0,0]]对于上面这个给定的矩阵, 返回 0。 注意: 给定的矩阵grid 的长度和宽度都不超过 50。 1. 深度优先搜索(DFS)DFS重在追求”专一”吧!一条道走到黑,我们想知道网格中每个连通形状的面积，然后取最大值。 二维数组中每一个位置都有可能是刀鱼最大面积的起点,所以每一个位置都要去作为起点去搜索 以 4 个方向探索与之相连的每一个土地（以及与这些土地相连的土地），那么探索过的土地总数将是该连通形状的面积。递归到最深一层,然后判断是否符合要求,然后再层层往上回退。为了确保每个土地访问不超过一次，我们每次经过一块土地时，将这块土地的值置为 0。这样我们就不会多次访问同一土地。 12345678910111213141516171819202122class Solution: def maxAreaOfIsland(self, grid: List[List[int]]) -&gt; int: if not grid: return 0 rows = len(grid) cols = len(grid[0]) max_area = 0 for row in range(rows): for col in range(cols): max_area = max(self.dfs(row, col, rows, cols, grid), max_area) return max_area def dfs(self, row, col, rows, cols, grid): res = 0 # 只有为1的时候才算岛屿 if 0 &lt;= row &lt; rows and 0 &lt;= col &lt; cols and grid[row][col] != 0 : # 搜索过的就置为0，防止重复搜索 grid[row][col] = 0 res = 1 for di, dj in [[0, 1], [0, -1], [1, 0], [-1, 0]]: new_row, new_col = row + di, col + dj res += self.dfs(new_row, new_col, rows, cols, grid) return res DFS也可以用栈来实现 1234567891011121314151617181920class Solution: def maxAreaOfIsland(self, grid: List[List[int]]) -&gt; int: if not grid: return 0 rows = len(grid) cols = len(grid[0]) max_area = 0 for row in range(rows): for col in range(cols): stack = [(row, col)] res = 0 while stack: row, col = stack.pop() if 0 &lt;= row &lt; rows and 0 &lt;= col &lt; cols and grid[row][col] != 0 : grid[row][col] = 0 res += 1 for di, dj in [[0, 1], [0, -1], [1, 0], [-1, 0]]: new_row, new_col = row + di, col + dj stack.append((new_row, new_col)) max_area = max(max_area, res) return max_area 1.1 复杂度分析时间复杂度： 我们访问每个网格最多一次。所以时间复杂度为$$O(R * C)$$。其中 R 是给定网格中的行数，C 是列数。 空间复杂度：递归的深度最大可能是整个网格的大小，因此最大可能使用 $$O(R * C) $$的栈空间,所以空间复杂度为$$O(R * C)$$ 2. 广度优先搜索(BFS)顾名思义，广度优先搜索追求的是”覆盖面积”。其实只要将深度优先搜索中的栈换成队列，就可以实现广度优先搜索。 1234567891011121314151617181920class Solution: def maxAreaOfIsland(self, grid: List[List[int]]) -&gt; int: if not grid: return 0 rows = len(grid) cols = len(grid[0]) max_area = 0 for i in range(rows): for j in range(cols): queue = collections.deque([(i, j)]) res = 0 while queue: row, col = queue.popleft() if 0 &lt;= row &lt; rows and 0 &lt;= col &lt; cols and grid[row][col] != 0 : grid[row][col] = 0 res += 1 for di, dj in [[0, 1], [0, -1], [1, 0], [-1, 0]]: new_row, new_col = row + di, col + dj queue.append((new_row, new_col)) max_area = max(max_area, res) return max_area 2.1 复杂度分析时间复杂度： 我们访问每个网格最多一次。所以时间复杂度为$$O(R * C)$$。其中 R 是给定网格中的行数，C 是列数。 空间复杂度：递归的深度最大可能是整个网格的大小，因此最大可能使用 $$O(R * C) $$的栈空间,所以空间复杂度为$$O(R * C)$$ ##总结深度优先搜索和栈有关,广度优先搜索和队列有关. ##python特别注意的一点如果仔细看代码,你会发现我在用栈实现的时候和用队列实现的时候,有一句代码不一样: 123456789用栈实现的;for row in range(rows): for col in range(cols): stack = [(row, col)]用队列实现的:for i in range(rows): for j in range(cols): queue = collections.deque([(i, j)]) 这里我调试了很久,用队列实现的时候,row, col = queue.popleft()这两个变量如果和上面的一样,提交的结果就不正确,但是用栈就可以,我猜想应该是队列底层实现的缘故,具体原因还不知道. 相似题目200. 岛屿数量 面试题13. 机器人的运动范围 面试题12. 矩阵中的路径","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"BSF","slug":"BSF","permalink":"https://liangweijiang.github.io/tags/BSF/"},{"name":"DFS","slug":"DFS","permalink":"https://liangweijiang.github.io/tags/DFS/"},{"name":"回溯","slug":"回溯","permalink":"https://liangweijiang.github.io/tags/%E5%9B%9E%E6%BA%AF/"}]},{"title":"《趣谈网络协议》学习笔记之--从二层到三层（上）","slug":"NetworkProtocol-02","date":"2020-03-15T03:47:29.800Z","updated":"2020-03-15T03:53:08.043Z","comments":true,"path":"2020/03/15/NetworkProtocol-02/","link":"","permalink":"https://liangweijiang.github.io/2020/03/15/NetworkProtocol-02/","excerpt":"","text":"学习自极客时间《趣谈网络协议》 作者：刘超 从二层到三层（上）1. 从物理层到MAC层一 、 物理层主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。它的主要作用是传输比特流（就是由1、0转化为电流强弱来进行传输,到达目的地后在转化为1、0，也就是我们常说的数模转换与模数转换），这一层的数据叫做比特，单位是bit比特。集线器(hub):和交换机不同，集线器没有大脑，它完全在物理层工作。它会将自己收到的每一个字节，都复制到其他端口上去。这是第一层物理层联通的方案。 二 、数据链路层** 1 解决三个问题** Hub 采取的是广播的模式，如果每一台电脑发出的包，局域网的每个电脑都能收到，这就需要解决几个问题： 这个包是发给谁的？谁应该接收？ 大家都在发，会不会产生混乱？有没有谁先发、谁后发的规则？ 如果发送的时候出现了错误，怎么办？ 这几个问题，都是第二层，数据链路层，也即 MAC 层要解决的问题。MAC 的全称是 Medium Access Control，即媒体访问控制。控制什么呢？其实就是控制在往媒体上发数据的时候，谁先发、谁后发的问题。防止发生混乱。这解决的是第二个问题。这个问题中的规则，学名叫多路访问。解决的方式有信道划分; 轮流协议；随机接入协议(著名的以太网，用的就是这个方式)。 接下来要解决第一个问题：发给谁，谁接收？这里用到一个物理地址，叫作链路层地址。但是因为第二层主要解决媒体接入控制的问题，所以它常被称为MAC 地址。解决第一个问题就牵扯到第二层的网络包格式。对于以太网，第二层的最开始，就是目标的 MAC 地址和源的 MAC 地址。 类型中多部分是IP数据包,ip又包含了运输层和应用层的信息,层层封装。 有了目标mac地址，数据包就可以在链路上广播，当有网卡发现mac地址正好是它的，就把这个数据包收起来，然后在打开IP,发现IP地址也是自己的，再打开TCP，端口也是自己的，就交给应用层去处理。应用层处理好后，又层层封装返回，这时候之前的源mac地址就变成了目标mac地址。 对于以太网，第二层的最后面是 CRC，也就是循环冗余检测。通过 XOR 异或的算法，来计算整个包是否在发送的过程中出现了错误，主要解决第三个问题。 ** 2 如何获取目标mac地址?** 一个广播的网络里面接入了 N 台机器，我怎么知道每个 MAC 地址是谁呢？这就是 ARP 协议，也就是已知 IP 地址，求 MAC 地址的协议。 ARP协议的报文格式如下: ARP协议的流程大致如下:当 A 想要与B通信时,A是知道B的IP地址的,但是不知道mac地址 A主机先是在自己的本地ARP缓存中检查主机B的匹配MAC地址。 如果主机A在ARP缓存中没有找到映射，它将询问自己所属的局域网的硬件地址，从而将ARP请求帧广播到本地网络上的所有主机。源主机A的IP地址和MAC地址都包括在ARP请求中。本地网络上的每台主机都接收到ARP请求并且检查是否与自己的IP地址匹配。如果主机发现请求的IP地址与自己的IP地址不匹配，它将丢弃ARP请求。 这里ARP协议报文头部的第一个的目标mac 为 ff ff ff ff ff ff ,这是一个广播地址,相当于在局域网里吼;ARP报文内容里的目标mac留空,就是为了找到想要的mac地址。 主机B确定ARP请求中的IP地址与自己的IP地址匹配，则将主机A的IP地址和MAC地址映射添加到本地ARP缓存 主机B将包含其MAC地址的ARP回复消息直接发送回主机A。 当主机A收到从主机B发来的ARP回复消息时，会用主机B的IP和MAC地址映射更新ARP缓存。本机缓存是有生存期的，生存期结束后，将再次重复上面的过程。主机B的MAC地址一旦确定，主机A就能向主机B发送IP通信了。 总结第一，MAC 层是用来解决多路访问的堵车问题的；第二，ARP 是通过吼的方式来寻找目标 MAC 地址的，吼完之后记住一段时间，这个叫作缓存；第三，交换机是有 MAC 地址学习能力的，学完了它就知道谁在哪儿了，不用广播了。 2. 交换机与VLAN一. 网络拓补结构的形成 两台交换机将网络划分成了三个局域网,一开始大家都不知道对方的任何信息,然后靠广播将信息群发到所以的机器中,然后找到对应的MAC地址,交换机有学习功能,他就知道了该机器所在的局域网,下次广播就不会发送到其他的局域网,就这样慢慢形成了拓补结构。 二. 拓补结构中的环路问题 机器 1 的广播包到达交换机 A 和交换机 B 的时候，本来两个交换机都学会了机器 1 是在局域网一的，但是当交换机 A 将包广播到局域网二之后，交换机 B 右边的网口收到了来自交换机 A 的广播包。根据学习机制，这彻底损坏了交换机 B 的三观，刚才机器 1 还在左边的网口呢，怎么又出现在右边的网口呢？哦，那肯定是机器 1 换位置了，于是就误会了，交换机 B 就学会了，机器 1 是从右边这个网口来的，把刚才学习的那一条清理掉。同理，交换机 A 右边的网口，也能收到交换机 B 转发过来的广播包，同样也误会了，于是也学会了，机器 1 从右边的网口来，不是从左边的网口来。然而当广播包从左边的局域网一广播的时候，两个交换机再次刷新三观，原来机器 1 是在左边的，过一会儿，又发现不对，是在右边的，过一会，又发现不对，是在左边的。 STP（最小生成树）协议 将图的环破坏变成树，解决环路问题。 三. 如何解决广播问题和安全问题？如果机器多了，交换机也多了，就算交换机比 Hub 智能一些，但是还是难免有广播的问题，一大波机器，相关的部门、不相关的部门，广播一大堆，性能就下来了。而且每一个部门所接触的信息不一样，有的部门信息可能比较敏感，不希望别的部门接收到这个包。 两个隔离的方法： 一个是物理隔离。每个部门设一个单独的会议室，对应到网络方面，就是每个部门有单独的交换机，配置单独的子网，这样部门之间的沟通就需要路由器了。这样的问题在于，有的部门人多，有的部门人少。人少的部门慢慢人会变多，人多的部门也可能人越变越少。如果每个部门有单独的交换机，口多了浪费，少了又不够用。 另外一种方式是虚拟隔离，就是用我们常说的 VLAN，或者叫虚拟局域网。使用 VLAN，一个交换机上会连属于多个局域网的机器，那交换机怎么区分哪个机器属于哪个局域网呢？ 我们只需要在原来的二层的头上加一个 TAG，里面有一个 VLAN ID，一共 12 位。12 位可以划分 4096 个 VLAN。 如果我们买的交换机是支持 VLAN 的，当这个交换机把二层的头取下来的时候，就能够识别这个 VLAN ID。这样只有相同 VLAN 的包，才会互相转发，不同 VLAN 的包，是看不到的。这样广播问题和安全问题就都能够解决了。 将两个交换机连接起来的口应该设置成什么 VLAN 呢？对于支持 VLAN 的交换机，有一种口叫作 Trunk 口。它可以转发属于任何 VLAN 的口。交换机之间可以通过这种口相互连接。 总结 当交换机的数目越来越多的时候，会遭遇环路问题，让网络包迷路，这就需要使用 STP 协议，将有环路的图变成没有环路的树，从而解决环路问题。但是STP 对于跨地域甚至跨国组织的网络支持，就很难做了，计算量太大。 交换机数目多会面临隔离问题，可以通过 VLAN 形成虚拟局域网，从而解决广播问题和安全问题。 3. ICMP与ping一. ICMP 协议的格式ping 是基于 ICMP 协议工作的。ICMP 全称 Internet Control Message Protocol，就是互联网控制报文协议。这里面的关键词是“控制”，那具体是怎么控制的呢？ 网络包在异常复杂的网络环境中传输时，常常会遇到各种各样的问题。当遇到问题的时候，总不能“不明不白”，要传出消息来，报告情况，这样才可以调整传输策略。ICMP就是相当于这个侦察兵。 ICMP 报文是封装在 IP 包里面的。因为传输指令的时候，肯定需要源地址和目标地址。它本身非常简单。因为作为侦查兵，要轻装上阵，不能携带大量的包袱。 ICMP 报文有很多的类型，不同的类型有不同的代码。最常用的类型是主动请求为 8，主动请求的应答为 0。 1. 查询报文类型 这种主动发起的，主动查看敌情，对应 ICMP 的查询报文类型。例如，常用的 ping 就是查询报文，是一种主动请求，并且获得主动应答的 ICMP 协议。所以，ping 发的包也是符合 ICMP 协议格式的，只不过它在后面增加了自己的格式。对 ping 的主动请求，进行网络抓包，称为 ICMP ECHO REQUEST。同理主动请求的回复，称为ICMP ECHO REPLY。比起原生的 ICMP，这里面多了两个字段，一个是标识符。这要用标识侦查的对象是什么，另一个是序号，用来确认回收包的情况，如果派出去 10 个，回来 10 个，就说明前方战况不错；如果派出去 10 个，回来 2 个，说明情况可能不妙。在选项数据中，ping 还会存放发送请求的时间值，来计算往返时间，说明路程的长短。 2. 差错报文类型这种是异常情况发起的，来报告发生了不好的事情，对应 ICMP 的差错报文类型。几个 ICMP 差错报文的例子：终点不可达为 3，源抑制为 4，超时为 11，重定向为 5。 终点不可达: 具体的原因在代码中表示就是，网络不可达代码为 0，主机不可达代码为 1，协议不可达代码为 2，端口不可达代码为 3，需要进行分片但设置了不分片位代码为 4。 第二种是源站抑制，也就是让源站放慢发送速度。 第三种是时间超时，也就是超过网络包的生存时间还是没到。 第四种是路由重定向，也就是让下次发给另一个路由器。 差错报文的结构相对复杂一些。除了前面还是 IP，ICMP 的前 8 字节不变，后面则跟上出错的那个 IP 包的 IP 头和 IP 正文的前 8 个字节。 二. ping：查询报文类型的使用 ping 命令执行的时候，源主机首先会构建一个 ICMP 请求数据包，ICMP 数据包内包含多个字段。最重要的是两个，第一个是类型字段，对于请求数据包而言该字段为 8；另外一个是顺序号，主要用于区分连续 ping 的时候发出的多个数据包。每发出一个请求数据包，顺序号会自动加 1。为了能够计算往返时间 RTT，它会在报文的数据部分插入发送时间。 由 ICMP 协议将这个数据包连同对方的IP地址 一起交给 IP 层。IP 层将以对方的IP地址作为目的地址，本机 IP 地址作为源地址，加上一些其他控制信息，构建一个 IP 数据包。 接下来，需要加入 MAC 头。如果在本节 ARP 映射表中查找出 对方的IP 地址 所对应的 MAC 地址，则可以直接使用；如果没有，则需要发送 ARP 协议查询 MAC 地址，获得 MAC 地址后，由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。 对方主机收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。 对方主机会构建一个 ICMP 应答包，应答数据包的类型字段为 0，顺序号为接收到的请求数据包中的顺序号，然后再发送出去给源主机。 在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 应答包，则说明目标主机可达。此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。 如果跨网段的话，还会涉及网关的转发、路由器的转发等等。但是对于 ICMP 的头来讲，是没什么影响的。会影响的是根据目标 IP 地址，选择路由的下一跳，还有每经过一个路由器到达一个新的局域网，需要换 MAC 头里面的 MAC 地址。 经常会遇到一个问题，如果不在我们的控制范围内，很多中间设备都是禁止 ping 的，但是 ping 不通不代表网络不通。这个时候就要使用 telnet，通过其他协议来测试网络是否通。 三. Traceroute：差错报文类型的使用Traceroute，会使用 ICMP 的规则，故意制造一些能够产生错误的场景。 1。 Traceroute 的第一个作用就是故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。Traceroute 的参数指向某个目的 IP 地址，它会发送一个 UDP 的数据包。将 TTL 设置成 1，也就是说一旦遇到一个路由器或者一个关卡。如果他“牺牲”了，就返回一个 ICMP 包，也就是网络差错包，类型是时间超时。这时候就知道达到目标IP的路径不值隔了一个路由，然后把TTL 设置成 2，如此反复，直到到达目的主机。这样，Traceroute 就拿到了所有的路由器 IP。当然，有的路由器压根不会回这个 ICMP。这也是 Traceroute 一个公网的地址，看不到中间路由的原因。 怎么知道 UDP 有没有到达目的主机呢？Traceroute 程序会发送一份 UDP 数据报给目的主机，但它会选择一个不可能的值作为 UDP 端口号（大于 30000）。当该数据报到达时，将使目的主机的 UDP 模块产生一份“端口不可达”错误 ICMP 报文。如果数据报没有到达，则可能是超时。 2. Traceroute 还有一个作用是故意设置不分片，从而确定路径的 MTU。要做的工作首先是发送分组，并设置“不分片”标志。发送的第一个分组的长度正好与出口 MTU 相等。如果中间遇到窄的关口会被卡住，会发送 ICMP 网络差错包，类型为“需要进行分片但设置了不分片位”。其实，这是人家故意的好吧，每次收到 ICMP“不能分片”差错时就减小分组的长度，直到到达目标主机。 总结 ICMP 相当于网络世界的侦察兵。 两种类型的 ICMP 报文，一种是主动探查的查询报文，一种异常报告的差错报文； ping 使用查询报文，Traceroute 使用差错报文。 不应发送ICMP差错报文的几种情况： 对ICMP差错报文，不再发送ICMP差错报告报文。 对第一个分片的数据报片的所有后续数据报片，都不发送ICMP差错报告报文 对具有多播地址的数据报，都不发送ICMP差错报告报文 对具有特殊地址（如127.0.0.0或0.0.0.0）的数据报，不发送ICMP差错报告报文 tracerouter发udp，为啥出错回icmp？ICMP一般认为属于网络层的，和IP同一层，是管理和控制IP的一种协议，而UDP和TCP是传输层，所以UDP出错可以返回ICMP差错报文。正常情况下，协议栈能正常走到udp，当然正常返回udp。但是，你主机不可达，是ip层的（还没到udp）。ip层，当然只知道回icmp。报文分片错误也是同理。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://liangweijiang.github.io/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://liangweijiang.github.io/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"}]},{"title":"学习笔记之---restful架构","slug":"restful","date":"2020-03-14T13:19:05.357Z","updated":"2020-03-14T13:20:50.713Z","comments":true,"path":"2020/03/14/restful/","link":"","permalink":"https://liangweijiang.github.io/2020/03/14/restful/","excerpt":"","text":"详解restful架构1. web服务我们在浏览器中能看到的每个网站，都是一个web服务。这种”互联网软件”采用客户端/服务器模式，建立在分布式体系上，通过互联网通信，具有高延时（high latency）、高并发等特点。网站开发，完全可以采用软件开发的模式。但是传统上，软件和网络是两个不同的领域，很少有交集；软件开发主要针对单机环境，网络则主要研究系统之间的通信。互联网的兴起，使得这两个领域开始融合，现在我们必须考虑，如何开发在互联网环境中使用的软件。 目前主流的三种web服务交互方案： – REST （ Representational State Transfer）表述性状态转移 – SOAP （Simple Object Access Protocol） 简单的对象访问协议 – XML-RPC （XML Remote Procedure Call）基于XML的远程过程调用 XML-RPC是通过XML将调用函数封装，并使用HTTP协议作为传送机制。后来在新的功能不断被引入下，这个标准慢慢演变成为今日的SOAP协定。SOAP服务则是以本身所定义的操作集，来访问网络上的资源。SOAP也是基于XML的，但是它不只限于HTTP协议的传输，包括TCP协议，UDP协议都可以传输。REST相比SOAP更加简洁，性能和开发效率也有突出的优势。 2. restful架构的历史REST这个词，全称是Representational State Transfer，中文意思是表述（编者注：通常译为表征）性状态转移，是Roy Thomas Fielding在他2000年的博士论文中提出的。Fielding是一个非常重要的人，他是HTTP协议（1.0版和1.1版）的主要设计者、Apache服务器软件的作者之一、Apache基金会的第一任主席。所以，他的这篇论文一经发表，就引起了关注，并且立即对互联网开发产生了深远的影响。他在论文中提到：”我这篇文章的写作目的，就是想在符合架构原理的前提下，理解和评估以网络为基础的应用软件的架构设计，得到一个功能强、性能好、适宜通信的架构。REST指的是一组架构约束条件和原则。” 如果一个架构符合REST的约束条件和原则，我们就称它为RESTful架构。 REST本身并没有创造新的技术、组件或服务，而隐藏在RESTful背后的理念就是使用Web的现有特征和能力， 更好地使用现有Web标准中的一些准则和约束。虽然REST本身受Web技术的影响很深， 但是理论上REST架构风格并不是绑定在HTTP上，只不过目前HTTP是唯一与REST相关的实例。 所以我们这里描述的REST也是通过HTTP实现的REST。 3. 理解restful3.1 什么是资源REST全称是表述性状态转移，那究竟指的是什么的表述? 其实指的就是资源。所谓”资源”，就是网络上的一个实体，或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲、一种服务，总之就是一个具体的实在。任何事物，只要有被引用到的必要，它就是一个资源。那么在我们的网络中，我们要引用资源，资源一定要有一个标识，在web中的唯一标识就是URI（统一资源定位符），URI我们不常听说，我们经常用URL，那么两者区别是什么 什么是URI，URL？ URI 统一资源标志符。 URL 统一资源定位符。 URI是给我们的资源进行标识的，URL是描述我们资源地址的。比如说我们每个人都有名字和身份证，名字可能重名，但是身份证是唯一的，那么身份证号就可以是我们的URI，标识我们每个人，也可以说标识我们每个资源。我们可以通过身份证号找到这个人，也可以通过地址找到他，这个就是我们的URL，我们通过这两种方式都可以找到我们的资源， 其实我们的URL可以说是URI的子集，通过定位的方式实现的URI。 3.2 统一资源接口现在我们可以通过URL去访问到资源，那么我们对资源会有很多不同的操作，增删改查，以前我们可能会为了这个增加新设计一个URL，然后这个URL就是对数据进行增加的，还会为了更新和删除分别设计一个URL，现在我们不用了，我们只有一个URL，然后根据HTTP请求方式的不同，对资源进行不同的操作，这个就是是统一资源接口。我们一定要遵循HTTP请求方法的语义，也就是说POST请求就在新增数据等…. RESTful架构应该遵循统一接口原则，统一接口包含了一组受限的预定义的操作，不论什么样的资源，都是通过使用相同的接口进行资源的访问。接口应该使用标准的HTTP方法如GET，PUT和POST，并遵循这些方法的语义。如果按照HTTP方法的语义来暴露资源，那么接口将会拥有安全性和幂等性的特性，例如GET和HEAD请求都是安全的， 无论请求多少次，都不会改变服务器状态。而GET、HEAD、PUT和DELETE请求都是幂等的，无论对资源操作多少次， 结果总是一样的，后面的请求并不会产生比第一次更多的影响。 下面列出了GET，DELETE，PUT和POST的典型用法: GET 安全且幂等 获取表示 变更时获取表示（缓存） 200（OK） - 表示已在响应中发出 204（无内容） - 资源有空表示 301（Moved Permanently） - 资源的URI已被更新 303（See Other） - 其他（如，负载均衡） 304（not modified）- 资源未更改（缓存） 400 （bad request）- 指代坏请求（如，参数错误） 404 （not found）- 资源不存在 406 （not acceptable）- 服务端不支持所需表示 500 （internal server error）- 通用错误响应 503 （Service Unavailable）- 服务端当前无法处理请求 POST 不安全且不幂等 使用服务端管理的（自动产生）的实例号创建资源 创建子资源 部分更新资源 如果没有被修改，则不过更新资源（乐观锁） 200（OK）- 如果现有资源已被更改 201（created）- 如果新资源被创建 202（accepted）- 已接受处理请求但尚未完成（异步处理） 301（Moved Permanently）- 资源的URI被更新 303（See Other）- 其他（如，负载均衡） 400（bad request）- 指代坏请求 404 （not found）- 资源不存在 406 （not acceptable）- 服务端不支持所需表示 409 （conflict）- 通用冲突 412 （Precondition Failed）- 前置条件失败（如执行条件更新时的冲突） 415 （unsupported media type）- 接受到的表示不受支持 500 （internal server error）- 通用错误响应 503 （Service Unavailable）- 服务当前无法处理请求 PUT 不安全但幂等 用客户端管理的实例号创建一个资源 通过替换的方式更新资源 如果未被修改，则更新资源（乐观锁） 200 （OK）- 如果已存在资源被更改 201 （created）- 如果新资源被创建 301（Moved Permanently）- 资源的URI已更改 303 （See Other）- 其他（如，负载均衡） 400 （bad request）- 指代坏请求 404 （not found）- 资源不存在 406 （not acceptable）- 服务端不支持所需表示 409 （conflict）- 通用冲突 412 （Precondition Failed）- 前置条件失败（如执行条件更新时的冲突） 415 （unsupported media type）- 接受到的表示不受支持 500 （internal server error）- 通用错误响应 503 （Service Unavailable）- 服务当前无法处理请求 DELETE 不安全但幂等 删除资源 200 （OK）- 资源已被删除 301 （Moved Permanently）- 资源的URI已更改 303 （See Other）- 其他，如负载均衡 400 （bad request）- 指代坏请求 404 （not found）- 资源不存在 409 （conflict）- 通用冲突 500 （internal server error）- 通用错误响应 503 （Service Unavailable）- 服务端当前无法处理请求 3.3 资源的表述资源的表述其实就是资源的展现形式，我们客户端和服务端传输的都是资源的表述，而不是资源本身。例如文本资源可以采用html、xml、json等格式，图片可以使用PNG或JPG展现出来。资源的表述包括数据和描述数据的元数据，例如，HTTP头”Content-Type” 就是这样一个元数据属性。那么客户端如何知道服务端提供哪种表述形式呢?可以通过HTTP内容协商，客户端可以通过Accept头请求一种特定格式的表述，服务端则通过Content-Type告诉客户端资源的表述形式。这些资源的表述呈现在页面上，就是我们说的资源状态。 3.4 状态转移我们在看页面的时候，从当前资源的表述(也可以说状态或者表现层)会跳转到其他的资源状态。服务端通过超媒体告诉客户端当前状态有哪些后续状态可以进入。这些类似”下一页”之类的链接起的就是这种推进状态的作用——指引你如何从当前状态进入下一个可能的状态。互联网通信协议HTTP协议，是一个无状态协议。这意味着，所有的状态都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生”状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是”表现层状态转化”。客户端用到的手段，只能是HTTP协议。具体来说，就是HTTP协议里面，四个表示操作方式的动词：GET、POST、PUT、DELETE。它们分别对应四种基本操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源。 3.5 总结可以得知REST风格的特点如下： 在web中，只要有被引用的必要都叫资源。 每个URI代表一个资源，独一无二的。 客户端通过HTTP的方法，对服务器端资源进行操作； 客户端和服务器之间，传递这种资源的某种表现层； 通过超链接的指引，实现”表现层状态转移”。 4. restful规范一 、面向资源编程 每个URL代表一种资源，URL中尽量不要用动词，要用名词。 二 、根据method不同，进行不同的操作 GET : 用来获取资源 POST : 用来新建资源（也可以用于更新资源） PUT : 用来更新资源 DELETE : 用来删除资源 PATCH : 用来局部更新资源 三 、在URL中体现版本 https://www.bootcss.com/v1/mycss https://v1.bootcss.com/mycss 四 、在URL中体现是否是API https://www.bootcss.com/api/mycss https://api.bootcss.com/mycss 五 、在URL中的过滤条件https://www.bootcss.com/v1/mycss？page=3 六 、尽量使用HTTPShttps://www.bootcss.com/v1/mycss 七 、响应时设置状态码 1** 信息，服务器收到请求，需要请求者继续执行操作 2** 成功，操作被成功接收并处理 3** 重定向，需要进一步的操作以完成请求 4** 客户端错误，请求包含语法错误或无法完成请求 5** 服务器错误，服务器在处理请求的过程中发生了错误 八 、返回值 GET请求 返回查到所有或单条数据 POST请求 返回新增的数据 PUT请求 返回更新数据 PATCH请求 局部更新 返回更新整条数据 DELETE请求 返回值为空 九 、返回错误信息返回值携带错误信息 十 、Hypermedia API如果遇到需要跳转的情况 携带调转接口的URL ret = { code: 100, data: { id: 1, name: &apos;小明&apos;, depart_id: &apos;http://www.baidu.com/api/v1/depart/4/&apos; } }参考文章理解RESTful架构 RESTful RESTful 架构详解","categories":[{"name":"随笔","slug":"随笔","permalink":"https://liangweijiang.github.io/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://liangweijiang.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"学习笔记之---七层网络协议和四层网络协议的区别","slug":"osi--tcp","date":"2020-03-14T09:11:21.531Z","updated":"2020-03-14T13:31:43.080Z","comments":true,"path":"2020/03/14/osi--tcp/","link":"","permalink":"https://liangweijiang.github.io/2020/03/14/osi--tcp/","excerpt":"","text":"浅谈七层网络协议和四层网络协议的区别1.OSI七层网络模型介绍 OSI（Open System Interconnection，开放系统互连）七层网络模型称为开放式系统互联参考模型 ，是一个逻辑上的定义，一个规范，它把网络从逻辑上分为了7层。每一层都有相关、相对应的物理设备，比如路由器，交换机。 OSI七层模型是一种框架性的设计方法，建立七层模型的主要目的是为解决异种网络互连时所遇到的兼容性问题，其最主要的功能就是帮助不同类型的主机实现数据传输。它的最大优点是将服务、接口和协议这三个概念明确地区分开来，通过七个层次化的结构模型使不同的系统不同的网络之间实现可靠的通讯。 七层模型的结构如下: 各层简介： 物理层（Physical Layer）：主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。它的主要作用是传输比特流（就是由1、0转化为电流强弱来进行传输,到达目的地后在转化为1、0，也就是我们常说的数模转换与模数转换），这一层的数据叫做比特，单位是bit比特。 数据链路层（Datalink Layer）：定义了如何让格式化数据以进行传输，以及如何让控制对物理介质的访问，这一层通常还提供错误检测和纠正，以确保数据的可靠传输。交换机(二层)、网桥设备在这一层。数据链路层协议的代表包括：PPP、STP、帧中继等。 网络层（Network Layer）：在位于不同地理位置的网络中的两个主机系统之间提供连接和路径选择，Internet的发展使得从世界各站点访问信息的用户数大大增加，而网络层正是管理这种连接的层。网络层负责在源机器和目标机器之间建立它们所使用的路由。路由器在该层。协议有：IP、ICMP（互联网控制报文协议）、ARP（地址转换协议）、RARP（反向地址转换协议） 传输层（Transport Layer）：O S I 模型中最重要的一层。定义了一些传输数据的协议和端口号（WWW端口80等），如：TCP（传输控制协议，传输效率低，可靠性强，用于传输可靠性要求高，数据量大的数据），UDP（用户数据报协议，与TCP特性恰恰相反，用于传输可靠性要求不高，数据量小的数据，如QQ聊天数据就是通过这种方式传输的）， 主要是将从下层接收的数据进行分段和传输，到达目的地址后再进行重组，常常把这一层数据叫做段。传输协议同时进行流量控制或是基于接收方可接收数据的快慢程度规定适当的发送速率。除此之外，传输层按照网络能处理的最大尺寸将较长的数据包进行强制分割。例如，以太网无法接收大于1 5 0 0 字节的数据包。发送方节点的传输层将数据分割成较小的数据片，同时对每一数据片安排一序列号，以便数据到达接收方节点的传输层时，能以正确的顺序重组。该过程即被称为排序。 会话层（Session Layer）：负责在网络中的两节点之间建立、维持和终止通信。 会话层的功能包括：建立通信链接，保持会话过程通信链接的畅通，同步两个节点之间的对话，决定通信是否被中断以及通信中断时决定从何处重新发送。通过传输层（端口号：传输端口与接收端口）建立数据传输的通路，主要在你的系统之间发起会话或者接受会话请求（设备之间需要互相认识可以是IP也可以是MAC或者是主机名）。 表示层（Presentation Layer）：应用程序和网络之间的翻译官，在表示层，数据将按照网络能理解的方案进行格式化；这种格式化也因所使用网络的类型不同而不同。 表示层管理数据的解密与加密，如系统口令的处理。可确保一个系统的应用层所发送的信息可以被另一个系统的应用层读取。例如，PC程序与另一台计算机进行通信，其中一台计算机使用扩展二一十进制交换码（EBCDIC），而另一台则使用美国信息交换标准码（ASCII）来表示相同的字符。如有必要，表示层会通过使用一种通格式来实现多种数据格式之间的转换。 应用层（Application Layer）： 是最靠近用户的OSI层，这一层为用户的应用程序（例如电子邮件、文件传输和终端仿真）提供网络服务。 2. TCP/IP四层网络模型介绍TCP/IP协议栈是美国国防部高级研究计划局计算机网（Advanced Research Projects Agency Network，ARPANET）和其后继因特网使用的参考模型。ARPANET是由美国国防部（U.S．Department of Defense，DoD）赞助的研究网络。最初，它只连接了美国境内的四所大学。随后的几年中，它通过租用的电话线连接了数百所大学和政府部门。最终ARPANET发展成为全球规模最大的互连网络-因特网。最初的ARPANET于1990年永久性地关闭。 TCP/IP是一组协议的代名词，它还包括许多协议，组成了TCP/IP协议簇。TCP/IP协议簇分为四层，IP位于协议簇的第二层(对应OSI的第三层)，TCP位于协议簇的第三层(对应OSI的第四层)。TCP/IP通讯协议采用了4层的层级结构，每一层都呼叫它的下一层所提供的网络来完成自己的需求。这4层分别为： 各层简介： 应用层：应用程序间沟通的层，如简单电子邮件传输（SMTP）、文件传输协议（FTP）、网络远程访问协议（Telnet）等。 传输层：在此层中，它提供了节点间的数据传送服务，如传输控制协议（TCP）、用户数据报协议（UDP）等，TCP和UDP给数据包加入传输数据并把它传输到下一层中，这一层负责传送数据，并且确定数据已被送达并接收。 网络层：负责提供基本的数据封包传送功能，让每一块数据包都能够到达目的主机（但不检查是否被正确接收），如网际协议（IP）。 网络接口层：对实际的网络媒体的管理，定义如何使用实际网络（如Ethernet、Serial Line等）来传送数据。 3. OSI七层和TCP/IP四层的关系 其实在应用、表示和会话这三层之间的协议可共用（由于实际的网络协议将它们归了一类所致） 4. OSI七层和TCP/IP四层的区别 OSI引入了服务、接口、协议、分层的概念，TCP/IP借鉴了OSI的这些概念建立TCP/IP模型。 OSI先有模型，后有协议，先有标准，后进行实践；而TCP/IP则相反，先有协议和应用再提出了模型，且是参照的OSI模型。 OSI是一种理论下的模型，而TCP/IP已被广泛使用，成为网络互联事实上的标准。 除了层的数量之外，开放式系统互联（OSI）模型与TCP/IP协议有什么区别？ 开放式系统互联模型是一个参考标准，解释协议相互之间应该如何相互作用。TCP/IP协议是美国国防部发明的，是让互联网成为了目前这个样子的标准之一。开放式系统互联模型中没有清楚地描绘TCP/IP协议，但是在解释TCP/IP协议时很容易想到开放式系统互联模型。两者的主要区别如下： TCP/IP协议中的应用层处理开放式系统互联模型中的第五层、第六层和第七层的功能。 TCP/IP协议中的传输层并不能总是保证在传输层可靠地传输数据包，而开放式系统互联模型可以做到。这是因为TCP/IP协议还提供一项名为UDP（用户数据报协议）的选择。UDP不能保证可靠的数据包传输。 参考文章网络OSI七层架构与TCP四层架构的应用与区别 详谈OSI七层网络协议和TCP/IP协议 七层协议和四层协议","categories":[{"name":"随笔","slug":"随笔","permalink":"https://liangweijiang.github.io/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://liangweijiang.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"每日一道算法之--最小栈","slug":"algorithm-155","date":"2020-03-14T04:36:34.607Z","updated":"2020-03-14T04:37:37.764Z","comments":true,"path":"2020/03/14/algorithm-155/","link":"","permalink":"https://liangweijiang.github.io/2020/03/14/algorithm-155/","excerpt":"","text":"最小栈力扣第155题 : https://leetcode-cn.com/problems/min-stack/ 设计一个支持 push，pop，top 操作，并能在常数时间内检索到最小元素的栈。 push(x) – 将元素 x 推入栈中。pop() – 删除栈顶的元素。top() – 获取栈顶元素。getMin() – 检索栈中的最小元素。示例: MinStack minStack = new MinStack();minStack.push(-2);minStack.push(0);minStack.push(-3);minStack.getMin(); –&gt; 返回 -3.minStack.pop();minStack.top(); –&gt; 返回 0.minStack.getMin(); –&gt; 返回 -2. 最开始的思路当我看到这道题的时候,因为是求最小的元素,所以我只用了一个变量,想要动态的更新最小值。但是有一个问题就出现了，当我把最小值pop出来后，当前的最小值就又会发生变化了，所以用变量保存最小值不是一个理想的解法。我又想到了再用一个数组来保存最小的的变化信息，当pop的时候在更新最小值。 12345678910111213141516171819202122232425class MinStack: def __init__(self): self.stack = [] self.min_ele = float('inf') self.min_list = [] def push(self, x: int) -&gt; None: self.stack.append(x) self.min_ele = min(self.min_ele, x) if self.min_ele not in self.min_list: self.min_list.append(self.min_ele) def pop(self) -&gt; None: pop_ele = self.stack.pop() if self.min_ele == pop_ele and pop_ele not in self.stack: self.min_list.pop() if self.min_list: self.min_ele = self.min_list[-1] def top(self) -&gt; int: if self.stack: return self.stack[-1] def getMin(self) -&gt; int: return self.min_ele 虽然没通过,但是辅助栈的雏形已经出来了 1. 同步的辅助栈 上面的代码其实存储最小值的变量是没必要的,因为最小值已经存储在辅助栈里面了 当我们在push入栈的时候,同时将该数和辅助栈的栈顶元素比较大小,如果小于栈顶元素,则最小值为该元素,将该元素push入辅助栈中;如果大于栈顶元素,则证明最小值仍为栈顶元素 从而实现了主栈和辅助栈永远是同步的,即长度一样,级主栈中每一个元素对应的栈中最小值是正确的. 123456789101112131415161718192021222324252627282930class MinStack: def __init__(self): \"\"\" initialize your data structure here. \"\"\" self.stack = [] self.min_stack = [] def push(self, x: int) -&gt; None: self.stack.append(x) # 主要逻辑就是在这里 if not self.min_stack or self.min_stack[-1] &gt; x: self.min_stack.append(x) else: self.min_stack.append(self.min_stack[-1]) def pop(self) -&gt; None: if self.stack: self.stack.pop() self.min_stack.pop() def top(self) -&gt; int: if self.stack: return self.stack[-1] def getMin(self) -&gt; int: if self.min_stack: return self.min_stack[-1] 1.1 复杂度分析时间复杂度：，“出栈”、“入栈”、“查看栈顶元素”的操作不论数据规模多大，都只是有限个步骤，因此时间复杂度是：O(1)。 空间复杂度：O(N)，这里 N 是读出的数据的个数。 2. 不同步的辅助栈同步辅助栈虽然很好理解,但是有一个问题就是它为了保持长度跟主栈一样,从而造成了没必要的浪费,所以这里讲一下不同步的辅助栈。 不同步辅助栈就是只有在push时该数小于或等于辅助栈的栈顶元素是才push入辅助栈 在pop元素之，如果该元素等于辅助栈的栈顶元素，则将辅助栈的栈顶元素pop出来 12345678910111213141516171819202122232425262728class MinStack: def __init__(self): \"\"\" initialize your data structure here. \"\"\" self.stack = [] self.min_stack = [] def push(self, x: int) -&gt; None: self.stack.append(x) if not self.min_stack or self.min_stack[-1] &gt;= x: self.min_stack.append(x) def pop(self) -&gt; None: if self.stack: top = self.stack.pop() if self.min_stack and top == self.min_stack[-1]: self.min_stack.pop() def top(self) -&gt; int: if self.stack: return self.stack[-1] def getMin(self) -&gt; int: if self.min_stack: return self.min_stack[-1] 2.1 复杂度分析时间复杂度：，“出栈”、“入栈”、“查看栈顶元素”的操作不论数据规模多大，都只是有限个步骤，因此时间复杂度是：O(1)。 空间复杂度：O(N)，这里 N 是读出的数据的个数 相似题目最大栈 滑动窗口最大值","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"栈","slug":"栈","permalink":"https://liangweijiang.github.io/tags/%E6%A0%88/"}]},{"title":"学习笔记之---堆和栈的区别","slug":"stack-heap","date":"2020-03-13T15:51:37.404Z","updated":"2020-03-15T03:48:02.075Z","comments":true,"path":"2020/03/13/stack-heap/","link":"","permalink":"https://liangweijiang.github.io/2020/03/13/stack-heap/","excerpt":"","text":"浅谈堆和栈的区别1. 数据结构中的堆栈相信每一个程序员对数据结构中的堆和栈都不陌生,他们在我们计算机的数据结构中承担着不可或缺的角色。其实堆和栈都是一种数据项按序排列的数据结构。 1.1 栈就像一摞叠在一起的盘子我们平时放盘子的时候，都是从下往上一个一个放；取的时候，我们也是从上往下一个一个地依次取，不能从中间任意抽出。后进者先出，先进者后出，这就是典型的“栈”结构。从栈的操作特性上来看，栈是一种“操作受限”的线性表，只允许在一端插入和删除数据。 1.2 堆就像一颗倒过来的数堆是一种经过排序的树形数据结构，每个结点都有一个值。通常我们所说的堆的数据结构，是指二叉堆。堆是一种特殊的树。只要满足这两点，它就是一个堆。 堆是一个完全二叉树； 堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值。 由于堆的这个特性，常用来实现优先队列，堆的存取是随意，这就如同我们在图书馆的书架上取书，虽然书的摆放是有顺序的，但是我们想取任意一本时不必像栈一样，先取出前面所有的书，书架这种机制不同于箱子，我们可以直接取出我们想要的书。 2. 内存分配中的堆栈一个由c/C++编译的程序占用的内存分为以下几个区: 栈区：存放函数的参数值、局部变量等，由编译器自动分配和释放，通常在函数执行完后就释放了，其操作方式类似于数据结构中的栈。栈内存分配运算内置于CPU的指令集，效率很高，但是分配的内存量有限，比如iOS中栈区的大小是2M。 堆区：就是通过new、malloc、realloc分配的内存块，编译器不会负责它们的释放工作，需要用程序区释放。分配方式类似于数据结构中的链表。在iOS开发中所说的“内存泄漏”说的就是堆区的内存。 静态区：全局变量和静态变量（在iOS中就是用static修饰的局部变量或者是全局全局变量）的存储是放在一块的，初始化的全局变量和静态变量在一块区域，未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。程序结束后，由系统释放。 常量区：常量存储在这里，不允许修改。 代码区：存放函数体的二进制代码。 2.1 内存分配中堆和栈的区别1. 申请方式和回收方式不同 栈(stack):栈空间的内存是由系统自动分配，一般存放局部变量，比如对象的地址等值，例如，声明在函数中一个局部变量 int b; 系统自动在栈中为b开辟空间。不需要程序员对这块内存进行管理，比如，函数中的局部变量的作用范围（生命周期）就是在调完这个函数之后就结束了。这些在系统层面都已经限定住了，程序员只需要在这种约束下进行程序编程就好，根本就没有把这块内存的管理权给到程序员，肯定也就不存在让程序员管理一说。 堆(heap):需要程序员自己申请，并指明大小，在c中malloc函数如 p1 = (char *)malloc(10);在C++中用new运算符如 p2 = (char *)malloc(10); 但是注意p1、p2本身是在栈中的。堆空间的内存是动态分配的，一般存放对象，并且需要手动释放内存。当然，iOS引入了ARC（自动引用计数管理技术）之后，程序员就不需要用代码管理对象的内存了，之前MRC（手动管理内存）的时候，程序员需要手动release对象。另外，ARC只是一种中间层的技术，虽然在ARC模式下，程序员不需要像之前那么麻烦管理内存，但是需要遵循ARC技术的规范操作，比如使用属性限定符weak、strong、assigen等。因此，如果程序员没有按ARC的规则并合理的使用这些属性限定符的话，同样是会造成内存泄漏的。 由于栈上的空间是自动分配自动回收的，所以栈上的数据的生存周期只是在函数的运行过程中，运行后就释放掉，不可以再访问。而堆上的数据只要程序员不释放空间，就一直可以访问到，不过缺点是一旦忘记释放会造成内存泄露。 2. 申请后系统的响应 栈：只要栈的剩余空间大于所申请空间，系统将为程序提供内存，否则将报异常提示栈溢出。 堆：首先应该知道操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时，会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点的空间分配给程序，另外，对于大多数系统，会在这块内存空间中的首地址处记录本次分配的大小，这样，代码中的delete语句才能正确的释放本内存空间。另外，由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动的将多余的那部分重新放入空闲链表中。 3. 申请大小的限制 栈：在Windows下,栈是向低地址扩展的数据结构，是一块连续的内存的区域。这句话的意思是栈顶的地址和栈的最大容量是系统预先规定好的，在WINDOWS下，栈的大小是2M（也有的说是1M，总之是一个编译时就确定的常数），如果申请的空间超过栈的剩余空间时，将提示overflow。因此，能从栈获得的空间较小。 堆：堆是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。 4. 申请效率的比较： 栈由系统自动分配，速度较快。但程序员是无法控制的。 堆是由new分配的内存，一般速度比较慢，而且容易产生内存碎片,不过用起来最方便. 另外，在WINDOWS下，最好的方式是用VirtualAlloc分配内存，他不是在堆，也不是在栈是直接在进程的地址空间中保留一快内存，虽然用起来最不方便。但是速度快，也最灵活。 2.5 堆和栈中的存储内容 栈： 栈空间中一般存储基本数据类型，对象的地址；在函数调用时，第一个进栈的是主函数中后的下一条指令（函数调用语句的下一条可执行语句）的地址，然后是函数的各个参数，在大多数的C编译器中，参数是由右往左入栈的，然后是函数中的局部变量。注意静态变量是不入栈的。 当本次函数调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的地址，也就是主函数中的下一条指令，程序由该点继续运行。 堆：堆空间一般存放对象本身，block的copy等;一般是在堆的头部用一个字节存放堆的大小。堆中的具体内容有程序员安排。 2.6 存取效率的比较char s1[] = “aaaaaaaaaaaaaaa”;char *s2 = “bbbbbbbbbbbbbbbbb”;aaaaaaaaaaa是在运行时刻赋值的；而bbbbbbbbbbb是在编译时就确定的；但是，在以后的存取中，在栈上的数组比指针所指向的字符串(例如堆)快。比如： 123456789＃includevoid main() &#123; char a = 1; char c[] = \"1234567890\"; char *p =\"1234567890\"; a = c[1]; a = p[1]; return;&#125; 对应的汇编代码 123456710: a = c[1];00401067 8A 4D F1 mov cl,byte ptr [ebp-0Fh]0040106A 88 4D FC mov byte ptr [ebp-4],cl11: a = p[1];0040106D 8B 55 EC mov edx,dword ptr [ebp-14h]00401070 8A 42 01 mov al,byte ptr [edx+1]00401073 88 45 FC mov byte ptr [ebp-4],al 第一种在读取时直接就把字符串中的元素读到寄存器cl中，而第二种则要先把指针值读到edx中，在根据edx读取字符，显然慢了。 总结堆和栈的区别可以用如下的比喻来看出： 使用栈就象我们去饭馆里吃饭，只管点菜（发出申请）、付钱、和吃（使用），吃饱了就走，不必理会切菜、洗菜等准备工作和洗碗、刷锅等扫尾工作，他的好处是快捷，但是自由度小。 使用堆就象是自己动手做喜欢吃的菜肴，比较麻烦，但是比较符合自己的口味，而且自由 度大。 (经典！) 参考文章 堆栈的工作原理 C语言堆栈入门——堆和栈的区别 关于堆栈的讲解 堆和栈的区别是什么？","categories":[{"name":"随笔","slug":"随笔","permalink":"https://liangweijiang.github.io/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"堆栈","slug":"堆栈","permalink":"https://liangweijiang.github.io/tags/%E5%A0%86%E6%A0%88/"},{"name":"内存分配","slug":"内存分配","permalink":"https://liangweijiang.github.io/tags/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/"}]},{"title":"每日一道算法之--剪绳子","slug":"algorithm-interview-14","date":"2020-03-12T15:58:33.660Z","updated":"2020-03-12T16:00:21.071Z","comments":true,"path":"2020/03/12/algorithm-interview-14/","link":"","permalink":"https://liangweijiang.github.io/2020/03/12/algorithm-interview-14/","excerpt":"","text":"剪绳子力扣 面试题14- I :https://leetcode-cn.com/problems/jian-sheng-zi-lcof/相同题目:343. 整数拆分 给你一根长度为 n 的绳子，请把绳子剪成整数长度的 m 段（m、n都是整数，n&gt;1并且m&gt;1），每段绳子的长度记为 k[0],k[1]…k[m] 。请问 k[0]k[1]…*k[m] 可能的最大乘积是多少？例如，当绳子的长度是8时，我们把它剪成长度分别为2、3、3的三段，此时得到的最大乘积是18。 示例 1： 输入: 2输出: 1解释: 2 = 1 + 1, 1 × 1 = 1 示例 2: 输入: 10输出: 36解释: 10 = 3 + 3 + 4, 3 × 3 × 4 = 36提示： 2 &lt;= n &lt;= 58 1. 动态规划一看到这道题的时候,看到最这个字,首先我第一肯定是想到动态规划。当我们首先要判断边界，当n小于4的时候，只会有一种可能或者没有，如 n == 2时,只可能分成两段,分别为1, 1。当n大于3时，我们剪断绳子的第一刀时，可以剪1,2，.., n-1的长度,即有n-1中可能所以状态转移方程为 f(n) = max(f(i) * f(n - i)) , 其中 0&lt;i&lt;n 1234567891011121314151617class Solution: def cuttingRope(self, n: int) -&gt; int: if n &lt; 2: return 0 if n == 2: return 1 if n == 3: return 2 dp = ['' for _ in range(n + 1)] dp[0] = 0 dp[1] = 1 dp[2] = 2 dp[3] = 3 max_count = 0 for i in range(4, n + 1): # 只需要遍历到一半,因为前半部分和后半部分是一样的 for j in range(1, i //2 + 1): max_count = max(max_count, dp[j] * dp[i - j]) dp[i] = max_count return dp[n] 1.1 复杂度分析时间复杂度:当n &gt; 4时,每一个子问题(假设长度为m),他的第一刀都有m - 1中可能,所以需要两层循环,时间复杂度为$$O(n^2)$$ 空间复杂度:运用了列表的数据结构,且其大小和n有关,即空间复杂度为O(1) 2. 贪婪算法通过复杂度分析,动态规划的时间复杂度和空间复杂度都不太理想,所以我有翻了《剑指offer》里看了一种非常巧妙的方法—-贪婪算法 可以发现,只有当n == 4时,以2分割比3更佳 所以当绳子大于4时,尽可能地以3分割;如果剩下的绳子刚好等于4,则将4分割成两个2 12345678910import mathclass Solution: def cuttingRope(self, n: int) -&gt; int: if n &lt;= 3: return n - 1 count3 = n // 3 # 如果存在4,要以2分割 if n - 3 * count3 == 1: count3 -= 1 count2 = (n - count3 * 3) // 2 return int(math.pow(3, count3)* math.pow(2, count2)) 2.1 复杂度分析时间复杂度: O(1) 空间复杂度:O(1) 总结做这道题之前,我只要看到最这个字,肯定都会联想到动态规划,做了这道题之后,哎,每一种题目,都还是会有自己特定的最合适的算法,而不是dp永远都是最好的.向之前有一道题322. 零钱兑换,我一开始就是想到了贪心算法,但其实正确的解法是动态规划。而且也要动脑子,这道题其实和数学的联系很大,如果理解了规律真的不难,还是要多刷多练,踏实地学习. 类似题目171. Excel表列序号 975. 奇偶跳","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"https://liangweijiang.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"数学","slug":"数学","permalink":"https://liangweijiang.github.io/tags/%E6%95%B0%E5%AD%A6/"},{"name":"贪心算法","slug":"贪心算法","permalink":"https://liangweijiang.github.io/tags/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/"}]},{"title":"每日一道算法之--寻找旋转排序数组中的最小值","slug":"algorithm-153","date":"2020-03-11T13:02:26.632Z","updated":"2020-03-11T13:03:39.316Z","comments":true,"path":"2020/03/11/algorithm-153/","link":"","permalink":"https://liangweijiang.github.io/2020/03/11/algorithm-153/","excerpt":"","text":"寻找旋转排序数组中的最小值力扣第153题:https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array/ 假设按照升序排序的数组在预先未知的某个点上进行了旋转。 ( 例如，数组 [0,1,2,4,5,6,7] 可能变为 [4,5,6,7,0,1,2] )。 请找出其中最小的元素。 你可以假设数组中不存在重复元素。 示例 1: 输入: [3,4,5,1,2]输出: 1 示例 2: 输入: [4,5,6,7,0,1,2]输出: 0 这道题是剑指的原题的简单版,这里可以假设假设数组中不存在重复元素。找出其中最小的元素,直接遍历数组找到最小的元素不就好了吗,时间复杂度也为O(n),但是这样就和旋转数组没什么关系了,所以就算做出来了,面试也没什么效果。 二分查找思想我们知道在一个有序数组中，用二分法查找一个数，时间复杂度为O（logn），效率非常高。那么这道题也是有序数组的变形，应该也能用二分法。 可以看到，旋转数组分为了两部分，左右两部分也都是有序的 而且旋转数组的分界点，正是最小的元素 所以我们可以利用双指针，开始时分别指向数组的最前（左部分）和最后（右部分），然后去中间点，如果中间点的值比最前的点大，那么证明中间点在左部分，且最小元素在右部分，所以可以将左部分的指针指向中间点，这就是实现二分的思想。 123456789101112131415161718class Solution: def findMin(self, nums: List[int]) -&gt; int: if not nums: return -1 if len(nums) == 1: return nums[0] left, right = 0, len(nums) - 1 mid = left # 左边的元素比右边的大 while nums[left] &gt;= nums[right]: # 最小元素作为边界,即为右边区间的第一个元素 if right - left == 1: mid = right break mid = left + (right - left) //2 if nums[mid] &gt;= nums[left]: left = mid else: right = mid return nums[mid] 复杂度分析时间复杂度:二分法的时间复杂度为O(logn)空间复杂度:O(1), 没有用到额外的数据结构 相似题目33. 搜索旋转排序数组 154. 寻找旋转排序数组中的最小值 II","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"https://liangweijiang.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"二分查找","slug":"二分查找","permalink":"https://liangweijiang.github.io/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"}]},{"title":"《趣谈网络协议》学习笔记之--通信协议综述","slug":"NetworkProtocol-01","date":"2020-03-10T08:56:43.896Z","updated":"2020-03-20T07:59:32.855Z","comments":true,"path":"2020/03/10/NetworkProtocol-01/","link":"","permalink":"https://liangweijiang.github.io/2020/03/10/NetworkProtocol-01/","excerpt":"","text":"学习自极客时间《趣谈网络协议》 作者：刘超 通信协议的综述1. 为什么要学习网络协议?1.1 协议的三要素计算机语言作为程序员控制一台计算机工作的协议，具备了协议的三要素。 语法，就是这一段内容要符合一定的规则和格式。例如，括号要成对，结束要使用分号等。 语义，就是这一段内容要代表某种意义。例如数字减去数字是有意义的，数字减去文本一般来说就没有意义。 顺序，就是先干啥，后干啥。例如，可以先加上某个数值，然后再减去某个数值。会了计算机语言，你就能够教给一台计算机完成你的工作了。但是，要想打造互联网世界的通天塔，只教给一台机器做什么是不够的，你需要学会教给一大片机器做什么。这就需要网络协议。只有通过网络协议，才能使一大片机器互相协作、共同完成一件事。 1.2 HTTP协议的格式 HTTP/1.1 200 OKDate: Tue, 27 Mar 2018 16:50:26 GMTContent-Type: text/html;charset=UTF-8Content-Language: zh-CN 首先，符合语法，也就是说，只有按照上面那个格式来，浏览器才认。 例如，上来是状态，然后是首部，然后是内容。第二，符合语义，就是要按照约定的意思来。 例如，状态 200，表述的意思是网页成功返回。如果不成功，就是我们常见的“404”。 第三，符合顺序，你一点浏览器，就是发送出一个 HTTP 请求，然后才有上面那一串 HTTP 返回的东西。浏览器显然按照协议商定好的做了，最后一个五彩缤纷的页面就出现在你面前了 1.3 网络协议的种类 2. 网络分层的真实含义是什么？2.1 网络为什么要分层？ 对于软件世界来说,在计算机领域，任何问题到了某个复杂的阶段，如果当前方法不能解决问题，必定可以通过加多一层来解决，如果加多一层都解决不了问题，那肯定是这个问题模型的层次已经到极限了。 1）各层之间相互独立：高层是不需要知道底层的功能是采取硬件技术来实现的，它只需要知道通过与底层的接口就可以获得所需要的服务；2）灵活性好：各层都可以采用最适当的技术来实现，例如某一层的实现技术发生了变化，用硬件代替了软件，只要这一层的功能与接口保持不变，实现技术的变化都并不会对其他各层以及整个系统的工作产生影响； 3）易于实现和标准化：由于采取了规范的层次结构去组织网络功能与协议，因此可以将计算机网络复杂的通信过程，划分为有序的连续动作与有序的交互过程，有利于将网络复杂的通信工作过程化解为一系列可以控制和实现的功能模块，使得复杂的计算机网络系统变得易于设计，实现和标准化 在网络协议中的分层。不仅仅是根据负责的功能来简单的划分层次，而且层与层之间会有不可缺少的的封装与传递。对于网络模型各层的封装是根据整个网络模型从上到下的工作流程来划分的。但是，每层之间会有一定的联系，不是独立工作的。 2.3 程序是如何工作的？ 2.3 层与层之间联系 只要是在网络上跑的包，都是完整的。可以有下层没上层，绝对不可能有上层没下层。 所以，对 TCP 协议来说，三次握手也好，重试也好，只要想发出去包，就要有 IP 层和 MAC 层，不然是发不出去的。 3. ifconfig：最熟悉又陌生的命令行 linux上查看ip地址的命令有ifconfig和ip addr两种 3.1 ifconfig 和 ip addr 的区别这是一个有关 net-tools 和 iproute2 的“历史”故事，net-tools起源于BSD的TCP/IP工具箱，后来成为老版本Linux内核中配置网络功能的工具，但自2001年起，Linux社区已经对其停止维护。同时，一些Linux发行版比如Arch Linux和CentOS/RHEL 7则已经完全抛弃了net-tools，只支持iproute2。 作为网络配置工具的一份子，iproute2是linux下管理控制TCP/IP网络和流量控制的新一代工具包，旨在替代老派的工具链net-tools，即大家比较熟悉的ifconfig，arp，route，netstat等命令。 net-tools通过procfs(/proc)和ioctl系统调用去访问和改变内核网络配置，而iproute2则通过netlink套接字接口与内核通讯。 抛开性能而言，net-tools的用法给人的感觉是比较乱，而iproute2的用户接口相对net-tools来说相对来说，更加直观。比如，各种网络资源（如link、IP地址、路由和隧道等）均使用合适的对象抽象去定义，使得用户可使用一致的语法去管理不同的对象，更重要的是，到目前为止，iproute2仍处在持续开发中，所以，net-tools和iproute2都需要去学习掌握了。 如果你仍在使用net-tools，而且尤其需要跟上新版Linux内核中的最新最重要的网络特性的话，那么是时候转到iproute2的阵营了。原因就在于使用iproute2可以做很多net-tools无法做到的事情。 3.2 ip地址的分类linux下输入ip addr 12345678910111213root@test:~# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff inet 10.100.122.2/24 brd 10.100.122.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fec7:7975/64 scope link valid_lft forever preferred_lft forever 在 IP 地址的后面有个 scope，对于 eth0 这张网卡来讲，是 global，说明这张网卡是可以对外的，可以接收来自各个地方的包。对于 lo 来讲，是 host，说明这张网卡仅仅可以供本机相互通信。lo 全称是 loopback，又称环回接口，往往会被分配到 127.0.0.1 这个地址。这个地址用于本机通信，经过内核处理后直接返回，不会在任何网络中出现。 这个命令显示了这台机器上所有的网卡。大部分的网卡都会有一个 IP 地址，当然，这不是必须的。IP 地址是一个网卡在网络世界的通讯地址，相当于我们现实世界的门牌号码 以前人们根本想不到会有这么多的计算机,所以ip地址总共就32位,也就是我们所说的ipv4,可是ipv4很快就别分配完了,于是就出现了ipv6。 iPv4被分成了5类 这里面有个尴尬的事情，就是 C 类地址能包含的最大主机数量实在太少了，只有 254 个。当时设计的时候恐怕没想到，现在估计一个网吧都不够用吧。而 B 类地址能包含的最大主机数量又太多了。6 万多台机器放在一个网络下面，一般的企业基本达不到这个规模，闲着的地址就是浪费。 3.3 无类型域间选路（CIDR） 无类型域间选路(CIDR)基本思想是取消地址的分类结构，取而代之的是允许以可变长分界的方式分配网络数。它支持路由聚合，可限制Internet主干路由器中必要路由信息的增长。“无类型”的意思是选路决策是基于整个32位IP地址的掩码操作。而不管其IP地址是A类、B类或是C类。这样能够将路由表中的许多表项归并(summarization)成更少的数目。 伴随着 CIDR 存在的，一个是广播地址，10.100.122.255。如果发送这个地址，所有 10.100.122 网络里面的机器都可以收到。 另一个是子网掩码，255.255.255.0。将子网掩码和 IP 地址进行 AND 计算。前面三个 255，转成二进制都是 1。1 和任何数值取 AND，都是原来数值，因而前三个数不变，为 10.100.122。后面一个 0，转换成二进制是 0，0 和任何数值取 AND，都是 0，因而最后一个数变为 0，合起来就是 10.100.122.0。这就是网络号。将子网掩码和 IP 地址按位计算 AND，就可得到网络号。 3.4 公有 IP 地址和私有 IP 地址上图中可以看到私有地址的范围,私有地址就是平时我们看到的数据中心里，办公室、家里或学校的 IP 地址，一般都是私有 IP 地址段。因为这些地址允许组织内部的 IT 人员自己管理、自己分配，而且可以重复。因此，你学校的某个私有 IP 地址段和我学校的可以是一样的。就像你的小区有402号房间,我的小区也可以有402号房间,但是一旦出了小区,直接说402房间别人就找不到了。 公有 IP 地址有个组织统一分配，你需要去买。如果你搭建一个网站，给你学校的人使用，让你们学校的 IT 人员给你一个 IP 地址就行。但是假如你要做一个类似网易 163 这样的网站，就需要有公有 IP 地址，这样全世界的人才能访问。 3.5 MAC地址 MAC 地址更像是身份证，是一个唯一的标识。它的唯一性设计是为了组网的时候，不同的网卡放在一个网络里面的时候，可以不用担心冲突。从硬件角度，保证不同的网卡有不同的标识。但是光有mac地址是不够的的，就像光知道你的身份证是很难找得到你的人的，还需要你现在的居住地址（相当于ip地址） MAC地址只有很小范围的定位功能，就像大家在一个房间里，这时候大喊这个人的身份证，就会有对应的人回复你。 mac地址是唯一的，为什么可以修改?想想身份证，身份证号是唯一的，不能改变的，但是可以造价。mac地址全球唯一，它是固化在网卡里的。网卡毕竟是个硬件，需要软件支持，既操作系统识别。重点来了，操作系统识别出来的mac地址是可以更改的，它只不过是一个字符串。我们常说的修改mac指的是修改电脑中记录的既注册表中的记录。 有了mac地址为什么还要有ip地址。举个例子，身份证号是你的唯一标识，不会重复，一落户就有（网卡一出厂就有mac）。现在我要和你通信（写信给你），地址用你的姓名+身份证，信能送到你手上吗?明显不能！身份证号前六位能定位你出生的县。mac地址前几位也可以定位生产厂家。但是你出生后会离开这个县（哪怕在这个县，也不能具体找到你）。所以一般写个人信息就要有出生地和现居地址了 4. DHCP与PXE：IP是怎么来的，又是怎么没的？4.1 配置ip地址使用 net-tools： $ sudo ifconfig eth1 10.0.0.1/24$ sudo ifconfig eth1 up 使用 iproute2： $ sudo ip addr add 10.0.0.1/24 dev eth1$ sudo ip link set up eth1 但是在手动配置ip地址时,不是自由的去配置的,要考虑很多因素,如两台电脑需要通信时,源IP 地址 16.158.23.6，目标 IP 地址 192.168.1.6,因为不是同一个网卡的话,Linux 默认的逻辑是，如果这是一个跨网段的调用，它便不会直接将包发送到网络上，而是企图将包发送到网关。需要经过多次网关才能达到,如果两台电脑是相邻的,如果直接配置成同一个网段的,直接发送ARP请求,节省很多资源. 4.2 动态主机配置协议（DHCP） 概要动态主机配置协议 (DHCP) 是由 RFC 1541（已被 RFC 2131 取代）定义的标准协议，允许服务器将 IP 地址和配置信息动态分发给客户端。正常情况下，DHCP 服务器至少会为客户端提供以下基本信息： IP 地址 子网掩码 默认网关 4.2.1 DHCP 的工作方式: 这里第二步,如果有多个DHCP服务器,新的客户端会收到多个ip地址,一般选择第一个到来的,客户端仍然使用 0.0.0.0 为源 IP 地址、255.255.255.255 为目标地址进行广播。在 BOOTP 里面，接受某个 DHCP Server 的分配的 IP。 4.2.2 IP 地址的收回和续客户机会在租期过去 50% 的时候，直接向为其提供 IP 地址的 DHCP Server 发送 DHCP request 消息包。客户机接收到该服务器回应的 DHCP ACK 消息包，会根据包中所提供的新的租期以及其他已经更新的 TCP/IP 参数，更新自己的配置。这样，IP 租用更新就完成了。 4.3 PXE 的工作过程网络管理员不仅能自动分配 IP 地址，还能帮你自动安装操作系统！我们安装操作系统的过程，只能插在 BIOS 启动之后了。因为没安装系统之前，连启动扇区都没有。因而这个过程叫做预启动执行环境（Pre-boot Execution Environment），简称 PXE。PXE 协议分为客户端和服务器端，由于还没有操作系统，只能先把客户端放在 BIOS 里面。当计算机启动时，BIOS 把 PXE 客户端调入内存里面，就可以连接到服务端做一些操作了。 4.2.4 DCHP总结 DHCP 协议主要是用来给客户租用 IP 地址，和房产中介很像，要商谈、签约、续租，广播还不能“抢单” DHCP 协议能给客户推荐“装修队”PXE，能够安装操作系统，这个在云计算领域大有用处 参考文章动态主机配置协议DHCP 关于ifconfig与ip addr 学习自极客时间 《趣谈网络协议》","categories":[{"name":"随笔","slug":"随笔","permalink":"https://liangweijiang.github.io/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://liangweijiang.github.io/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"}]},{"title":"每日一道算法之--数组中的重复数字","slug":"algorithm-Interview-03","date":"2020-03-09T14:39:07.977Z","updated":"2020-03-09T14:40:55.208Z","comments":true,"path":"2020/03/09/algorithm-Interview-03/","link":"","permalink":"https://liangweijiang.github.io/2020/03/09/algorithm-Interview-03/","excerpt":"","text":"数组中重复的数字力扣面试题03 : https://leetcode-cn.com/problems/shu-zu-zhong-zhong-fu-de-shu-zi-lcof/ 找出数组中重复的数字。 在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。 示例 1： 输入：[2, 3, 1, 0, 2, 5, 3]输出：2 或 3 限制： 2 &lt;= n &lt;= 100000 这是剑指offer里面的原题,也是比较简单的一道题,但是,一开始我能想到的就是通过排序然后遍历就能够找到重复的数字,时间复杂度为O(logn),或者通过哈希表建立索引,从而使时间复杂度变为O(n),但是要牺牲额外的空间.然后作者给我们提供了一种很好的方法,我暂且叫做下标定位法.看看是怎么实现的吧 1. 排序实现直接看代码: 123456789class Solution: def findRepeatNumber(self, nums: List[int]) -&gt; int: if not nums: return -1 if len(nums) == 1: return nums.sort() for i in range(1, len(nums)): if nums[i] == nums[i - 1]: return nums[i] return -1 2. 利用哈希表实现12345678910class Solution: def findRepeatNumber(self, nums: List[int]) -&gt; int: if not nums: return -1 if len(nums) == 1: return -1 has_map = &#123;&#125; for num in nums: if num in has_map: return num has_map[num] = 1 return -1 3. 下标定位实现 阅读题目可以发现,所有数字都在 0～n-1 的范围内(哈哈我感觉其实救赎出题人有意而为), 这就可以假设如果数组中没有重复的数字, 那么排好序之后,数组每一个下标对应的数,其实就是刚好等于下标的,看到这句话,卧槽,牛逼牛逼!!如果有重复的数,则有些下标可能存在多个数,有的下标可能没有数。 现在可以重新对这个数组排序,从下标为i开始,这个数字为m,如果m不为i,则将a[i]与a[m]比较,如果不相等,则交换;如果相等,则证明找到了重复的数字。这样,下标为m的数它的值也为m了,相当于每个数最多两次交换就能找到它对应的下标. 12345678class Solution: def findRepeatNumber(self, nums: List[int]) -&gt; int: for i in range(len(nums)): while nums[i] != i: if nums[i] == nums[nums[i]]: return nums[i] nums[nums[i]], nums[i] = nums[i], nums[nums[i]] return -1 3.1 复杂度分析时间复杂度:虽然代码中有两层循环,但是每个数最多两次交换就能找到它对应的下标,所以时间复杂度还是为O(n) 空间复杂度:没有用到额外的数据结构,所以空间复杂度为O(1)","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"https://liangweijiang.github.io/tags/%E6%95%B0%E7%BB%84/"}]},{"title":"学习笔记之---负载均衡","slug":"LoadBalancing","date":"2020-03-09T07:16:29.244Z","updated":"2020-03-15T17:17:38.538Z","comments":true,"path":"2020/03/09/LoadBalancing/","link":"","permalink":"https://liangweijiang.github.io/2020/03/09/LoadBalancing/","excerpt":"","text":"负载均衡1 什么是负载均衡?百度百科是这样说的: 负载均衡建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。负载均衡（Load Balance）其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。 互联网早期，业务流量比较小并且业务逻辑比较简单，单台服务器便可以满足基本的需求；但随着互联网的发展，业务流量越来越大并且业务逻辑也越来越复杂，单台机器的性能问题以及单点问题凸显了出来，因此需要多台机器来进行性能的水平扩展以及避免单点故障。但是要如何将不同的用户的流量分发到不同的服务器上面呢？ 这就是负载均衡所要解决的问题。回到上边请求页面的过程，这个请求此时会被一台专门的服务器来处理，这台服务器其实就是个集群的老大，他负责把这个请求派给下面哪个小弟（服务器）来处理，处理完之后将数据返回给用户。当有多个请求同时发生时，集群的老大可以将请求派给不同的小弟，这样处理的效率就会大幅提升，充分发挥集群的力量，至于哪个请求到底派给哪个小弟，这就是调度策略的问题了。 我的理解就是有一个老大哥给每一小弟安排工作,而且工作不能偏心,要能使每一个小弟都能很好的工作,这样他们的效率就会更高,不会轻易累死小弟… 1.1 负载均衡的特点负载均衡技术具有一下优势： 高性能：负载均衡技术将业务较均衡的分担到多台设备或链路上，从而提高了整个系统的性能； 可扩展性：负载均衡技术可以方便的增加集群中设备或链路的数量，在不降低业务质量的前提下满足不断增长的业务需求； 高可靠性：单个甚至多个设备或链路法神故障也不会导致业务中断，提高了整个系统的可靠性； 可管理性：大量的管理共组都集中在使用负载均衡技术的设备上，设备集群或链路集群只需要维护通过的配置即可； 透明性：对用户而言，集群等于一个或多个高可靠性、高性能的设备或链路，用户感知不到，也不关心具体的网络结构，增加或减少设备或链路数量都不会影响正常的业务。 1.2 负载均衡的分类负载均衡技术分类： 服务器负载均衡：在数据中心等组网环境中，可以采用服务器负载均衡，将网络服务分担给多台服务器进行处理，提高数据中心的业务处理能力； 链路负载均衡：在有多个运营商出接口的组网环境中，可以采用出方向多链路动态负载均衡，实现链路的动态选择，提高服务的可靠性； 防火墙负载均衡：在防火墙处理能力成为瓶颈的组网环境中，可以采用防火墙负载均衡，将网络流量分担给多台防火墙设备，提高防火桥的处理能力； 2. 负载均衡的算法 随机算法Random随机，按权重设置随机概率。在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 轮询及加权轮询轮询(Round Robbin)当服务器群中各服务器的处理能力相同时，且每笔业务处理量差异不大时，最适合使用这种算法。 轮循，按公约后的权重设置轮循比率。存在慢的提供者累积请求问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。加权轮询(Weighted Round Robbin)为轮询中的每台服务器附加一定权重的算法。比如服务器1权重1，服务器2权重2，服务器3权重3，则顺序为1-2-2-3-3-3-1-2-2-3-3-3- …… 最小连接及加权最小连接最少连接(Least Connections)在多个服务器中，与处理连接数(会话数)最少的服务器进行通信的算法。即使在每台服务器处理能力各不相同，每笔业务处理量也不相同的情况下，也能够在一定程度上降低服务器的负载。加权最少连接(Weighted Least Connection)为最少连接算法中的每台服务器附加权重的算法，该算法事先为每台服务器分配处理连接的数量，并将客户端请求转至连接数最少的服务器上。 哈希算法普通哈希一致性哈希一致性Hash，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 IP地址散列通过管理发送方IP和目的地IP地址的散列，将来自同一发送方的分组(或发送至同一目的地的分组)统一转发到相同服务器的算法。当客户端有一系列业务需要处理而必须和一个服务器反复通信时，该算法能够以流(会话)为单位，保证来自相同客户端的通信能够一直在同一服务器中进行处理。 URL散列通过管理客户端请求URL信息的散列，将发送至相同URL的请求转发至同一服务器的算法。 3. 负载均衡的实现3.1 HTTP重定向实现负载均衡 HTTP重定向服务器就是一个普通的服务器，当用户访问时，其会根据一定的算法得到服务器集群的一个真实服务器的IP地址，将其放在HTTP响应头中，响应状态码为（302），当用户浏览器接收到这个响应时，会将得到的真实服务器的IP地址提出并重新访问。当浏览器收到响应消息后，解析Location字段，并向该URL发起请求，然后指定的服务器处理该用户的请求，最后将结果返回给用户。 在使用HTTP重定向来实现服务器集群负载均衡的过程中，需要一台服务器作为请求调度者。用户的一项操作需要发起两次HTTP请求，一次向调度服务器发送请求，获取后端服务器的IP，第二次向后端服务器发送请求，获取处理结果。 优点：采用HTTP重定向来实现服务器集群的负载均衡实现起来较为容易，逻辑比较简单。缺点: 这种方式需要用户浏览器访问两次，性能较差 HTTP重定向服务器会的处理能力会成为负载均衡的瓶颈由于不同用户的访问时间 HTTP重定向返回302，可能会使搜索引擎判定为SEO作弊，降低搜索排名,若分配给该用户的后端服务器出现故障，并且如果页面被浏览器缓存，那么当用户再次访问网站时，请求都会发给出现故障的服务器，从而导致访问失败 3.2 DNS负载均衡 当用户向我们的域名发起请求时，DNS服务器会自动地根据我们事先设定好的调度策略选一个合适的IP返回给用户，用户再向该IP发起请求 优点： 将负载均衡工作交给DNS，省略掉了网络管理的麻烦 DNS负载均衡最大的优点就是配置简单。服务器集群的调度工作完全由DNS服务器承担，那么我们就可以把精力放在后端服务器上，保证他们的稳定性与吞吐量。而且完全不用担心DNS服务器的性能，即便是使用了轮询策略，它的吞吐率依然卓越。 DNS负载均衡具有较强了扩展性，你完全可以为一个域名解析较多的IP，而且不用担心性能问题。 缺点： 由于把集群调度权交给了DNS服务器，从而我们没办法随心所欲地控制调度者，没办法定制调度策略。。 当我们发现某一台后端服务器发生故障时，即使我们立即将该服务器从域名解析中去除，但由于DNS服务器会有缓存，该IP仍然会在DNS中保留一段时间，那么就会导致一部分用户无法正常访问网站（可以用动态 DNS来解决）。事实上，大型网站总是部分使用DNS域名解析，作为第一级负载均衡手段，然后再在内部做第二级负载均衡。 3.3 数据链路层负载均衡(LVS)数据链路层负载均衡是指在通信协议的数据链路层修改mac地址进行负载均衡。 这种数据传输方式又称作三角传输模式，负载均衡数据分发过程中不修改IP地址，只修改目的的mac地址，通过配置真实物理服务器集群所有机器虚拟IP和负载均衡服务器IP地址一样，从而达到负载均衡，这种负载均衡方式又称为直接路由方式（DR）. 用户请求到达负载均衡服务器后，负载均衡服务器将请求数据的目的mac地址修改为真是WEB服务器的mac地址，并不修改数据包目标IP地址，因此数据可以正常到达目标WEB服务器，该服务器在处理完数据后可以经过网管服务器而不是负载均衡服务器直接到达用户浏览器。 使用三角传输模式的链路层负载均衡是目前大型网站所使用的最广的一种负载均衡手段。在linux平台上最好的链路层负载均衡开源产品是LVS(linux virtual server)。 3.4 IP层负载均衡先看一下ip层ip包的结构 可以看到结构中有原地址和目标地址这两个部分,这是实现ip层负载均衡的关键,我们就是通过修改这两个地址来达到“转发”目的 用户请求数据包到达负载均衡服务器后，负载均衡服务器在操作系统内核进行获取网络数据包，根据负载均衡算法计算得到一台真实的WEB服务器地址，然后将数据包的IP地址修改为真实的WEB服务器地址，不需要通过用户进程处理。真实的WEB服务器处理完毕后，相应数据包回到负载均衡服务器，负载均衡服务器再将数据包源地址修改为自身的IP地址发送给用户浏览器。 这里的关键在于真实WEB服务器相应数据包如何返回给负载均衡服务器，一种是负载均衡服务器在修改目的IP地址的同时修改源地址，将数据包源地址改为自身的IP，即源地址转换（SNAT），另一种方案是将负载均衡服务器同时作为真实物理服务器的网关服务器，这样所有的数据都会到达负载均衡服务器。 优点: IP负载均衡在内核进程完成数据分发，较反向代理均衡有更好的处理性能。缺点: 由于所有请求响应的数据包都需要经过负载均衡服务器，因此负载均衡的网卡带宽成为系统的瓶颈。 3.5 反向代理负载均衡(nginx) 代理与反向代理:VPN服务就是我们常用的一种代理（正向代理），用户将请教交给代理服务器，代理服务器访问网站获取数据，之后代理服务器再将数据返还给用户。在这个过程中，应用服务器并不知道用户的存在。只知道代理浏览器的访问。反向代理是指在服务器端的代理，代理服务器接收用户的请求，再转发给真实服务器，之后再返回给代理服务器再给用户，在这个过程中，用户并不知道真实服务器的存在。 传统代理服务器位于浏览器一端，代理浏览器将HTTP请求发送到互联网上。而反向代理服务器则位于网站机房一侧，代理网站web服务器接收http请求。 反向代理的作用是保护网站安全，所有互联网的请求都必须经过代理服务器，相当于在web服务器和可能的网络攻击之间建立了一个屏障。 除此之外，代理服务器也可以配置缓存加速web请求。当用户第一次访问静态内容的时候，静态内存就被缓存在反向代理服务器上，这样当其他用户访问该静态内容时，就可以直接从反向代理服务器返回，加速web请求响应速度，减轻web服务器负载压力。 另外，反向代理服务器也可以实现负载均衡的功能。 反向代理服务器管理了一组服务器，当用户访问时，代理服务器根据负载均衡算法将请求转发到真实服务器，真实服务器也通过反向代理服务器返还数据。内部服务器不对外部提供服务，所以不需要外部IP，而反向代理服务器需要两个网卡，一个IP用于外部用户访问使用，另外一个用于内部使用 优点： 隐藏后端服务器。与HTTP重定向相比，反向代理能够隐藏后端服务器，所有浏览器都不会与后端服务器直接交互，从而能够确保调度者的控制权，提升集群的整体性能。 故障转移。与DNS负载均衡相比，反向代理能够更快速地移除故障结点。当监控程序发现某一后端服务器出现故障时，能够及时通知反向代理服务器，并立即将其删除。 合理分配任务 。HTTP重定向和DNS负载均衡都无法实现真正意义上的负载均衡，也就是调度服务器无法根据后端服务器的实际负载情况分配任务。但反向代理服务器支持手动设定每台后端服务器的权重。我们可以根据服务器的配置设置不同的权重，权重的不同会导致被调度者选中的概率的不同。 缺点： 调度者压力过大 。由于所有的请求都先由反向代理服务器处理，那么当请求量超过调度服务器的最大负载时，调度服务器的吞吐率降低会直接降低集群的整体性能。 制约扩展。当后端服务器也无法满足巨大的吞吐量时，就需要增加后端服务器的数量，可没办法无限量地增加，因为会受到调度服务器的最大吞吐量的制约。 4. 四层和七层负载均衡的区别 源自:负载均衡基础知识:https://www.cnblogs.com/danbing/p/7459224.html作者: 金钟路上小码工 4.1 技术原理上的区别。 所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。 以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。 所谓七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。 以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。 负载均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。 4.2 应用场景的需求。 七层应用负载的好处，是使得整个网络更”智能化”, 参考我们之前的另外一篇专门针对HTTP应用的优化的介绍，就可以基本上了解这种方式的优势所在。例如访问一个网站的用户流量，可以通过七层的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术；将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术。 当然这只是七层应用的一个小案例，从技术原理上，这种方式可以对客户端的请求和服务器的响应进行任意意义上的修改，极大的提升了应用系统在网络层的灵活性。很多在后台，(例如Nginx或者Apache)上部署的功能可以前移到负载均衡设备上，例如客户请求中的Header重写，服务器响应中的关键字过滤或者内容插入等功能。 另外一个常常被提到功能就是安全性。网络中最常见的SYN Flood攻击，即黑客控制众多源客户端，使用虚假IP地址对同一目标发送SYN攻击，通常这种攻击会大量发送SYN报文，耗尽服务器上的相关资源，以达到Denial of Service(DoS)的目的。 从技术原理上也可以看出，四层模式下这些SYN攻击都会被转发到后端的服务器上；而七层模式下这些SYN攻击自然在负载均衡设备上就截止，不会影响后台服务器的正常运营。另外负载均衡设备可以在七层层面设定多种策略，过滤特定报文，例如SQL Injection等应用层面的特定攻击手段，从应用层面进一步提高系统整体安全。 现在的7层负载均衡，主要还是着重于应用广泛的HTTP协议，所以其应用范围主要是众多的网站或者内部信息平台等基于B/S开发的系统。 4层负载均衡则对应其他TCP应用，例如基于C/S开发的ERP等系统。 参考文章几种常见的负载均衡 负载均衡基础知识 关于负载均衡的详细介绍（通俗易懂） 负载均衡","categories":[{"name":"随笔","slug":"随笔","permalink":"https://liangweijiang.github.io/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"负载均衡","slug":"负载均衡","permalink":"https://liangweijiang.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://liangweijiang.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"每日一道算法之--组合总和","slug":"algorithm-39","date":"2020-03-05T12:55:27.140Z","updated":"2020-03-05T12:56:39.571Z","comments":true,"path":"2020/03/05/algorithm-39/","link":"","permalink":"https://liangweijiang.github.io/2020/03/05/algorithm-39/","excerpt":"","text":"组合总和力扣第39题:https://leetcode-cn.com/problems/combination-sum/参考文章回溯算法 + 剪枝 极客时间-数据结构与算法之美 给定一个无重复元素的数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。 candidates 中的数字可以无限制重复被选取。 说明： 所有数字（包括 target）都是正整数。 解集不能包含重复的组合。示例 1: 输入: candidates = [2,3,6,7], target = 7,所求解集为:[[7],[2,2,3]] 示例 2: 输入: candidates = [2,3,5], target = 8,所求解集为:[ [2,2,2,2], [2,3,3], [3,5]] 回溯思想当我第一眼看到这个题的时候,我第一时间想到就是DP,但是仔细阅读题目的时候就可以发现,这道题是求所有可能的总和,而动态规划只能解决最有问题,所以以后遇到求总和问题的时候,就应该先想到回溯的思想去解决问题. 回溯的处理思想，有点类似枚举搜索。我们枚举所有的解，找到满足期望的解。为了有规律地枚举所有可能的解，避免遗漏和重复，我们把问题求解的过程分为多个阶段。每个阶段，我们都会面对一个岔路口，我们先随意选一条路走，当发现这条路走不通的时候（不符合期望的解），就回退到上一个岔路口，另选一种走法继续走。 相信看过明日边缘和蝴蝶效应这些电影的人应该很容易去理解回溯,下面就来用回溯思想去分析一下这道题. 可以看到,以蓝色点递归可以找到所有的组合 但是有一些节点是重复的,因为递归时没有加限制条件,更深一层的递归又会重复去考虑之前已经计算过的组合,所以需要去排序. 排好序之后,当候选数组的元素比目标数还大时,该元素后面的数可以都不用去考虑了. 123456789101112131415161718class Solution: def combinationSum(self, candidates: List[int], target: int) -&gt; List[List[int]]: candidates.sort() n = len(candidates) res = [] def helper(start, cur_num, tmp): if cur_num == 0: res.append(tmp) return # 这里是去重, 排序之后,start前面的元素都不用去考虑了 for i in range(start, n): # 剪枝,该元素比目标数还大,则直接跳出 # 这里是自下往上组合,上图中是自上往下组合,原理都一样 if cur_num - candidates[i] &lt; 0: break helper(i, cur_num - candidates[i], tmp + [candidates[i]]) helper(0, target, []) return res 复杂度分析时间复杂度:每一次递归遍历考虑所有可能的组合,所以时间复杂度为$$O(n^2)$$ 空间复杂度:O(n) 总结回溯思想可能是一个时间复杂度较高的算法,很多时候可以用dp去优化,但是在枚举所有可能的结果的时候,就是发挥它的特点的时候了,不要因为复杂度高就不去考虑,所以还是的脚踏实地去学习编程吧!!! 相似题目 组合总和II 组合总和III 全排列 N皇后","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组","slug":"数组","permalink":"https://liangweijiang.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"回溯思想","slug":"回溯思想","permalink":"https://liangweijiang.github.io/tags/%E5%9B%9E%E6%BA%AF%E6%80%9D%E6%83%B3/"}]},{"title":"python单例模式的实现","slug":"python-02","date":"2020-03-04T08:13:02.751Z","updated":"2020-03-04T08:18:12.492Z","comments":true,"path":"2020/03/04/python-02/","link":"","permalink":"https://liangweijiang.github.io/2020/03/04/python-02/","excerpt":"","text":"单例模式什么是单例模式 单例模式（Singleton Pattern）是一种常用的软件设计模式，该模式的主要目的是确保某一个类只有一个实例存在。当你希望在整个系统中，某个类只能出现一个实例时，单例对象就能派上用场。 比如，某个服务器程序的配置信息存放在一个文件中，客户端通过一个 AppConfig 的类来读取配置文件的信息。如果在程序运行期间，有很多地方都需要使用配置文件的内容，也就是说，很多地方都需要创建 AppConfig 对象的实例，这就导致系统中存在多个 AppConfig 的实例对象，而这样会严重浪费内存资源，尤其是在配置文件内容很多的情况下。事实上，类似 AppConfig 这样的类，我们希望在程序运行期间只存在一个实例对象。 单例模式的实现python实现单例模式有多种实现方法，下面一一来解释说明 1. 基于装饰器的单例模式的实现12345678910111213141516171819202122232425def singleton(cls): # 创建一个字典用来保存类的实例对象 _instance = &#123;&#125; def _singleton(*args, **kwargs): # 先判断这个类有没有对象 if cls not in _instance: _instance[cls] = cls(*args, **kwargs) # 创建一个对象,并保存到字典当中 # 将实例对象返回 return _instance[cls] return _singleton@singletonclass A(object): a = 1 def __init__(self, x=0): self.x = x print('这是A的类的初始化方法')a1 = A(2)a2 = A(3)print(a1.x, a2.x)print(id(a1), id(a2)) 可以看到打印结果为: 2. 基于类方法的单例模式的实现123456789101112131415161718192021class A: def __init__(self, x, y): self.x = x self.y = y @classmethod def singleton(cls, *args, **kwargs): if not hasattr(cls, '__instance'): cls.__instance = cls(*args, **kwargs) return cls.__instanceobj1 = A(1, 2)obj2 = A(3, 4)print(obj1.x, obj1.y, obj2.x, obj2.y)print(id(obj1), id(obj2))obj3 = A.singleton(1, 2)obj4 = A.singleton(3, 4)print(obj3.x, obj3.y, obj4.x, obj4.y)print(id(obj3), id(obj4) 打印结果如下: 但是这个实现方法在多线程上会出现堵塞现象,所以需要加锁1234567891011121314151617181920212223242526import threadingclass A: _instance_lock = threading.Lock() def __init__(self, x, y): self.x = x self.y = y @classmethod def singleton(cls, *args, **kwargs): if not hasattr(cls, '__instance'): with cls._instance_lock: cls.__instance = cls(*args, **kwargs) return cls.__instanceobj1 = A(1, 2)obj2 = A(3, 4)print(obj1.x, obj1.y, obj2.x, obj2.y)print(id(obj1), id(obj2))obj3 = A.singleton(1, 2)obj4 = A.singleton(3, 4)print(obj3.x, obj3.y, obj4.x, obj4.y)print(id(obj3), id(obj4)) 可以发现,使用类方法创建单例模式时,必须要调用该方法,否则直接调用类得到的并不是单例 3. 基于new方法实现单例模式(推荐) 一个对象的实例化过程是先执行类的new方法,如果我们没有写,默认会调用object的new方法,返回一个实例化对象,然后再调用init方法,对这个对象进行初始化,我们可以根据这个实现单例. 在一个类的new方法中先判断是不是存在实例,如果存在实例,就直接返回,如果不存在实例就创建. 1234567891011121314151617import threadingclass A: _instance_lock = threading.Lock() def __new__(cls, *args, **kwargs): if not hasattr(cls, '__instance'): with cls._instance_lock: if not hasattr(cls, '__instance'): cls.__instance = super().__new__(cls) return cls.__instanceobj1 = A()obj2 = A()print(obj1, obj2)print(id(obj1), id(obj2)) 45.基于metaclass方式实现 类由type创建，创建类时，type的init方法自动执行，类() 执行type的 call方法(类的new方法,类的init方法) 对象由类创建，创建对象时，类的init方法自动执行，对象()执行类的 call 方法 1234567891011class Foo: def __init__(self): pass def __call__(self, *args, **kwargs): passobj = Foo()# 执行type的 __call__ 方法，调用 Foo类（是type的对象）的 __new__方法，用于创建对象，然后调用 Foo类（是type的对象）的 __init__方法，用于对对象初始化。obj() # 执行Foo的 __call__ 方法 元类的使用 1234567891011121314151617181920class SingletonType(type): #只有继承了type类才能称之为一个元类，否则就是一个普通的自定义类 def __init__(self,*args,**kwargs): super(SingletonType,self).__init__(*args,**kwargs) def __call__(cls, *args, **kwargs): # 这里的cls，即Foo类 print('cls',cls) # __new__()创建对象 obj = cls.__new__(cls,*args, **kwargs) # __init__()实例化对象 cls.__init__(obj,*args, **kwargs) # Foo.__init__(obj) return objclass Foo(metaclass=SingletonType): # 指定创建Foo的type为SingletonType def __init__(self，name): self.name = name def __new__(cls, *args, **kwargs): return object.__new__(cls)obj = Foo('xx') 实现单例模式 1234567891011121314151617181920import threadingclass SingletonType(type): _instance_lock = threading.Lock() def __call__(cls, *args, **kwargs): if not hasattr(cls, \"_instance\"): with SingletonType._instance_lock: if not hasattr(cls, \"_instance\"): cls._instance = super(SingletonType,cls).__call__(*args, **kwargs) return cls._instanceclass Foo(metaclass=SingletonType): def __init__(self,name): self.name = nameobj1 = Foo('name')obj2 = Foo('name')print(obj1,obj2)","categories":[{"name":"python","slug":"python","permalink":"https://liangweijiang.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://liangweijiang.github.io/tags/python/"},{"name":"设计模式","slug":"设计模式","permalink":"https://liangweijiang.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"python与其他语言的对比","slug":"python-01","date":"2020-03-04T05:12:40.670Z","updated":"2020-03-08T15:10:45.420Z","comments":true,"path":"2020/03/04/python-01/","link":"","permalink":"https://liangweijiang.github.io/2020/03/04/python-01/","excerpt":"","text":"python与其他语言的对比1.C语言 它既有高级语言的特点，又具有汇编语言的特点，它是结构式语言。C语言应用指针：可以直接进行靠近硬件的操作，但是C的指针操作不做保护，也给它带来了很多不安全的因素。C++在这方面做了改进，在保留了指针操作的同时又增强了安全性，受到了一些用户的支持，但是，由于这些改进增加语言的复杂度，也为另一部分所诟病。Java则吸取了C++的教训，取消了指针操作，也取消了C++改进中一些备受争议的地方，在安全性和适合性方面均取得良好的效果，但其本身解释在虚拟机中运行，运行效率低于C++/C。一般而言，C，C++，java被视为同一系的语言，它们长期占据着程序使用榜的前三名。 C语言的优点：简洁紧凑、灵活方便；运算符丰富；数据类型丰富；表达方式灵活实用；允许直接访问物理地址，对硬件进行操作；生成目标代码质量高，程序执行效率高；可移植性好；表达力强； C语言的缺点：C语言的缺点主要表现在数据的封装性上，这一点使得C在数据的安全性上有很大缺陷，这也是C和C++的一大区别。 C语言的语法限制不太严格，对变量的类型约束不严格，影响程序的安全性，对数组下标越界不作检查等。从应用的角度，C语言比其他高级语言较难掌握。也就是说，对用C语言的人，要求对程序设计更熟练一些。 2.c++语言 C++是C语言的继承，它既可以进行C语言的过程化程序设计，又可以进行以抽象数据类型为特点的基于对象的程序设计，还可以进行以继承和多态为特点的面向对象的程序设计。C++擅长面向对象程序设计的同时，还可以进行基于过程的程序设计，因而C++就适应的问题规模而论，大小由之。 C++不仅拥有计算机高效运行的实用性特征，同时还致力于提高大规模程序的编程质量与程序设计语言的问题描述能力。 C++语言的程序因为要体现高性能，所以都是编译型的。但其开发环境，为了方便测试，将调试环境做成解释型的。即开发过程中，以解释型的逐条语句执行方式来进行调试，以编译型的脱离开发环境而启动运行的方式来生成程序最终的执行代码。 生成程序是指将源码（C++语句）转换成一个可以运行的应用程序的过程。如果程序的编写是正确的，那么通常只需按一个功能键，即可搞定这个过程。该过程实际上分成两个步骤。 第一步是对程序进行编译，这需要用到编译器（compiler）。编译器将C++语句转换成机器码(也称为目标码)；如果这个步骤成功，下一步就是对程序进行链接，这需要用到链接器（linker）。链接器将编译获得机器码与C++库中的代码进行合并。C++库包含了执行某些常见任务的函数（“函数”是子程序的另一种称呼）。例如，一个C++库中包含标准的平方根函数sqrt，所以不必亲自计算平方根。C++库中还包含一些子程序，它们把数据发送到显示器，并知道如何读写硬盘上的数据文件。 3. C#语言 C#是微软公司发布的一种面向对象的、运行于.NET Framework之上的高级程序设计语言。C#看起来与Java有着惊人的相似；它包括了诸如单一继承、接口、与Java几乎同样的语法和编译成中间代码再运行的过程。但是C#与Java有着明显的不同，它借鉴了Delphi的一个特点，与COM（组件对象模型）是直接集成的，而且它是微软公司 .NET windows网络框架的主角。首先，C# 和JAVA一样，简直就是照搬了C++的部分语法，因此，对于数量众多的C++程序员学习起来很容易上手，另外，对于新手来说，比C++要简单一些。其次，Windows是占垄断地位的平台，而开发Windows应用，当然微软的声音是不能忽略的。最重要的是，相对于C++，用C# 开发应用软件可以大大缩短开发周期，同时可以利用原来除用户界面代码之外的C++代码。 4. Java语言 Java是一种可以撰写跨平台应用软件的面向对象的程序设计语言，是由Sun Microsystems公司于1995年5月推出的Java程序设计语言和Java平台（即JavaSE, JavaEE, JavaME）的总称。Java 技术具有卓越的通用性、高效性、平台移植性和安全性，广泛应用于个人PC、数据中心、游戏控制台、科学超级计算机、移动电话和互联网，同时拥有全球最大的开发者专业社群。在全球云计算和移动互联网的产业环境下，Java更具备了显著优势和广阔前景。 Java的优势，与传统程序不同，Sun 公司在推出 Java 之际就将其作为一种开放的技术。全球数以万计的 Java 开发公司被要求所设计的 Java软件必须相互兼容。“Java 语言靠群体的力量而非公司的力量”是Sun公司的口号之一，并获得了广大软件开发商的认同。这与微软公司所倡导的注重精英和封闭式的模式完全不同。Sun 公司对 Java 编程语言的解释是：Java 编程语言是个简单、面向对象、分布式、解释性、健壮、安全与系统无关、可移植、高性能、多线程和动态的语言。 5.php语言 PHP（PHP: Hypertext Preprocessor的缩写，中文名：“PHP：超文本预处理器”）是一种通用开源脚本语言。语法吸收了C语言、Java和Perl的特点，入门门槛较低，易于学习，使用广泛，主要适用于Web开发领域。 的执行动态网页——动态页面方面，与其他的编程语言相比，PHP是将程序嵌入到HTML文档中去执行，执行效率比完全生成htmL标记的CGI要高许多，PHP具有非常强大的功能，所有的CGI的功能PHP都能实现； PHP支持几乎所有流行的数据库以及操作系统；最重要的是PHP可以用C、C++进行程序的扩展。 6.python语言 python是一种面向对象、直译式计算机程序设计语言，Python语法简洁而清晰，具有丰富和强大的类库。它常被昵称为胶水语言，它能够很轻松的把用其他语言制作的各种模块（尤其是C/C++）轻松地联结在一起。常见的一种应用情形是，使用python快速生成程序的原型（有时甚至是程序的最终界面），然后对其中有特别要求的部分，用更合适的语言改写。 Python是完全面向对象的语言。函数、模块、数字、字符串都是对象。并且完全支持继承、重载、派生、多继承，有益于增强源代码的复用性。Python支持重载运算符和动态类型。相对于Lisp这种传统的函数式编程语言，Python对函数式设计只提供了有限的支持。有两个标准库(functools, itertools)提供了Haskell和Standard ML中久经考验的函数式程序设计工具。Python本身被设计为可扩充的。并非所有的特性和功能都集成到语言核心。Python提供了丰富的API和工具，以便程序员能够轻松地使用C语言、C++、Cython来编写扩充模块。Python编译器本身也可以被集成到其它需要脚本语言的程序内。因此，很多人还把Python作为一种“胶水语言”（glue language）使用。使用Python将其他语言编写的程序进行集成和封装。 编译型语言和解释型语言 编译性语言(需要编译器,相当于翻译) 只须编译一次就可以把源代码编译成机器语言，后面的执行无须重新编译，直接使用之前的编译结果就可 以；因此其执行的效率比较高； 编译性语言代表：C、C++、Pascal/Object Pascal（Delphi）； 程序执行效率比较高，但比较依赖编译器，调试麻烦, 因此跨平台性差一些； 不同平台对编译器影响较大。如：（1）16位系统下int是2个字节（16位），而32位系统下int占4个字节（32位）；（2）32位系统下long类型占4字节，而64位系统下long类型占8个字节； 解释型语言（需要解释器，相当于同声传译） 源代码不能直接翻译成机器语言，而是先翻译成中间代码，再由解释器对中间代码进行解释运行； 程序不需要编译，程序在运行时才翻译成机器语言，每执行一次都要翻译一次； 解释型跨平台好，一份代码，到处使用 解释性语言代表：Python、JavaScript、Shell、Ruby、MATLAB等； 运行效率一般相对比较低，依赖解释器，跨平台性好； python解释器的种类和特点CPythonCPython是使用最广且被的Python解释器。本教程以CPython为准。当我们从Python官方网站下载并安装好Python 2.7后，我们就直接获得了一个官方版本的解释器：CPython。这个解释器是用C语言开发的，所以叫CPython。在命令行下运行python就是启动CPython解释器。 IPythonIPython是基于CPython之上的一个交互式解释器，也就是说，IPython只是在交互方式上有所增强，但是执行Python代码的功能和CPython是完全一样的。好比很多国产浏览器虽然外观不同，但内核其实都是调用了IE。CPython用&gt;&gt;&gt;作为提示符，而IPython用In [序号]:作为提示符。 PyPyPyPy是另一个Python解释器，它的目标是执行速度。PyPy采用JIT技术，对Python代码进行动态编译（注意不是解释），所以可以显著提高Python代码的执行速度。 绝大部分Python代码都可以在PyPy下运行，但是PyPy和CPython有一些是不同的，这就导致相同的Python代码在两种解释器下执行可能会有不同的结果。如果你的代码要放到PyPy下执行，就需要了解PyPy和CPython的不同点。 JythonJython是运行在Java平台上的Python解释器，可以直接把Python代码编译成Java字节码执行。 IronPythonIronPython和Jython类似，只不过IronPython是运行在微软.Net平台上的Python解释器，可以直接把Python代码编译成.Net的字节码。","categories":[{"name":"python","slug":"python","permalink":"https://liangweijiang.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://liangweijiang.github.io/tags/python/"}]},{"title":"python的垃圾回收机制","slug":"python-GC","date":"2020-03-04T04:07:35.310Z","updated":"2020-03-05T04:11:27.598Z","comments":true,"path":"2020/03/04/python-GC/","link":"","permalink":"https://liangweijiang.github.io/2020/03/04/python-GC/","excerpt":"","text":"python的垃圾回收机制 垃圾回收机制是自动帮助我们管理内存，清理垃圾的一种工具1）、引用计数当一个对象的引用被创建或者复制时，对象的引用计数加1；当一个对象的引用被销毁时，对象的引用计数减1；当对象的引用计数减少为0时，就意味着对象已经没有被任何人使用了，可以将其所占用的内存释放了。2）、标记-清除标记-清除不改动真实的引用计数，而是将集合中对象的引用计数复制一份副本，改动该对象引用的副本。对于副本做任何的改动，都不会影响到对象生命走起的维护。3）、分代回收将系统中的所有内存块根据其存活时间划分为不同的集合，每一个集合就成为一个“代”，垃圾收集的频率随着“代”的存活时间的增大而减小。也就是说，活得越长的对象，就越不可能是垃圾，就应该减少对它的垃圾收集频率。那么如何来衡量这个存活时间：通常是利用几次垃圾收集动作来衡量，如果一个对象经过的垃圾收集次数越多，可以得出：该对象存活时间就越长。 1. 引用计数python一切皆对象,每一个对象都保存了一个称为引用计数的整数值，来追踪到底有多少引用指向了这个对象。无论何时，如果我们程序中的一个变量或其他对象引用了目标对象，Python将会增加这个计数值。 对象被创建 a=14 对象被引用 b=a 对象被作为参数,传到函数中 func(a) 对象作为一个元素，存储在容器中 List={a,”a”,”b”,2} 而当程序停止使用这个对象，则Python会减少这个计数值。一旦计数值被减到零，Python将会释放这个对象以及回收相关内存空间。 当该对象的别名被显式销毁时 del a 当该对象的引别名被赋予新的对象， a=26 一个对象离开它的作用域，例如 func函数执行完毕时，函数里面的局部变量的引用计数器就会减一（但是全局变量不会） 将该元素从容器中删除时，或者容器被销毁时。 当指向该对象的内存的引用计数器为0的时候，该内存将会被Python虚拟机销毁 1.1 引用计数的优点可以看出,引用计数有以下几个优点: 高效 运行期没有停顿 可以类比一下Ruby的垃圾回收机制，也就是 实时性：一旦没有引用，内存就直接释放了。不用像其他机制等到特定时机。实时性还带来一个好处：处理回收内存的时间分摊到了平时。 对象有确定的生命周期 易于实现,简单直观 但是针对引用计数这种算法来说，如果一个数据结构引用了它自身，即如果这个数据结构是一个循环数据结构，那么某些引用计数值是肯定无法变成零的。为了更好地理解这个问题，让我们举个例子。 123456a = &#123; &#125; #对象A的引用计数为 1b = &#123; &#125; #对象B的引用计数为 1a['b'] = b #B的引用计数增1b['a'] = a #A的引用计数增1del a #A的引用减 1，最后A对象的引用为 1del b #B的引用减 1, 最后B对象的引用为 1 在这个例子中程序执行完del语句后，A、B对象已经没有任何引用指向这两个对象，但是这两个对象各包含一个对方对象的引用，虽然最后两个对象都无法通过其它变量来引用这两个对象了，这对GC来说就是两个非活动对象或者说是垃圾对象，但是他们的引用计数并没有减少到零。因此如果是使用引用计数法来管理这两对象的话，他们并不会被回收，它会一直驻留在内存中，就会造成了内存泄漏（内存空间在使用完毕后未释放）。 1.2 引用计数的缺点虽然引用计数有着非常简单高效的优点,但是他也有这致命的缺点 维护引用计数消耗资源，维护引用计数的次数和引用赋值成正比，而不像mark and sweep等基本与回收的内存数量有关。 无法解决循环引用的问题 为了解决对象的循环引用问题，Python引入了标记-清除和分代回收两种GC机制。 2. 标记清除 『标记清除（Mark—Sweep）』算法是一种基于追踪回收（tracing GC）技术实现的垃圾回收算法。它分为两个阶段：第一阶段是标记阶段，GC会把所有的『活动对象』打上标记，第二阶段是把那些没有标记的对象『非活动对象』进行回收。那么GC又是如何判断哪些是活动对象哪些是非活动对象的呢？ 对象之间通过引用（指针）连在一起，构成一个有向图，对象构成这个有向图的节点，而引用关系构成这个有向图的边。从根对象（root object）出发，沿着有向边遍历对象，可达的（reachable）对象标记为活动对象，不可达的对象就是要被清除的非活动对象。根对象就是全局变量、调用栈、寄存器。 标记阶段，遍历所有的GC Roots对象(栈区中的所有内容或者线程都可以作为GC Roots对象），然后将所有 GC Roots的对象可以直接或间接访问到的对象标记为存活的对象，其余的均为非存活对象，应该被清除; 清除阶段，再次遍历对象，如果发现某个对象没有标记为可达，则就将其回收。 在上图中，我们把小黑圈视为全局变量，也就是把它作为root object，从小黑圈出发，对象1可直达，那么它将被标记，对象2、3可间接到达也会被标记，而4和5不可达，那么1、2、3就是活动对象，4和5是非活动对象会被GC回收。 标记清除算法作为Python的辅助垃圾收集技术主要处理的是一些容器对象，比如list、dict、tuple，instance等，因为对于字符串、数值对象是不可能造成循环引用问题。Python使用一个双向链表将这些容器对象组织起来。 不过，这种简单粗暴的标记清除算法也有明显的缺点：清除非活动的对象前它必须顺序扫描整个堆内存，哪怕只剩下小部分活动对象也要扫描所有对象，而且会暂停整个应用程序，等待标记清除结束后才会恢复应用程序的运行 3. 分代回收分代回收是一种以空间换时间的操作方式，Python将内存根据对象的存活时间划分为不同的集合，每个集合称为一个代，Python将内存分为了3“代”，分别为年轻代（第0代）、中年代（第1代）、老年代（第2代），他们对应的是3个链表，它们的垃圾收集频率与对象的存活时间的增大而减小。新创建的对象都会分配在年轻代，年轻代链表的总数达到上限时，Python垃圾收集机制就会被触发，把那些可以被回收的对象回收掉，而那些不会回收的对象就会被移到中年代去，依此类推，老年代中的对象是存活时间最久的对象，甚至是存活于整个系统的生命周期内。同时，分代回收是建立在标记清除技术基础之上。分代回收同样作为Python的辅助垃圾收集技术处理那些容器对象。 新定义的变量，放到新生代这个等级中，假设每隔1分钟扫描新生代一次，如果发现变量依然被引用，那么该对象的权重（权重本质就是个整数）加一，当变量的权重大于某个设定得值（假设为3），会将它移动到更高一级的青春代，青春代的gc扫描的频率低于新生代（扫描时间间隔更长），假设5分钟扫描青春代一次，这样每次gc需要扫描的变量的总个数就变少了，节省了扫描的总时间，接下来，青春代中的对象，也会以同样的方式被移动到老年代中。也就是等级（代）越高，被垃圾回收机制扫描的频率越低 分代回收是基于这样的一个统计事实，对于程序，存在一定比例的内存块的生存周期比较短；而剩下的内存块，生存周期会比较长，甚至会从程序开始一直持续到程序结束。生存期较短对象的比例通常在 80%～90% 之间，这种思想简单点说就是：对象存在时间越长，越可能不是垃圾，应该越少去收集。这样在执行标记-清除算法时可以有效减小遍历的对象数，从而提高垃圾回收的速度。 Python默认定义了三代对象集合，索引数越大，对象存活时间越长12345678910#define NUM_GENERATIONS 3#define GEN_HEAD(n) (&amp;generations[n].head)/* linked lists of container objects */static struct gc_generation generations[NUM_GENERATIONS] = &#123; /* PyGC_Head, threshold, count */ &#123;&#123;&#123;GEN_HEAD(0), GEN_HEAD(0), 0&#125;&#125;, 700, 0&#125;, &#123;&#123;&#123;GEN_HEAD(1), GEN_HEAD(1), 0&#125;&#125;, 10, 0&#125;, &#123;&#123;&#123;GEN_HEAD(2), GEN_HEAD(2), 0&#125;&#125;, 10, 0&#125;,&#125;; 新生成的对象会被加入第0代，前面_PyObject_GC_Malloc中省略的部分就是Python GC触发的时机。每新生成一个对象都会检查第0代有没有满，如果满了就开始着手进行垃圾回收.1234567891011g-&gt;gc.gc_refs = GC_UNTRACKED; generations[0].count++; /* number of allocated GC objects */ if (generations[0].count &gt; generations[0].threshold &amp;&amp; enabled &amp;&amp; generations[0].threshold &amp;&amp; !collecting &amp;&amp; !PyErr_Occurred()) &#123; collecting = 1; collect_generations(); collecting = 0; &#125; 3.1 在Python中的零代(Generation Zero)很多时候你的代码也许会在不经意间包含循环引用并且你并未意识到。事实上，当你的Python程序运行的时候它将会建立一定数量的“浮点数垃圾”，Python的GC不能够处理未使用的对象因为应用计数值不会到零。就是为什么Python要引入Generational GC算法的原因！正如Ruby使用一个链表(free list)来持续追踪未使用的、自由的对象一样，Python使用一种不同的链表来持续追踪活跃的对象。而不将其称之为“活跃列表”，Python的内部C代码将其称为零代(Generation Zero)。每次当你创建一个对象或其他什么值的时候，Python会将其加入零代链表。请注意到这并不是一个真正的列表，并不能直接在你的代码中访问，事实上这个链表是一个完全内部的Python运行体 3.2 Python中的GC阈值随着你的程序运行，Python解释器保持对新创建的对象，以及因为引用计数为零而被释放掉的对象的追踪。从理论上说，这两个值应该保持一致，因为程序新建的每个对象都应该最终被释放掉。 当然，事实并非如此。因为循环引用的原因，并且因为你的程序使用了一些比其他对象存在时间更长的对象，从而被分配对象的计数值与被释放对象的计数值之间的差异在逐渐增长。一旦这个差异累计超过某个阈值，则Python的收集机制就启动了，并且触发上边所说到的零代算法，释放“浮动的垃圾”，并且将剩下的对象移动到一代列表。 随着时间的推移，程序所使用的对象逐渐从零代列表移动到一代列表。而Python对于一代列表中对象的处理遵循同样的方法，一旦被分配计数值与被释放计数值累计到达一定阈值，Python会将剩下的活跃对象移动到二代列表。 通过这种方法，你的代码所长期使用的对象，那些你的代码持续访问的活跃对象，会从零代链表转移到一代再转移到二代。通过不同的阈值设置，Python可以在不同的时间间隔处理这些对象。Python处理零代最为频繁，其次是一代然后才是二代。 3.3 弱代假说来看看代垃圾回收算法的核心行为：垃圾回收器会更频繁的处理新对象。一个新的对象即是你的程序刚刚创建的，而一个来的对象则是经过了几个时间周期之后仍然存在的对象。Python会在当一个对象从零代移动到一代，或是从一代移动到二代的过程中提升(promote)这个对象。 为什么要这么做？这种算法的根源来自于弱代假说(weak generational hypothesis)。这个假说由两个观点构成：首先是年亲的对象通常死得也快，而老对象则很有可能存活更长的时间。 假定现在我用Python或是Ruby创建一个新对象 n1=”ABC”： 根据假说，我的代码很可能仅仅会使用ABC很短的时间。这个对象也许仅仅只是一个方法中的中间结果，并且随着方法的返回这个对象就将变成垃圾了。大部分的新对象都是如此般地很快变成垃圾。然而，偶尔程序会创建一些很重要的，存活时间比较长的对象-例如web应用中的session变量或是配置项。 通过频繁的处理零代链表中的新对象，Python的垃圾收集器将把时间花在更有意义的地方：它处理那些很快就可能变成垃圾的新对象。同时只在很少的时候，当满足阈值的条件，收集器才回去处理那些老变量。 分代回收的逻辑分配内存-&gt; 发现超过阈值了-&gt; 触发垃圾回收-&gt; 将所有可收集对象链表放到一起-&gt; 遍历, 计算有效引用计数-&gt; 分成 有效引用计数=0 和 有效引用计数 &gt; 0 两个集合-&gt; 大于0的, 放入到更老一代-&gt; =0的, 执行回收-&gt; 回收遍历容器内的各个元素, 减掉对应元素引用计数(破掉循环引用)-&gt; 执行-1的逻辑, 若发现对象引用计数=0, 触发内存回收-&gt; python底层内存管理机制回收内存 总结总体来说，在Python中，主要通过引用计数进行垃圾回收；通过 “标记-清除” 解决容器对象可能产生的循环引用问题；通过 “分代回收” 以空间换时间的方法提高垃圾回收效率。 参考文章：一文搞定Python垃圾回收机制Python垃圾回收机制–完美讲解!Python中的垃圾回收机制PYTHON 源码阅读 - 垃圾回收机制《垃圾回收的算法与实现》","categories":[{"name":"python","slug":"python","permalink":"https://liangweijiang.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://liangweijiang.github.io/tags/python/"},{"name":"垃圾回收","slug":"垃圾回收","permalink":"https://liangweijiang.github.io/tags/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"}]},{"title":"每日一道算法之--有效的括号","slug":"algorithm-20","date":"2020-03-03T11:41:23.245Z","updated":"2020-03-03T11:42:43.389Z","comments":true,"path":"2020/03/03/algorithm-20/","link":"","permalink":"https://liangweijiang.github.io/2020/03/03/algorithm-20/","excerpt":"","text":"有效的括号力扣第20题 : https://leetcode-cn.com/problems/valid-parentheses/ 给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串，判断字符串是否有效。 有效字符串需满足： 左括号必须用相同类型的右括号闭合。左括号必须以正确的顺序闭合。注意空字符串可被认为是有效字符串。 示例 1: 输入: “()”输出: true 示例 2: 输入: “()[]{}”输出: true 示例 3: 输入: “(]”输出: false 题目分析题目不难理解,就是括号要一一对应,换句话来说,只要出现了右括号,name就必定有一个左括号与之对应,而且左括号和右括号必须是对称的,刚好栈这种数据结构可以很好地实现这一目的. 要想一一对应,字符串长度必须是偶数 遍历这个数组,每当遇到左括号时,直接入栈 当遇到有括号时,就取出栈顶元素,然后与该括号配对,若配对失败,则证明字符串无效,若配对成功,则继续遍历 直到数组遍历完成并且栈里没有元素以后,则证明字符串有效 翻译成代码如下: 123456789101112class Solution: def isValid(self, s: str) -&gt; bool: has_map = &#123;')':'(', '&#125;':'&#123;', ']':'['&#125; stack = [] if len(s) % 2 != 0: return False for char in s: if char in has_map: top_ele = stack.pop() if stack else '' if top_ele != has_map[char]: return False else: stack.append(char) return not stack 复杂度分析时间复杂度：因为我们一次只遍历给定的字符串中的一个字符并在栈上进行 O(1) 的推入和弹出操作,所以时间复杂度为O(n)。 空间复杂度：在最糟糕的情况下，我们最终要把所有括号推到栈上。例如 ((((((((((, 而如果是有效字符串,则也要将n/2的括号入栈,所以空间复杂度为O(n)。","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"栈","slug":"栈","permalink":"https://liangweijiang.github.io/tags/%E6%A0%88/"},{"name":"数组","slug":"数组","permalink":"https://liangweijiang.github.io/tags/%E6%95%B0%E7%BB%84/"}]},{"title":"每日一道算法之--二叉树的层次遍历","slug":"algorithm-102","date":"2020-03-03T09:46:49.296Z","updated":"2020-03-03T10:35:03.161Z","comments":true,"path":"2020/03/03/algorithm-102/","link":"","permalink":"https://liangweijiang.github.io/2020/03/03/algorithm-102/","excerpt":"","text":"二叉树的层次遍历力扣第102题 : https://leetcode-cn.com/problems/binary-tree-level-order-traversal/ 给定一个二叉树，返回其按层次遍历的节点值。 （即逐层地，从左到右访问所有节点）。 例如: 给定二叉树: [3,9,20,null,null,15,7], 3 / 9 20 / 15 7 返回其层次遍历结果： [ [3], [9,20], [15,7]] 1.递归一开始看到这题时,因为之前学过二叉树的知识,所以我知道这道题的第一思路就是递归但是这道层次遍历的主要问题就是,数是分左右节点的,如果直接递归,那么同一层的左右节点就不会给同时读取.所以,能不能先定义一个变量,专门记录该节点的层级.然后分析题目的返回值,它是一个子元素是列表的列表,不难发现,子元素的索引,刚好就是数的层级,所以可以直接定义一个列表levels = [],每递归一层,如果大列表中没有该层级的子列表,就往大列表中添加一个字列表,然后往该层级的子列表中添加该节点的值代码如下: 12345678910111213141516171819202122# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def levelOrder(self, root: TreeNode) -&gt; List[List[int]]: levels= [] if not root : return levels def foo(node, level): n = len(levels) if n == level: levels.append([]) levels[level].append(node.val) if node.left: foo(node.left, level + 1) if node.right: foo(node.right, level + 1) foo(root, 0) return levels 1.1 复杂度分析时间复杂度:假设有n个节点,恰好会递归到每一个节点,所以时间复杂度为O(n) 空间复杂度:假设有n个节点,数组存储的刚好是每一个节点,所以空间复杂度为O(n) 2.迭代实现了递归的方式后,迭代的思想节本和递归差不多,只是要加多一个栈的数据结构 12345678910111213141516class Solution: def levelOrder(self, root: TreeNode) -&gt; List[List[int]]: levels = [] stack = [] if not root: return levels stack.append((root, 0)) while stack: node, level = stack.pop() if level == len(levels): levels.append([]) levels[level].append(node.val) if node.right: stack.append((node.right, level + 1)) if node.left: stack.append((node.left, level + 1)) return levels 2.1 复杂度分析时间复杂度：假设有n个节点,恰好会递归到每一个节点,因为每个节点恰好会被运算一次,所以时间复杂度为O(n) 空间复杂度：假设有n个节点,数组存储的刚好是每一个节点,栈的存储也是每一个节点,所以空间复杂度为O(n)+O(n) = O(n) 总结这道题考察的就是树的遍历,和前后序遍历差不错,但是就是加多了一个变量来记录层级,还是那句话,多加练习,多加练习!!!!!!","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"递归","slug":"递归","permalink":"https://liangweijiang.github.io/tags/%E9%80%92%E5%BD%92/"},{"name":"树的遍历","slug":"树的遍历","permalink":"https://liangweijiang.github.io/tags/%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86/"}]},{"title":"每日一道算法之--链表反转","slug":"algorithm-206","date":"2020-03-02T10:10:34.816Z","updated":"2020-03-02T10:32:34.192Z","comments":true,"path":"2020/03/02/algorithm-206/","link":"","permalink":"https://liangweijiang.github.io/2020/03/02/algorithm-206/","excerpt":"","text":"反转链表力扣第206题:https://leetcode-cn.com/problems/reverse-linked-list/submissions/ 反转一个单链表。 示例: 输入: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL输出: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL 进阶:你可以迭代或递归地反转链表。你能否用两种方法解决这道题？ 1.递归解决1.1 创建新的节点一开始的时候我的想法是,既然是反转链表,那就可以创建一个新的节点来重新存储,然后直接递归到最后的节点,在不断地回溯中将新节点指向回溯的节点. 123456789101112131415161718192021# Definition for singly-linked list.# class ListNode:# def __init__(self, x):# self.val = x# self.next = Noneclass Solution: new_node = ListNode(0) n = new_node def reverseList(self, head: ListNode) -&gt; ListNode: if not head:return head def foo(head): if not head.next: return head node = foo(head.next) if node: self.n.next = ListNode(node.val) self.n = self.n.next return head foo(head) self.n.next = ListNode(head.val) return self.new_node.next 在测试了几个例子都行的通,我就很兴奋的提交了,结果哦吼,提交时间超时…… 1.2 在原链表处理我就在找原因,有可能是因为创建了新节点,处理时间太长,能不能不用新的节点,直接在原本的链表中去改变指针的指向,当获取到最后的节点时直接处理该节点 逐步递归,知道获取到最后的节点 递归回退的时候,一次改变节点的指针,使该节点的下下个指针指向自己,即node.next.next = node 注意的是,要将该节点的下一个指针删除,一开始我没注意,看了官方题解才知道 1234567class Solution: def reverseList(self, head: ListNode) -&gt; ListNode: if not head or not head.next: return head node = self.reverseList(head.next) head.next.next = head; head.next = None; return node 1.3 复杂度分析时间复杂度：O(n)，假设 n 是列表的长度，要层层递归,那么时间复杂度为 O(n)。 空间复杂度：O(n)，由于使用递归，将会使用隐式栈空间。递归深度可能会达到 nn 层。 2.迭代实现1.1 用栈实现因为栈是先进先出的数据结构,所以先用栈存储每一个节点,然后在依次取出操作 12345678910111213class Solution: def reverseList(self, head: ListNode) -&gt; ListNode: if not head or not head.next: return head stack = [] while head: stack.append(head) head = head.next n = stack.pop() while stack: node = stack.pop() node.next.next = node node.next = None return n 1.1.1 复杂度分析时间复杂度:假设列表长度为n, 进栈的时间复杂度为O(n),出栈的时间复杂度同样为O(n),所以时间复杂度为2*O(n) = O(n) 空间复杂度为:运用了栈的数据结构,所以空间复杂度为O(n)可以看到效率还是不错的 2.2 官方的双指针解法当我们要反转一个链表时,只需要改变每一个节点的前驱和后继指针 12345678910class Solution: def reverseList(self, head: ListNode) -&gt; ListNode: if not head: return None prev &#x3D; None cur &#x3D; head while cur: cur.next&#x3D; prev prev &#x3D; cur cur &#x3D; cur.next return prev 2.2.1 复杂度分析时间复杂度:O(n) 空间复杂度为:O(n)","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"链表","slug":"链表","permalink":"https://liangweijiang.github.io/tags/%E9%93%BE%E8%A1%A8/"},{"name":"递归","slug":"递归","permalink":"https://liangweijiang.github.io/tags/%E9%80%92%E5%BD%92/"}]},{"title":"每日一道算法之--股票问题总结","slug":"algorithm-stock","date":"2020-03-02T07:31:24.558Z","updated":"2020-03-02T10:32:55.199Z","comments":true,"path":"2020/03/02/algorithm-stock/","link":"","permalink":"https://liangweijiang.github.io/2020/03/02/algorithm-stock/","excerpt":"","text":"股票问题总结最近在leetcode刷题的时候发现了一个很好的解决股票问题的题解,所以收藏了这个链接,他主要运用了状态机的思想,从而非常有效的解决股票等dp问题 文章如下: 本文参考自英文版LeetCode：https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/discuss/108870/Most-consistent-ways-of-dealing-with-the-series-of-stock-problems 很多读者抱怨股票系列问题奇技淫巧太多，如果面试真的遇到这类问题，基本不会想到那些巧妙的办法，怎么办？所以本文拒绝奇技淫巧，而是稳扎稳打，只用一种通用方法解决所用问题，以不变应万变。 这篇文章用状态机的技巧来解决，可以全部提交通过。不要觉得这个名词高大上，文学词汇而已，实际上就是 DP table，看一眼就明白了。 先随便抽出一道题，看看别人的解法： 123456789101112int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if(prices.empty()) return 0; int s1=-prices[0],s2=INT_MIN,s3=INT_MIN,s4=INT_MIN; for(int i=1;i&lt;prices.size();++i) &#123; s1 = max(s1, -prices[i]); s2 = max(s2, s1+prices[i]); s3 = max(s3, s2-prices[i]); s4 = max(s4, s3+prices[i]); &#125; return max(0,s4);&#125; 能看懂吧？会做了吗？不可能的，你看不懂，这才正常。就算你勉强看懂了，下一个问题你还是做不出来。为什么别人能写出这么诡异却又高效的解法呢？因为这类问题是有框架的，但是人家不会告诉你的，因为一旦告诉你，你五分钟就学会了，该算法题就不再神秘，变得不堪一击了。 本文就来告诉你这个框架，然后带着你一道一道秒杀。 这 6 道股票买卖问题是有共性的，我们通过对第四题（限制最大交易次数为 k）的分析一道一道解决。因为第四题是一个最泛化的形式，其他的问题都是这个形式的简化。 第一题是只进行一次交易，相当于 k = 1；第二题是不限交易次数，相当于 k = +infinity（正无穷）；第三题是只进行 2 次交易，相当于 k = 2；剩下两道也是不限次数，但是加了交易「冷冻期」和「手续费」的额外条件，其实就是第二题的变种，都很容易处理。 一、穷举框架首先，还是一样的思路：如何穷举？这里的穷举思路和上篇文章递归的思想不太一样。 递归其实是符合我们思考的逻辑的，一步步推进，遇到无法解决的就丢给递归，一不小心就做出来了，可读性还很好。缺点就是一旦出错，你也不容易找到错误出现的原因。比如上篇文章的递归解法，肯定还有计算冗余，但确实不容易找到。 而这里，我们不用递归思想进行穷举，而是利用「状态」进行穷举。我们具体到每一天，看看总共有几种可能的「状态」，再找出每个「状态」对应的「选择」。我们要穷举所有「状态」，穷举的目的是根据对应的「选择」更新状态。听起来抽象，你只要记住「状态」和「选择」两个词就行，下面实操一下就很容易明白了。 1234for 状态1 in 状态1的所有取值： for 状态2 in 状态2的所有取值： for ... dp[状态1][状态2][...] = 择优(选择1，选择2...) 比如说这个问题，每天都有三种「选择」：买入、卖出、无操作，我们用 buy, sell, rest 表示这三种选择。但问题是，并不是每天都可以任意选择这三种选择的，因为 sell 必须在 buy 之后，buy 必须在 sell 之后。那么 rest 操作还应该分两种状态，一种是 buy 之后的 rest（持有了股票），一种是 sell 之后的 rest（没有持有股票）。而且别忘了，我们还有交易次数 k 的限制，就是说你 buy 还只能在 k &gt; 0 的前提下操作。 很复杂对吧，不要怕，我们现在的目的只是穷举，你有再多的状态，老夫要做的就是一把梭全部列举出来。这个问题的「状态」有三个，第一个是天数，第二个是允许交易的最大次数，第三个是当前的持有状态（即之前说的 rest 的状态，我们不妨用 1 表示持有，0 表示没有持有）。然后我们用一个三维数组就可以装下这几种状态的全部组合： 123456789dp[i][k][0 or 1]0 &lt;= i &lt;= n-1, 1 &lt;= k &lt;= Kn 为天数，大 K 为最多交易数此问题共 n × K × 2 种状态，全部穷举就能搞定。for 0 &lt;= i &lt; n: for 1 &lt;= k &lt;= K: for s in &#123;0, 1&#125;: dp[i][k][s] = max(buy, sell, rest) 而且我们可以用自然语言描述出每一个状态的含义，比如说 dp[3][2][1] 的含义就是：今天是第三天，我现在手上持有着股票，至今最多进行 2 次交易。再比如 dp[2][3][0] 的含义：今天是第二天，我现在手上没有持有股票，至今最多进行 3 次交易。很容易理解，对吧？ 我们想求的最终答案是 dp[n - 1][K][0]，即最后一天，最多允许 K 次交易，最多获得多少利润。读者可能问为什么不是 dp[n - 1][K][1]？因为 [1] 代表手上还持有股票，[0] 表示手上的股票已经卖出去了，很显然后者得到的利润一定大于前者。 记住如何解释「状态」，一旦你觉得哪里不好理解，把它翻译成自然语言就容易理解了。 二、状态转移框架现在，我们完成了「状态」的穷举，我们开始思考每种「状态」有哪些「选择」，应该如何更新「状态」。只看「持有状态」，可以画个状态转移图。 123456789101112131415通过这个图可以很清楚地看到，每种状态（0 和 1）是如何转移而来的。根据这个图，我们来写一下状态转移方程：dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i]) max( 选择 rest , 选择 sell )解释：今天我没有持有股票，有两种可能：要么是我昨天就没有持有，然后今天选择 rest，所以我今天还是没有持有；要么是我昨天持有股票，但是今天我 sell 了，所以我今天没有持有股票了。dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i]) max( 选择 rest , 选择 buy )解释：今天我持有着股票，有两种可能：要么我昨天就持有着股票，然后今天选择 rest，所以我今天还持有着股票；要么我昨天本没有持有，但今天我选择 buy，所以今天我就持有股票了。 这个解释应该很清楚了，如果 buy，就要从利润中减去 prices[i]，如果 sell，就要给利润增加 prices[i]。今天的最大利润就是这两种可能选择中较大的那个。而且注意 k 的限制，我们在选择 buy 的时候，把 k 减小了 1，很好理解吧，当然你也可以在 sell 的时候减 1，一样的。 现在，我们已经完成了动态规划中最困难的一步：状态转移方程。如果之前的内容你都可以理解，那么你已经可以秒杀所有问题了，只要套这个框架就行了。不过还差最后一点点，就是定义 base case，即最简单的情况。 12345678dp[-1][k][0] = 0解释：因为 i 是从 0 开始的，所以 i = -1 意味着还没有开始，这时候的利润当然是 0 。dp[-1][k][1] = -infinity解释：还没开始的时候，是不可能持有股票的，用负无穷表示这种不可能。dp[i][0][0] = 0解释：因为 k 是从 1 开始的，所以 k = 0 意味着根本不允许交易，这时候利润当然是 0 。dp[i][0][1] = -infinity解释：不允许交易的情况下，是不可能持有股票的，用负无穷表示这种不可能。 把上面的状态转移方程总结一下： 12345678base case：dp[-1][k][0] = dp[i][0][0] = 0dp[-1][k][1] = dp[i][0][1] = -infinity状态转移方程：dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i])dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i])读者可能会问，这个数组索引是 -1 怎么编程表示出来呢，负无穷怎么表示呢？这都是细节问题，有很多方法实现。现在完整的框架已经完成，下面开始具体化。 三、秒杀题目第一题，k = 1直接套状态转移方程，根据 base case，可以做一些化简： 123456789dp[i][1][0] = max(dp[i-1][1][0], dp[i-1][1][1] + prices[i])dp[i][1][1] = max(dp[i-1][1][1], dp[i-1][0][0] - prices[i]) = max(dp[i-1][1][1], -prices[i])解释：k = 0 的 base case，所以 dp[i-1][0][0] = 0。现在发现 k 都是 1，不会改变，即 k 对状态转移已经没有影响了。可以进行进一步化简去掉所有 k：dp[i][0] = max(dp[i-1][0], dp[i-1][1] + prices[i])dp[i][1] = max(dp[i-1][1], -prices[i]) 直接写出代码： 1234567int n = prices.length;int[][] dp = new int[n][2];for (int i = 0; i &lt; n; i++) &#123; dp[i][0] = Math.max(dp[i-1][0], dp[i-1][1] + prices[i]); dp[i][1] = Math.max(dp[i-1][1], -prices[i]);&#125;return dp[n - 1][0]; 显然 i = 0 时 dp[i-1] 是不合法的。这是因为我们没有对 i 的 base case 进行处理。可以这样处理： 12345678910111213141516171819for (int i = 0; i &lt; n; i++) &#123; if (i - 1 == -1) &#123; dp[i][0] = 0; // 解释： // dp[i][0] // = max(dp[-1][0], dp[-1][1] + prices[i]) // = max(0, -infinity + prices[i]) = 0 dp[i][1] = -prices[i]; //解释： // dp[i][1] // = max(dp[-1][1], dp[-1][0] - prices[i]) // = max(-infinity, 0 - prices[i]) // = -prices[i] continue; &#125; dp[i][0] = Math.max(dp[i-1][0], dp[i-1][1] + prices[i]); dp[i][1] = Math.max(dp[i-1][1], -prices[i]);&#125;return dp[n - 1][0]; 第一题就解决了，但是这样处理 base case 很麻烦，而且注意一下状态转移方程，新状态只和相邻的一个状态有关，其实不用整个 dp 数组，只需要一个变量储存相邻的那个状态就足够了，这样可以把空间复杂度降到 O(1): 12345678910111213// k == 1int maxProfit_k_1(int[] prices) &#123; int n = prices.length; // base case: dp[-1][0] = 0, dp[-1][1] = -infinity int dp_i_0 = 0, dp_i_1 = Integer.MIN_VALUE; for (int i = 0; i &lt; n; i++) &#123; // dp[i][0] = max(dp[i-1][0], dp[i-1][1] + prices[i]) dp_i_0 = Math.max(dp_i_0, dp_i_1 + prices[i]); // dp[i][1] = max(dp[i-1][1], -prices[i]) dp_i_1 = Math.max(dp_i_1, -prices[i]); &#125; return dp_i_0;&#125; 两种方式都是一样的，不过这种编程方法简洁很多。但是如果没有前面状态转移方程的引导，是肯定看不懂的。后续的题目，我主要写这种空间复杂度 O(1) 的解法。 第二题，k = +infinity如果 k 为正无穷，那么就可以认为 k 和 k - 1 是一样的。可以这样改写框架： 1234567dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i])dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i]) = max(dp[i-1][k][1], dp[i-1][k][0] - prices[i])我们发现数组中的 k 已经不会改变了，也就是说不需要记录 k 这个状态了：dp[i][0] = max(dp[i-1][0], dp[i-1][1] + prices[i])dp[i][1] = max(dp[i-1][1], dp[i-1][0] - prices[i]) 直接翻译成代码： 12345678910int maxProfit_k_inf(int[] prices) &#123; int n = prices.length; int dp_i_0 = 0, dp_i_1 = Integer.MIN_VALUE; for (int i = 0; i &lt; n; i++) &#123; int temp = dp_i_0; dp_i_0 = Math.max(dp_i_0, dp_i_1 + prices[i]); dp_i_1 = Math.max(dp_i_1, temp - prices[i]); &#125; return dp_i_0;&#125; 第三题，k = +infinity with cooldown每次 sell 之后要等一天才能继续交易。只要把这个特点融入上一题的状态转移方程即可： 1234567891011121314151617dp[i][0] = max(dp[i-1][0], dp[i-1][1] + prices[i])dp[i][1] = max(dp[i-1][1], dp[i-2][0] - prices[i])解释：第 i 天选择 buy 的时候，要从 i-2 的状态转移，而不是 i-1 。翻译成代码：int maxProfit_with_cool(int[] prices) &#123; int n = prices.length; int dp_i_0 = 0, dp_i_1 = Integer.MIN_VALUE; int dp_pre_0 = 0; // 代表 dp[i-2][0] for (int i = 0; i &lt; n; i++) &#123; int temp = dp_i_0; dp_i_0 = Math.max(dp_i_0, dp_i_1 + prices[i]); dp_i_1 = Math.max(dp_i_1, dp_pre_0 - prices[i]); dp_pre_0 = temp; &#125; return dp_i_0;&#125; 第四题，k = +infinity with fee每次交易要支付手续费，只要把手续费从利润中减去即可。改写方程： 12345678910111213141516dp[i][0] = max(dp[i-1][0], dp[i-1][1] + prices[i])dp[i][1] = max(dp[i-1][1], dp[i-1][0] - prices[i] - fee)解释：相当于买入股票的价格升高了。在第一个式子里减也是一样的，相当于卖出股票的价格减小了。直接翻译成代码：int maxProfit_with_fee(int[] prices, int fee) &#123; int n = prices.length; int dp_i_0 = 0, dp_i_1 = Integer.MIN_VALUE; for (int i = 0; i &lt; n; i++) &#123; int temp = dp_i_0; dp_i_0 = Math.max(dp_i_0, dp_i_1 + prices[i]); dp_i_1 = Math.max(dp_i_1, temp - prices[i] - fee); &#125; return dp_i_0;&#125; 第五题，k = 2k = 2 和前面题目的情况稍微不同，因为上面的情况都和 k 的关系不太大。要么 k 是正无穷，状态转移和 k 没关系了；要么 k = 1，跟 k = 0 这个 base case 挨得近，最后也没有存在感。 这道题 k = 2 和后面要讲的 k 是任意正整数的情况中，对 k 的处理就凸显出来了。我们直接写代码，边写边分析原因。 原始的动态转移方程，没有可化简的地方 12dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i])dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i]) 按照之前的代码，我们可能想当然这样写代码（错误的）： 12345678int k = 2;int[][][] dp = new int[n][k + 1][2];for (int i = 0; i &lt; n; i++) if (i - 1 == -1) &#123; /* 处理一下 base case*/ &#125; dp[i][k][0] = Math.max(dp[i-1][k][0], dp[i-1][k][1] + prices[i]); dp[i][k][1] = Math.max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i]);&#125;return dp[n - 1][k][0]; 为什么错误？我这不是照着状态转移方程写的吗？ 还记得前面总结的「穷举框架」吗？就是说我们必须穷举所有状态。其实我们之前的解法，都在穷举所有状态，只是之前的题目中 k 都被化简掉了。这道题由于没有消掉 k 的影响，所以必须要对 k 进行穷举： 12345678910111213141516int max_k = 2;int[][][] dp = new int[n][max_k + 1][2];for (int i = 0; i &lt; n; i++) &#123; for (int k = max_k; k &gt;= 1; k--) &#123; if (i - 1 == -1) &#123; /* 处理 base case */ dp[i][k][0] = 0; dp[i][k][1] = -prices[i]; continue; &#125; dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i]); dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i]); &#125;&#125;// 穷举了 n × max_k × 2 个状态，正确。return dp[n - 1][max_k][0]; 如果你不理解，可以返回第一点「穷举框架」重新阅读体会一下。 这里 k 取值范围比较小，所以可以不用 for 循环，直接把 k = 1 和 2 的情况手动列举出来也可以： 12345678910111213141516dp[i][2][0] = max(dp[i-1][2][0], dp[i-1][2][1] + prices[i])dp[i][2][1] = max(dp[i-1][2][1], dp[i-1][1][0] - prices[i])dp[i][1][0] = max(dp[i-1][1][0], dp[i-1][1][1] + prices[i])dp[i][1][1] = max(dp[i-1][1][1], -prices[i])int maxProfit_k_2(int[] prices) &#123; int dp_i10 = 0, dp_i11 = Integer.MIN_VALUE; int dp_i20 = 0, dp_i21 = Integer.MIN_VALUE; for (int price : prices) &#123; dp_i20 = Math.max(dp_i20, dp_i21 + price); dp_i21 = Math.max(dp_i21, dp_i10 - price); dp_i10 = Math.max(dp_i10, dp_i11 + price); dp_i11 = Math.max(dp_i11, -price); &#125; return dp_i20;&#125; 有状态转移方程和含义明确的变量名指导，相信你很容易看懂。其实我们可以故弄玄虚，把上述四个变量换成 a, b, c, d。这样当别人看到你的代码时就会一头雾水，大惊失色，不得不对你肃然起敬。 第六题，k = any integer有了上一题 k = 2 的铺垫，这题应该和上一题的第一个解法没啥区别。但是出现了一个超内存的错误，原来是传入的 k 值会非常大，dp 数组太大了。现在想想，交易次数 k 最多有多大呢？ 一次交易由买入和卖出构成，至少需要两天。所以说有效的限制 k 应该不超过 n/2，如果超过，就没有约束作用了，相当于 k = +infinity。这种情况是之前解决过的。 直接把之前的代码重用： 12345678910111213141516171819int maxProfit_k_any(int max_k, int[] prices) &#123; int n = prices.length; if (max_k &gt; n / 2) return maxProfit_k_inf(prices); int[][][] dp = new int[n][max_k + 1][2]; for (int i = 0; i &lt; n; i++) for (int k = max_k; k &gt;= 1; k--) &#123; if (i - 1 == -1) &#123; /* 处理 base case */ dp[i][k][0] = 0; dp[i][k][1] = -prices[i]; continue; &#125; dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i]); dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i]); &#125; return dp[n - 1][max_k][0];&#125; 至此，6 道题目通过一个状态转移方程全部解决。 四、最后总结本文给大家讲了如何通过状态转移的方法解决复杂的问题，用一个状态转移方程秒杀了 6 道股票买卖问题，现在想想，其实也不算难对吧？这已经属于动态规划问题中较困难的了。 关键就在于列举出所有可能的「状态」，然后想想怎么穷举更新这些「状态」。一般用一个多维 dp 数组储存这些状态，从 base case 开始向后推进，推进到最后的状态，就是我们想要的答案。想想这个过程，你是不是有点理解「动态规划」这个名词的意义了呢？ 具体到股票买卖问题，我们发现了三个状态，使用了一个三维数组，无非还是穷举 + 更新，不过我们可以说的高大上一点，这叫「三维 DP」，怕不怕？这个大实话一说，立刻显得你高人一等，名利双收有没有。 所以，大家不要被各种高大上的名词吓到，再多的困难问题，奇技淫巧，也不过是基本套路的不断升级组合产生的。只要把住算法的底层原理，即可举一反三，逐个击破。 买卖股票的最佳时机 买卖股票的最佳时机 II 买卖股票的最佳时机 III 买卖股票的最佳时机 IV 最佳买卖股票时机含冷冻期 买卖股票的最佳时机含手续费 作者：labuladong链接：https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/solution/yi-ge-fang-fa-tuan-mie-6-dao-gu-piao-wen-ti-by-l-3/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"https://liangweijiang.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"状态机","slug":"状态机","permalink":"https://liangweijiang.github.io/tags/%E7%8A%B6%E6%80%81%E6%9C%BA/"}]},{"title":"每日一道算法之--无重复的最长的子字符串","slug":"algorithm-3","date":"2020-02-29T08:59:16.674Z","updated":"2020-03-11T12:30:29.188Z","comments":true,"path":"2020/02/29/algorithm-3/","link":"","permalink":"https://liangweijiang.github.io/2020/02/29/algorithm-3/","excerpt":"","text":"无重复的最长的子字符串力扣第3题:https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/ 1 暴力解决暴力方法就是将所有的肯恩列举出来,在会超过时间限制,这里就不列举了 2 滑动窗口这道题是我第一道碰到的滑动窗口的题目,当时想了很久都想不出来,后来去看一一下别人的题解恍然大悟,滑动窗口确实是解决字符串问题的一非常好的方法 滑动窗口的顾名思义就是可以滑动的数据结构,遍历整个字符串,当滑动窗口里没有该字符时,就将该字符加进滑动窗口 当遇到有重复字符时,要将滑动窗口该字符前面的的字符(包括该字符)全部去除,然后在将该字符加进滑动窗口 代码如下: 1234567891011121314151617181920class Solution: def lengthOfLongestSubstring(self, s: str) -&gt; int: # 集合可以保证唯一性 silde_win = set() # 设置滑动窗口的值 left = 0 # 记录最长子串的长度 max_len = 0 # 记录当前的子串长度 cur_len = 0 for i in range(len(s)): cur_len += 1 # 设置滑动窗口的值 while s[i] in silde_win: silde_win.remove(s[left]) left += 1 cur_len -= 1 silde_win.add(s[i]) max_len = max(max_len, cur_len) return max_len 2.1 复杂度分析时间复杂度:遍历了一次数组,时间复杂度为$$0(N)$$, 但是每次滑动窗口的都有重复字符,如字符串为’aaaaaaaaaaaaaaaaaaa’,会浪费没必要的时间,但是均摊时间复杂度依然为$$O(N)$$ 空间复杂度:用了集合,所以空间复杂度为$$O(N)$$ 滑动窗口的优化可以看到提交的成绩不是很理想,所以我一直在想着怎么优化,想到了几个优化方法 如果字符串有相邻的子串,直接忽视123456789101112131415161718192021222324class Solution: def lengthOfLongestSubstring(self, s: str) -&gt; int: if not s :return 0 silde_win = set() left = 0 max_len = 0 cur_len = 0 for i in range(len(s)): # 如果字符串有相邻的子串,直接忽视 if i &gt; 0 and s[i-1] == s[i]: silde_win = set() silde_win.add(s[i]) left = i cur_len = 1 continue cur_len += 1 # 设置滑动窗口的值 while s[i] in silde_win: silde_win.remove(s[left]) left += 1 cur_len -= 1 silde_win.add(s[i]) max_len = max(max_len, cur_len) return max_len 可以发现成绩有了提升,但不是很明显 然后在看看我么你写的代码,silde_win这个数据结构其实是有很多操作的,话费了很多时间,换个思路想一想,我们能又能用更好地数据结构来代替这个集合呢,其实这个滑动窗口只是一个辅助的数据结构,只是用来暂时存储字符串的字串的,那为什么不直接用分片呢 123456789101112131415161718192021class Solution: def lengthOfLongestSubstring(self, s: str) -&gt; int: if not s :return 0 # 设置滑动窗口的值 left = 0 # 记录最长子串的长度 max_len = 0 # 记录当前的子串长度 cur_len = 0 for i in range(len(s)): if i &gt; 0 and s[i-1] == s[i]: left = i cur_len = 1 continue cur_len += 1 # 设置滑动窗口的值 while s[i] in s[left:i]: left += 1 cur_len -= 1 max_len = max(max_len, cur_len) return max_len 相似题目76.最小覆盖子串 159. 至多包含两个不同字符的最长子串 340. 至多包含 K 个不同字符的最长子串","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"滑动窗口","slug":"滑动窗口","permalink":"https://liangweijiang.github.io/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"}]},{"title":"每日一道算法之--买卖股票的最佳时机","slug":"algorithm-121","date":"2020-02-29T07:25:08.775Z","updated":"2020-03-02T10:29:59.799Z","comments":true,"path":"2020/02/29/algorithm-121/","link":"","permalink":"https://liangweijiang.github.io/2020/02/29/algorithm-121/","excerpt":"","text":"买卖股票的最佳时机力扣第121题：https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。 如果你最多只允许完成一笔交易（即买入和卖出一支股票），设计一个算法来计算你所能获取的最大利润。 注意你不能在买入股票前卖出股票。 示例 1: 输入: [7,1,5,3,6,4]输出: 5解释: 在第 2 天（股票价格 = 1）的时候买入，在第 5 天（股票价格 = 6）的时候卖出，最大利润 = 6-1 = 5 。 注意利润不能是 7-1 = 6, 因为卖出价格需要大于买入价格。 示例 2： 输入: [7,6,4,3,1]输出: 0解释: 在这种情况下, 没有交易完成, 所以最大利润为 0 1 暴力方法暴力方法简单容易理解，只是两次循环把所有的可能一一列举出来。然后在取其中的最大值 12345678class Solution: def maxProfit(self, prices: List[int]) -&gt; int: max_profit = 0 for i in range(len(prices) - 1): for j in range(i + 1, len(prices)): profit = prices[j] - prices[i] max_profit = max(max_profit, profit) return max_profit 1.1 复杂度分析时间复杂度:循环里嵌套另一个循环,所里时间复杂度为$$O(N^2)$$ 空间复杂度:只使用了max_profit和profit两个变量,所以空间复杂度为$$O(1)$$ 2 动态规划遍历一次 由题意不难理解,当前最大的收益就是你当前的价格减去之前的最小价格,所以定义一个变量min_price存储之前的最小值,在定义一个变量max_profit存储最大的收益值,便可以达到遍历一次 状态转移方程为dp[i] = max(dp[i-1]+diff[i], 0), dp[i])指以i元素结尾的子数组的最大和 12345678class Solution: def maxProfit(self, prices: List[int]) -&gt; int: min_price = float('inf') max_profit = 0 for i in range(len(prices)): min_price = min(prices[i], min_price) max_profit = max(max_profit, prices[i]-min_price) return max_profit 2.1 复杂度分析时间复杂度:遍历了一次数组,所以时间复杂度为$$O(N)$$ 空间复杂度:只使用了min_price和max_profit两个变量,所以空间复杂度为$$O(1)$$","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"https://liangweijiang.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"}]},{"title":"DRF源码解析6--权限组件的封装和初始化","slug":"DRF-06","date":"2020-02-26T09:55:17.825Z","updated":"2020-02-26T09:56:50.508Z","comments":true,"path":"2020/02/26/DRF-06/","link":"","permalink":"https://liangweijiang.github.io/2020/02/26/DRF-06/","excerpt":"","text":"1.权限组件的初始化在前面的版本控制和认证组件里提到的initia初始化函数, 同时也对权限组件进行了初始化 1234567def initial(self, request, *args, **kwargs): # 认证组件 self.perform_authentication(request) # 权限组件 self.check_permissions(request) # 频率 self.check_throttles(request) 1.1 check_permissions可以看到,check_permissions函数就是初始化权限组件的函数了 123456789 def check_permissions(self, request): for permission in self.get_permissions():# permission_denied函数抛出异常# 说明权限组件中必须包含has_permission的方法# 同时说明这是DRF框架给我们提供的自定义权限组件的钩子 if not permission.has_permission(request, self): self.permission_denied( request, message=getattr(permission, 'message', None) ) 1.2 get_permissions可以看出,权限组件在self.get_permissions方法中获取 12def get_permissions(self): return [permission() for permission in self.permission_classes] 可以看到,这个和认证组件的获取方法是一样的,只是没有认证组件那么绕 2. 权限组件的类型DRF提供的权限组件在rest_framework.permissions中,如下图可以看到, has_permission方法返回的是布尔类型 #总结DRF的权限组件比较简单,和认证组件大致一样","categories":[{"name":"django-rest-framework","slug":"django-rest-framework","permalink":"https://liangweijiang.github.io/categories/django-rest-framework/"}],"tags":[{"name":"DRF","slug":"DRF","permalink":"https://liangweijiang.github.io/tags/DRF/"}]},{"title":"每日一道算法之--乘积最大子序和","slug":"algorithm-152","date":"2020-02-26T09:08:00.357Z","updated":"2020-03-02T10:32:21.176Z","comments":true,"path":"2020/02/26/algorithm-152/","link":"","permalink":"https://liangweijiang.github.io/2020/02/26/algorithm-152/","excerpt":"","text":"乘积最大子序和力扣第152题:https://leetcode-cn.com/problems/maximum-product-subarray/给定一个整数数组 nums ，找出一个序列中乘积最大的连续子序列（该序列至少包含一个数）。 示例 1: 输入: [2,3,-2,4]输出: 6解释: 子数组 [2,3] 有最大乘积 6。 示例 2: 输入: [-2,0,-1]输出: 0解释: 结果不能为 2, 因为 [-2,-1] 不是子数组。 1. 类似指针的解法参考力扣第53题最大子序和的其中一种双指针解法,这道题同样可以用类似指针的解法 首先定义一个res记录最大的子序和,cur_pos记录当前的乘积 然后cur_pos依次累乘, 每一次的结果都有三种情况: cur_pos等于0, 这时候要重新将指针偏移后一位 cur_pos大于0, 这时候要更新res的结果,就是和cur_pos比较大小 cur_pos小于0, 负负得正,需要找到指针前面最大的负数,相除就变为最大 12345678910111213141516171819202122232425262728class Solution: def maxProduct(self, nums: List[int]) -&gt; int: if not nums: return 0 # 目前的累乘 cur_pro = 1 # 前面最大的负数 max_neg = float(\"-inf\") # 结果 res = float(\"-inf\") for num in nums: cur_pro *= num # 考虑三种情况 # 大于0 if cur_pro &gt; 0: res = max(res, cur_pro) # 小于0 elif cur_pro &lt; 0: if max_neg != float(\"-inf\"): res = max(res, cur_pro // max_neg) else: res = max(res, num) max_neg = max(max_neg, cur_pro) # 等于0 else: cur_pro = 1 max_neg = float(\"-inf\") res = max(res, num) return res 1.1 复杂度分析时间复杂度:遍历整个数组的时间复杂度为O(N)空间复杂度:没有用到额外的数据结构,所以空间复杂度为O(1) 2. 动态规划解决不难发现,每一个元素的乘积,最大值只可能在自身或者自身与上一次的累乘之中公式如下: dp_max[i] = Math.max(nums[i-1],dp_max[i-1]*nums[i-1]) 因为存在负数,所以当这个元素为负数是,其最大乘积可能是与上一次最小乘积相乘所以不仅要定义一个变量存储最大当前的最大累乘,还要定义一个变量存储当前的最小累乘 12345678910111213141516class Solution: def maxProduct(self, nums: List[int]) -&gt; int: if not nums: return 0 # 存储最后的结果 res = nums[0] # 存储最大当前的最大累乘 res_max = nums[0] # 存储当前的最小累乘 res_min = nums[0] for num in nums[1:]: cur_max = max(res_max*num, res_min*num, num) cur_min = min(res_max*num, res_min*num, num) res = max(res, cur_max) res_max = cur_max res_min = cur_min return res 2.1 复杂度分析时间复杂度:遍历整个数组的时间复杂度为O(N)空间复杂度:没有用到额外的数据结构,所以空间复杂度为O(1)","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"https://liangweijiang.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"指针","slug":"指针","permalink":"https://liangweijiang.github.io/tags/%E6%8C%87%E9%92%88/"}]},{"title":"DRF源码解析5--认证组件的封装和初始化","slug":"DRF-05","date":"2020-02-24T12:59:20.730Z","updated":"2020-02-26T09:41:53.685Z","comments":true,"path":"2020/02/24/DRF-05/","link":"","permalink":"https://liangweijiang.github.io/2020/02/24/DRF-05/","excerpt":"","text":"1.认证组件的初始化在对DRF的版本认证里说到,initial()不仅对版本认证组件进行了初始化,同时还初始化了认证组件,现在来分析一下DRF是怎么样初始化认证方法的 12def perform_authentication(self, request): request.user 可以看到,perform_authentication()方法返回了request(相当于封装的Request),进入request中找到uesr方法 1.1 截取Request部分代码如下:123456789101112131415161718192021222324252627class Request: def __init__(self, request, parsers=None, authenticators=None, negotiator=None, parser_context=None): assert isinstance(request, HttpRequest), ( 'The `request` argument must be an instance of ' '`django.http.HttpRequest`, not `&#123;&#125;.&#123;&#125;`.' .format(request.__class__.__module__, request.__class__.__name__) ) self._request = request self.parsers = parsers or () self.authenticators = authenticators or () self.negotiator = negotiator or self._default_negotiator() @property def user(self): if not hasattr(self, '_user'): with wrap_attributeerrors(): self._authenticate() return self._user @user.setter def user(self, value): # 当调用user时触发, 如user = 'xxx', 则value = 'xxx' self._user = value self._request.user = value 可以看到,user执行了self._authenticate方法,返回的_user为当前用户 截取self._authenticate的代码如下:12345678910111213 def _authenticate(self): for authenticator in self.authenticators: try:# 这里是调用默认的认证组件里的authenticate方法 user_auth_tuple = authenticator.authenticate(self) except exceptions.APIException: self._not_authenticated() raise if user_auth_tuple is not None: self._authenticator = authenticator self.user, self.auth = user_auth_tuple return self.authenticators为Request的属性,所以在init中可以找到 123def __init__(self, request, parsers=None, authenticators=None, negotiator=None, parser_context=None): self.authenticators = authenticators or () authenticators是作为参数传进来的,所以回到实例化Request的initialize_request方法中 12345678910def initialize_request(self, request, *args, **kwargs): parser_context = self.get_parser_context(request) return Request( request, parsers=self.get_parsers(), authenticators=self.get_authenticators(), negotiator=self.get_content_negotiator(), parser_context=parser_context ) 可以看到,authenticators传进了一个self.get_authenticators的方法 1.2 截取self.get_authenticators代码如下12def get_authenticators(self): return [auth() for auth in self.authentication_classes] 可以看到,get_authenticators方法返回了self.authentication_classes中所有auth的执行结果的一个列表, 而self.authentication_classes则为DRF中默认的认证组件 authenticate回到_authenticate方法中,现在已经知道authenticator是DRF默认的认证组件,则进去其authenticate方法中 12345678class ForcedAuthentication: def __init__(self, force_user, force_token): self.force_user = force_user self.force_token = force_token def authenticate(self, request): return (self.force_user, self.force_token) 其返回了self.force_user, self.force_token,分别为用户和验证用户信息的的token码,说明了认证组件都带有authenticate方法并且返回用户认证的信息 1.3 思路总结DRF认证组件的初始化主要分为两部分: 2. 认证组件的类型DRF提供的认证组件在rest_framework.authentication中 2.1 BaseAuthentication1234567class BaseAuthentication: def authenticate(self, request): raise NotImplementedError(\".authenticate() must be overridden.\") def authenticate_header(self, request): pass 可以看出,authenticate方法就是自定制认证组件的钩子函数 2.2 SessionAuthentication1234567891011121314151617181920212223242526class SessionAuthentication(BaseAuthentication): def authenticate(self, request): # 重写了authenticate方法并获取当前的用户信息 # Get the session-based user from the underlying HttpRequest object user = getattr(request._request, 'user', None) # Unauthenticated, CSRF validation not required if not user or not user.is_active: return None # 执行enforce_csrf方法判断用户的csrf_token是否正确 self.enforce_csrf(request) # CSRF passed with authenticated user return (user, None) def enforce_csrf(self, request): check = CSRFCheck() # populates request.META['CSRF_COOKIE'], which is used in process_view() # 中间件的process_request方法,拿取用户的CSRF_COOKIE check.process_request(request) # 认证用户的CSRF_COOKIE是否正确 reason = check.process_view(request, None, (), &#123;&#125;) if reason: # CSRF failed, bail with explicit error message raise exceptions.PermissionDenied('CSRF Failed: %s' % reason) 总结DRF的认证组件就是通过中间件等方法,获取当前用户的认证信息,在与本地的信息进行对比,从而达到认证用户的目的。","categories":[{"name":"django-rest-framework","slug":"django-rest-framework","permalink":"https://liangweijiang.github.io/categories/django-rest-framework/"}],"tags":[{"name":"DRF","slug":"DRF","permalink":"https://liangweijiang.github.io/tags/DRF/"}]},{"title":"每日一道算法之--三数之和","slug":"algorithm-15","date":"2020-02-24T09:25:51.544Z","updated":"2020-03-02T10:30:37.376Z","comments":true,"path":"2020/02/24/algorithm-15/","link":"","permalink":"https://liangweijiang.github.io/2020/02/24/algorithm-15/","excerpt":"","text":"三数之和力扣第15题：https://leetcode-cn.com/problems/3sum/给定一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？找出所有满足条件且不重复的三元组。 注意：答案中不可以包含重复的三元组。 示例： 给定数组 nums = [-1, 0, 1, 2, -1, -4]，满足要求的三元组集合为：[ [-1, 0, 1], [-1, -1, 2]] 1. 排序 + 双指针解法题目中的要求是不能含有相同的三元组，所以在算法中我们需要去重，排序是一个很好的方法，因为排序可以让相同的数连载一起，方便判断去重。让后在通过双指针对数组一一检查，找到所有合适的三元组。 1234567891011121314151617181920212223242526272829class Solution: def threeSum(self, nums: List[int]) -&gt; List[List[int]]: # 先将nums排序 nums.sort() res = [] for i in range(len(nums) - 2): # 设置两个指针 l, r = i + 1, len(nums) - 1 if nums[i] &gt; 0 : return res # 去除重复的判断,因为nums[i -1]已经包含了nums[i]的所有组合的可能性 if i &gt; 0 and nums[i] == nums[i - 1] : continue while l &lt; r: s = nums[i] + nums[l] + nums[r] if s &lt; 0: # 如果和小于0，证明左边的数太小了，需要往后移 l += 1 # 去除重复的判断，但是前提条件为l&lt;r while l &lt; r and nums[l] == nums[l - 1]: l += 1 elif s &gt; 0: r -= 1 # 如果和大于0，证明右边的数太大了，需要往前移 while l &lt; r and nums[r] == nums[r + 1]: r -= 1 else: res.append([nums[i], nums[l], nums[r]]) l += 1 r -= 1 while l &lt; r and nums[l] == nums[l - 1]: l += 1 while l &lt; r and nums[r] == nums[r + 1]: r -= 1 return res 1.1 时间复杂度分析 时间复杂度：排序的时间复杂度为 O(NlogN), 遍历数组为O(N),双指针的遍历为O(N),所以总的时间复杂度为$$O(NlogN)+0(N)*O(N) = O(N^2)$$ 空间复杂度：没有用到额外的数据结构，所以空间复杂度为$$O(1)$$ 2.哈希索引的方法（空间换时间）参考两数之和，我们可以构建哈希表的方法使查找效率变得更高。 12345678910111213141516171819202122232425262728class Solution: def threeSum(self, nums: List[int]) -&gt; List[List[int]]: if len(nums) &lt; 3: return [] nums.sort() # 因为a+b = 0等价于a = -b target_hash = &#123;-x: i for i, x in enumerate(nums)&#125; res = [] res_hash = &#123;&#125; # 从零开始检索,到倒数第二位结束 for i, first in enumerate(nums[:-1]): if nums[i] &gt; 0: return res if i &gt; 0 and first == nums[i - 1]: continue #从第一个指针的下一位开始搜索 for j, second in enumerate(nums[i + 1:]): # 检查两数之和是否存在于哈希表target_hash中 if first + second in target_hash: target_index = target_hash[first + second] if target_index == i or target_index == i + j + 1: continue # 将找到的结果存入另一个哈希表中, 避免包含重复结果 row = sorted([first, second, nums[target_index]]) key = \",\".join([str(x) for x in row]) if key not in res_hash: res.append(row) res_hash[key] = True return res","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://liangweijiang.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"双指针","slug":"双指针","permalink":"https://liangweijiang.github.io/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"},{"name":"哈希表","slug":"哈希表","permalink":"https://liangweijiang.github.io/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"},{"name":"排序","slug":"排序","permalink":"https://liangweijiang.github.io/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"DRF源码解析4--版本控制组件的封装","slug":"DRF-04","date":"2020-02-22T14:09:24.712Z","updated":"2020-02-22T14:11:09.294Z","comments":true,"path":"2020/02/22/DRF-04/","link":"","permalink":"https://liangweijiang.github.io/2020/02/22/DRF-04/","excerpt":"","text":"一.DRF中APIView的initial()方法初始化版本信息在讲到DRF对ruquest的封装时,返回新封装的Request后,DRF执行了initial()方法对组件的初始化 12345678910111213def initial(self, request, *args, **kwargs): # 版本控制组件 version, scheme = self.determine_version(request, *args, **kwargs) # 将版本空值信息写入request中 request.version, request.versioning_scheme = version, scheme # Ensure that the incoming request is permitted # 认证组件 self.perform_authentication(request) # 权限组件 self.check_permissions(request) # 频率 self.check_throttles(request) 1.1重写determine_version()自定制版本信息12345678910 def determine_version(self, request, *args, **kwargs): \"\"\" If versioning is being used, then determine any API version for the incoming request. Returns a two-tuple of (version, versioning_scheme) \"\"\" if self.versioning_class is None: return (None, None)# self.versioning_class是drf配置默认的类,说明我们自定义版本时要重写这个方法 scheme = self.versioning_class() return (scheme.determine_version(request, *args, **kwargs), scheme) 二.rest_framework.versioning提供的版本控制方法 2.1 BaseVersioning1234567891011121314151617181920212223class BaseVersioning: # default_version(None), allowed_versions(None), version_param可以在settings中重新配置 default_version = api_settings.DEFAULT_VERSION allowed_versions = api_settings.ALLOWED_VERSIONS version_param = api_settings.VERSION_PARAM def determine_version(self, request, *args, **kwargs): # 在继承该类时要重写determine_version(方法) msg = '&#123;cls&#125;.determine_version() must be implemented.' raise NotImplementedError(msg.format( cls=self.__class__.__name__ )) def reverse(self, viewname, args=None, kwargs=None, request=None, format=None, **extra): # 和django.urls.reverse大致相同, # 但可以选择接受一个请求并返回使用请求获取基本URL的标准URL。 return _reverse(viewname, args, kwargs, request, format, **extra) def is_allowed_version(self, version): if not self.allowed_versions: return True return ((version is not None and version == self.default_version) or (version in self.allowed_versions)) 2.2 URLPathVersioning1234567891011121314151617181920212223242526272829303132333435363738class URLPathVersioning(BaseVersioning): \"\"\" To the client this is the same style as `NamespaceVersioning`. The difference is in the backend - this implementation uses Django's URL keyword arguments to determine the version. An example URL conf for two views that accept two different versions. 可以看到版本信息就在url中 urlpatterns = [ url(r'^(?P&lt;version&gt;[v1|v2]+)/users/$', users_list, name='users-list'), url(r'^(?P&lt;version&gt;[v1|v2]+)/users/(?P&lt;pk&gt;[0-9]+)/$', users_detail, name='users-detail') ] GET /1.0/something/ HTTP/1.1 Host: example.com Accept: application/json \"\"\" invalid_version_message = _('Invalid version in URL path.') def determine_version(self, request, *args, **kwargs): # self.version_param,self.default_version是父类中的属性,可以自定义 version = kwargs.get(self.version_param, self.default_version) if version is None: # 如果没有自己配置默认为DRF默认的版本信息 version = self.default_version if not self.is_allowed_version(version): raise exceptions.NotFound(self.invalid_version_message) return version def reverse(self, viewname, args=None, kwargs=None, request=None, format=None, **extra): if request.version is not None: kwargs = &#123;&#125; if (kwargs is None) else kwargs # self.version_param就是版本的key kwargs[self.version_param] = request.version return super().reverse( viewname, args, kwargs, request, format, **extra 其他的类基本配置都差不多","categories":[{"name":"django-rest-framework","slug":"django-rest-framework","permalink":"https://liangweijiang.github.io/categories/django-rest-framework/"}],"tags":[{"name":"DRF","slug":"DRF","permalink":"https://liangweijiang.github.io/tags/DRF/"}]},{"title":"DRF源码解析3--routers对路由的封装","slug":"DRF-03","date":"2020-02-20T15:15:11.102Z","updated":"2020-02-20T15:16:50.088Z","comments":true,"path":"2020/02/20/DRF-03/","link":"","permalink":"https://liangweijiang.github.io/2020/02/20/DRF-03/","excerpt":"","text":"当我们想最方便的使用drf的路由的时候,只需要用DefaultRoute实例化一个路由实例,然后注册,再讲注册后的组件加入urlpatterns即可 123456from rest_framework.routers import DefaultRouterrouter = DefaultRouter()# 其中BookModelView继承了viewsets.ModelViewSetrouter.register(r'^book', views.BookModelView)urlpatterns += router.urls 到底routers底层是怎么样实现的呢 routersDefaultRoute是routers组件里的一个类,相当于帮助我们在路由里构建好了如{‘list’:”create”}的对应关系,它继承了SimpleRouter,截取源码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102class SimpleRouter(BaseRouter): routes = [ # List route. Route( url=r'^&#123;prefix&#125;&#123;trailing_slash&#125;$', # 这里构建好了对应关系 mapping=&#123; 'get': 'list', 'post': 'create' &#125;, name='&#123;basename&#125;-list', detail=False, initkwargs=&#123;'suffix': 'List'&#125; ), def __init__(self, trailing_slash=True): self.trailing_slash = '/' if trailing_slash else '' super().__init__() def get_default_basename(self, viewset): \"\"\" If `basename` is not specified, attempt to automatically determine it from the viewset. \"\"\" queryset = getattr(viewset, 'queryset', None) assert queryset is not None, '`basename` argument not specified, and could ' \\ 'not automatically determine the name from the viewset, as ' \\ 'it does not have a `.queryset` attribute.' return queryset.model._meta.object_name.lower() def get_routes(self, viewset): # 获取对应关系 known_actions = list(flatten([route.mapping.values() for route in self.routes if isinstance(route, Route)])) # 找出viewsets里所有的方法 extra_actions = viewset.get_extra_actions() # checking action names against the known actions list # 判断路由的方法对应的viewsets的方法 not_allowed = [ action.__name__ for action in extra_actions if action.__name__ in known_actions ] if not_allowed: msg = ('Cannot use the @action decorator on the following ' 'methods, as they are existing routes: %s') raise ImproperlyConfigured(msg % ', '.join(not_allowed)) # partition detail and list actions detail_actions = [action for action in extra_actions if action.detail] list_actions = [action for action in extra_actions if not action.detail] routes = [] for route in self.routes: if isinstance(route, DynamicRoute) and route.detail: routes += [self._get_dynamic_route(route, action) for action in detail_actions] elif isinstance(route, DynamicRoute) and not route.detail: routes += [self._get_dynamic_route(route, action) for action in list_actions] else: routes.append(route) return routes def get_urls(self): \"\"\" Use the registered viewsets to generate a list of URL patterns. \"\"\" ret = [] # 这里的self.registry是父类BaseRouter的一个属性 for prefix, viewset, basename in self.registry: lookup = self.get_lookup_regex(viewset) routes = self.get_routes(viewset) # 这里是对路径进行了不同形式的封装 for route in routes: # Only actions which actually exist on the viewset will be bound mapping = self.get_method_map(viewset, route.mapping) if not mapping: continue # Build the url pattern regex = route.url.format( prefix=prefix, lookup=lookup, trailing_slash=self.trailing_slash ) if not prefix and regex[:2] == '^/': regex = '^' + regex[2:] initkwargs = route.initkwargs.copy() initkwargs.update(&#123; 'basename': basename, 'detail': route.detail, &#125;) view = viewset.as_view(mapping, **initkwargs) name = route.name.format(basename=basename) ret.append(url(regex, view, name=name)) return ret 进入BaseRouter中,截取源码如下: 1234567891011121314151617181920212223242526272829303132333435class BaseRouter: def __init__(self): # SimpleRouter的get_urls中的需要的属性 self.registry = [] def register(self, prefix, viewset, basename=None): # 如果没有basename,则self.get_default_basename()方法 # get_default_basename()方法就是报错要求basename必须有, # 从而看得出来要想使用router组件必须执行register()方法 if basename is None: basename = self.get_default_basename(viewset) self.registry.append((prefix, viewset, basename)) # invalidate the urls cache if hasattr(self, '_urls'): del self._urls def get_default_basename(self, viewset): \"\"\" If `basename` is not specified, attempt to automatically determine it from the viewset. \"\"\" raise NotImplementedError('get_default_basename must be overridden') def get_urls(self): \"\"\" Return a list of URL patterns, given the registered viewsets. \"\"\" raise NotImplementedError('get_urls must be overridden') @property def urls(self): if not hasattr(self, '_urls'): self._urls = self.get_urls() return self._urls DefaultRoute类进行了更好的优化 123456789101112131415161718192021222324252627282930313233343536373839404142class DefaultRouter(SimpleRouter): \"\"\" The default router extends the SimpleRouter, but also adds in a default API root view, and adds format suffix patterns to the URLs. \"\"\" include_root_view = True include_format_suffixes = True root_view_name = 'api-root' default_schema_renderers = None APIRootView = APIRootView APISchemaView = SchemaView SchemaGenerator = SchemaGenerator def __init__(self, *args, **kwargs): if 'root_renderers' in kwargs: self.root_renderers = kwargs.pop('root_renderers') else: self.root_renderers = list(api_settings.DEFAULT_RENDERER_CLASSES) super().__init__(*args, **kwargs) def get_api_root_view(self, api_urls=None): \"\"\" Return a basic root view. \"\"\" api_root_dict = OrderedDict() list_name = self.routes[0].name for prefix, viewset, basename in self.registry: api_root_dict[prefix] = list_name.format(basename=basename) return self.APIRootView.as_view(api_root_dict=api_root_dict) def get_urls(self): urls = super().get_urls() if self.include_root_view: view = self.get_api_root_view(api_urls=urls) root_url = url(r'^$', view, name=self.root_view_name) urls.append(root_url) if self.include_format_suffixes: urls = format_suffix_patterns(urls) return urls 最后路由组件创建了怎么样的url?","categories":[{"name":"django-rest-framework","slug":"django-rest-framework","permalink":"https://liangweijiang.github.io/categories/django-rest-framework/"}],"tags":[{"name":"DRF","slug":"DRF","permalink":"https://liangweijiang.github.io/tags/DRF/"}]},{"title":"DRF源码解析2--viewsets.ModelViewSet对视图的封装","slug":"DRF-02","date":"2020-02-19T13:47:47.427Z","updated":"2020-02-19T15:08:42.664Z","comments":true,"path":"2020/02/19/DRF-02/","link":"","permalink":"https://liangweijiang.github.io/2020/02/19/DRF-02/","excerpt":"","text":"viewsetsdrf中 viewsets 对 view 进行了更加深层的封装,在CBV编程中减少代码的冗余,截取viewsets源码如下 12345678class ModelViewSet(mixins.CreateModelMixin, mixins.RetrieveModelMixin, mixins.UpdateModelMixin, mixins.DestroyModelMixin, mixins.ListModelMixin, GenericViewSet):# 可以看到viewsets中的ModelViewSet只是继承了各种类,每一个类对应CBV的每一个方法,如CreateModelMixin则对应post方法 pass 进入GenericViewSet的源码中,不难发现,GenericViewSet这个类主要是获取我们的数据和处理数据的组件 123class GenericViewSet(ViewSetMixin, generics.GenericAPIView): # GenericViewSet同样是继承了两个类 pass 进入generics.GenericAPIView 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class GenericAPIView(views.APIView): # queryset就是获取的ORM对象 queryset = None # serializer_class是序列化的类 serializer_class = None lookup_field = 'pk' lookup_url_kwarg = None # The filter backend classes to use for queryset filtering filter_backends = api_settings.DEFAULT_FILTER_BACKENDS # The style to use for queryset pagination. # pagination_class就是和分页组件相关的类,默认为drf配置中的组件 pagination_class = api_settings.DEFAULT_PAGINATION_CLASS def get_queryset(self): # 这里断言就是为了说明在继承这个类时,一定要有queryset属性或覆盖这个方法 assert self.queryset is not None, ( \"'%s' should either include a `queryset` attribute, \" \"or override the `get_queryset()` method.\" % self.__class__.__name__ ) # 获取ORM对象 queryset = self.queryset if isinstance(queryset, QuerySet): # Ensure queryset is re-evaluated on each request. queryset = queryset.all() return queryset def get_serializer(self, *args, **kwargs): serializer_class = self.get_serializer_class() kwargs['context'] = self.get_serializer_context() # serializer_class接收的参数可能不同 return serializer_class(*args, **kwargs) def get_serializer_class(self): # 继承这个类时,一定要有serializer_classt属性或覆盖这个方法 assert self.serializer_class is not None, ( \"'%s' should either include a `serializer_class` attribute, \" \"or override the `get_serializer_class()` method.\" % self.__class__.__name__ ) return self.serializer_class def get_serializer_context(self): return &#123; 'request': self.request, 'format': self.format_kwarg, 'view': self &#125; def filter_queryset(self, queryset): for backend in list(self.filter_backends): queryset = backend().filter_queryset(self.request, queryset, self) return queryset 接着回到ModelViewSet中,进入到mixins.CreateModelMixin的源码中 1234567891011121314151617181920class CreateModelMixin: \"\"\" Create a model instance. \"\"\" def create(self, request, *args, **kwargs): # 这里调用的就是GenericAPIView中的get_serializer serializer = self.get_serializer(data=request.data) serializer.is_valid(raise_exception=True) self.perform_create(serializer) headers = self.get_success_headers(serializer.data) return Response(serializer.data, status=status.HTTP_201_CREATED, headers=headers) def perform_create(self, serializer): serializer.save() def get_success_headers(self, data): try: return &#123;'Location': str(data[api_settings.URL_FIELD_NAME])&#125; except (TypeError, KeyError): return &#123;&#125; 现在我们只需要继承ModelViewSet,然后重写queryset和处理数据所需要的组件类如序列化的类等,但是怎么将self.post对应上self.list方法呢,GenericViewSet还继承了ViewSetMixin,看一下ViewSetMixin的源码的截取 1234567891011121314151617181920212223242526272829303132333435class ViewSetMixin: @classonlymethod # 对as_view()方法又一次封装,action表示可以接收参数了 def as_view(cls, actions=None, **initkwargs): if not actions: raise TypeError(\"The `actions` argument must be provided when \" \"calling `.as_view()` on a ViewSet. For example \" \"`.as_view(&#123;'get': 'list'&#125;)`\") def view(request, *args, **kwargs): self = cls(**initkwargs) # We also store the mapping of request methods to actions, # so that we can later set the action attribute. # eg. `self.action = 'list'` on an incoming GET request. self.action_map = actions # Bind methods to actions # This is the bit that's different to a standard view # method, action退出action为一个字典,&#123;'get':'list'&#125; for method, action in actions.items(): # handler为实例中的各个方法 handler = getattr(self, action) # 这里setattr相当于metmod == handler setattr(self, method, handler) if hasattr(self, 'get') and not hasattr(self, 'head'): self.head = self.get self.request = request self.args = args self.kwargs = kwargs # And continue as usual return self.dispatch(request, *args, **kwargs) return csrf_exempt(view) 奉献一张图来看下我们的继承顺序","categories":[{"name":"django-rest-framework","slug":"django-rest-framework","permalink":"https://liangweijiang.github.io/categories/django-rest-framework/"}],"tags":[{"name":"DRF","slug":"DRF","permalink":"https://liangweijiang.github.io/tags/DRF/"}]},{"title":"DRF源码解析1--APIView对request的重新封装","slug":"DRF-01","date":"2020-02-19T08:58:37.586Z","updated":"2020-02-19T10:08:43.094Z","comments":true,"path":"2020/02/19/DRF-01/","link":"","permalink":"https://liangweijiang.github.io/2020/02/19/DRF-01/","excerpt":"","text":"截取APIView12345678910111213141516171819202122232425262728293031323334353637383940414243444546@classmethodclass APIView(View): def as_view(cls, **initkwargs): if isinstance(getattr(cls, 'queryset', None), models.query.QuerySet): def force_evaluation(): raise RuntimeError( 'Do not evaluate the `.queryset` attribute directly, ' 'as the result will be cached and reused between requests. ' 'Use `.all()` or call `.get_queryset()` instead.' ) cls.queryset._fetch_all = force_evaluation # 继承了django中View类的的as_view()方法,然后重写了dispatch方法 view = super().as_view(**initkwargs) view.cls = cls view.initkwargs = initkwargs return csrf_exempt(view) def dispatch(self, request, *args, **kwargs): self.args = args self.kwargs = kwargs # 在传入request是,apiview对request进行了一次包装 request = self.initialize_request(request, *args, **kwargs) # 此时self.request是initialize_request方法返回的Request self.request = request self.headers = self.default_response_headers # deprecate? try: # 相比于View类的dispatch方法,Apiview在这里进行了一次初始化的方法 self.initial(request, *args, **kwargs) # Get the appropriate handler method if request.method.lower() in self.http_method_names: handler = getattr(self, request.method.lower(), self.http_method_not_allowed) else: handler = self.http_method_not_allowed response = handler(request, *args, **kwargs) except Exception as exc: response = self.handle_exception(exc) self.response = self.finalize_response(request, response, *args, **kwargs) return self.response 进入self.initalize_request()12345678910def initialize_request(self, request, *args, **kwargs): parser_context = self.get_parser_context(request) # 可以看到, request已经被封装成Request返回,而request则被封装成Request的一个属性 return Request( request, parsers=self.get_parsers(), authenticators=self.get_authenticators(), negotiator=self.get_content_negotiator(), parser_context=parser_context ) 截取Ruquest123456789101112131415161718192021222324252627282930class Request: def __init__(self, request, parsers=None, authenticators=None, negotiator=None, parser_context=None): assert isinstance(request, HttpRequest), ( 'The `request` argument must be an instance of ' '`django.http.HttpRequest`, not `&#123;&#125;.&#123;&#125;`.' .format(request.__class__.__module__, request.__class__.__name__) ) # request被封装了私有属性 self._request = request @property def content_type(self): meta = self._request.META # 封装了content_type方法获取传输类型 return meta.get('CONTENT_TYPE', meta.get('HTTP_CONTENT_TYPE', '')) @property def query_params(self): \"\"\" More semantically correct name for request.GET. \"\"\" # django的view中的request.Get属性封装成了query_params属性 return self._request.GET @property def data(self): if not _hasattr(self, '_full_data'): self._load_data_and_files() # django的view中的request.Post属性封装成了data属性 return self._full_data 我们可以看出~CBV在内部做了一个分发,本质和FBV是一样的。 以后做接口开发的时候，就要用CBV，学习了restful规范，现在就很容易理解我们为什么用CBV了。","categories":[{"name":"django-rest-framework","slug":"django-rest-framework","permalink":"https://liangweijiang.github.io/categories/django-rest-framework/"}],"tags":[{"name":"DRF","slug":"DRF","permalink":"https://liangweijiang.github.io/tags/DRF/"}]}]}